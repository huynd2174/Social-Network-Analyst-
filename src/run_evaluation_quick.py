"""
Script Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ chatbot trÃªn evaluation dataset (Quick - 100 cÃ¢u)

Cháº¡y: python src/run_evaluation_quick.py
"""

import os
import sys
import json
from datetime import datetime

# Add src to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from chatbot import KpopChatbot
from chatbot.comparison import ChatbotComparison


def main():
    """Cháº¡y Ä‘Ã¡nh giÃ¡ chatbot trÃªn evaluation dataset (100 cÃ¢u Ä‘á»ƒ nhanh)."""
    print("\n" + "="*70)
    print("  ğŸ“Š ÄÃNH GIÃ CHATBOT TRÃŠN EVALUATION DATASET (QUICK - 100 cÃ¢u)")
    print("="*70)
    
    # Check dataset
    dataset_path = "data/evaluation_dataset.json"
    if not os.path.exists(dataset_path):
        print(f"\nâŒ Dataset khÃ´ng tá»“n táº¡i: {dataset_path}")
        print("   Cháº¡y: python src/run_chatbot.py --mode eval")
        return
    
    # Load dataset info
    with open(dataset_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    questions = data.get('questions', [])
    metadata = data.get('metadata', {})
    
    print(f"\nğŸ“‚ Dataset: {dataset_path}")
    print(f"   âœ… Tá»•ng sá»‘ cÃ¢u há»i: {len(questions)}")
    print(f"   âœ… YÃªu cáº§u: â‰¥ 2000 cÃ¢u há»i")
    print(f"   âœ… Káº¿t quáº£: {'âœ… Äáº T' if len(questions) >= 2000 else 'âŒ CHÆ¯A Äáº T'}")
    
    print(f"\n   PhÃ¢n bá»‘ theo sá»‘ hop:")
    for hop, count in metadata.get('by_hops', {}).items():
        print(f"      - {hop}-hop: {count} cÃ¢u")
    
    print(f"\n   PhÃ¢n bá»‘ theo loáº¡i:")
    for qtype, count in metadata.get('by_type', {}).items():
        print(f"      - {qtype}: {count} cÃ¢u")
    
    # Initialize chatbot
    print(f"\nğŸ”„ Äang khá»Ÿi táº¡o chatbot...")
    chatbot = KpopChatbot(verbose=False)
    
    # Initialize comparison
    comparison = ChatbotComparison(kpop_chatbot=chatbot)
    
    # Evaluate on 100 questions (quick test)
    max_questions = 100
    print(f"\nğŸ”„ Äang Ä‘Ã¡nh giÃ¡ trÃªn {max_questions} cÃ¢u há»i (quick test)...")
    print(f"   ğŸ’¡ Äá»ƒ Ä‘Ã¡nh giÃ¡ táº¥t cáº£, cháº¡y: python src/run_evaluation.py")
    
    # Run evaluation
    start_time = datetime.now()
    result = comparison.evaluate_kpop_chatbot(
        questions,
        max_questions=max_questions
    )
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    # Print results
    print("\n" + "="*70)
    print("  ğŸ“Š Káº¾T QUáº¢ ÄÃNH GIÃ (100 cÃ¢u)")
    print("="*70)
    
    print(f"\nâœ… Chatbot: {result.chatbot_name}")
    print(f"   ğŸ“ˆ Accuracy: {result.accuracy:.2%} ({result.correct}/{result.total})")
    print(f"   â±ï¸  Thá»i gian trung bÃ¬nh: {result.avg_response_time:.2f}s/cÃ¢u")
    print(f"   â±ï¸  Tá»•ng thá»i gian: {duration/60:.1f} phÃºt ({duration:.0f} giÃ¢y)")
    
    if result.accuracy_by_hops:
        print(f"\n   ğŸ“Š Accuracy theo sá»‘ hop:")
        for hop in sorted(result.accuracy_by_hops.keys(), key=int):
            acc = result.accuracy_by_hops[hop]
            print(f"      - {hop}-hop: {acc:.2%}")
    
    if result.accuracy_by_type:
        print(f"\n   ğŸ“Š Accuracy theo loáº¡i cÃ¢u há»i:")
        for qtype, acc in result.accuracy_by_type.items():
            print(f"      - {qtype}: {acc:.2%}")
    
    if result.accuracy_by_category:
        print(f"\n   ğŸ“Š Accuracy theo category:")
        for category, acc in result.accuracy_by_category.items():
            print(f"      - {category}: {acc:.2%}")
    
    # Save results
    output_path = "data/evaluation_results_quick.json"
    results_data = {
        "timestamp": datetime.now().isoformat(),
        "chatbot_name": result.chatbot_name,
        "total_questions": result.total,
        "correct": result.correct,
        "accuracy": result.accuracy,
        "avg_response_time": result.avg_response_time,
        "total_time_seconds": duration,
        "accuracy_by_hops": result.accuracy_by_hops,
        "accuracy_by_type": result.accuracy_by_type,
        "accuracy_by_category": result.accuracy_by_category,
        "errors": result.errors[:10] if result.errors else []
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ Káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o: {output_path}")
    
    # Show some errors if any
    if result.errors:
        print(f"\nâš ï¸  Má»™t sá»‘ lá»—i (hiá»ƒn thá»‹ 5 lá»—i Ä‘áº§u):")
        for i, error in enumerate(result.errors[:5], 1):
            print(f"   {i}. {error}")
    
    print("\n" + "="*70)
    print("  âœ… ÄÃNH GIÃ HOÃ€N Táº¤T!")
    print("="*70)
    print(f"\nğŸ’¡ Äá»ƒ Ä‘Ã¡nh giÃ¡ táº¥t cáº£ {len(questions)} cÃ¢u há»i:")
    print(f"   python src/run_evaluation.py")
    print()


if __name__ == "__main__":
    main()





