"""
Demo Script cho K-pop Knowledge Graph Chatbot

Script nÃ y demo táº¥t cáº£ cÃ¡c tÃ­nh nÄƒng cá»§a chatbot Ä‘á»ƒ trÃ¬nh bÃ y:
1. Small LLM (â‰¤1B params)
2. GraphRAG trÃªn Ä‘á»“ thá»‹ tri thá»©c
3. Multi-hop Reasoning
4. Evaluation Dataset
5. Comparison vá»›i chatbot khÃ¡c
"""

import os
import sys
import json
from datetime import datetime

# Add src to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from chatbot import KpopChatbot, GraphRAG, MultiHopReasoner, EvaluationDatasetGenerator, ChatbotComparison


def print_section(title: str):
    """Print a formatted section header."""
    print("\n" + "="*70)
    print(f"  {title}")
    print("="*70 + "\n")


def demo_1_small_llm():
    """Demo 1: Small LLM (â‰¤1B params) - 1 Ä‘iá»ƒm"""
    print_section("1. DEMO: Small LLM (â‰¤1B Parameters)")
    
    from chatbot.small_llm import SmallLLM, get_llm
    
    print("ğŸ”„ Äang khá»Ÿi táº¡o Small LLM...")
    try:
        llm = get_llm("qwen2-0.5b")
        
        # Get model size
        param_count = sum(p.numel() for p in llm.model.parameters())
        param_count_b = param_count / 1e9
        
        print(f"\nâœ… Model: Qwen2-0.5B-Instruct")
        print(f"âœ… Sá»‘ tham sá»‘: {param_count_b:.3f} tá»· ({param_count/1e6:.1f}M)")
        print(f"âœ… YÃªu cáº§u: â‰¤ 1 tá»· tham sá»‘")
        print(f"âœ… Káº¿t quáº£: {'âœ… Äáº T' if param_count_b <= 1.0 else 'âŒ KHÃ”NG Äáº T'}")
        
        # Test generation
        print(f"\nğŸ§ª Test generation:")
        test_query = "BTS lÃ  nhÃ³m nháº¡c K-pop."
        response = llm.generate(test_query, max_new_tokens=50)
        print(f"   Query: {test_query}")
        print(f"   Response: {response[:100]}...")
        
        return True
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        return False


def demo_2_graphrag():
    """Demo 2: GraphRAG - 0.5 Ä‘iá»ƒm"""
    print_section("2. DEMO: GraphRAG trÃªn Äá»“ thá»‹ Tri thá»©c")
    
    print("ğŸ”„ Äang khá»Ÿi táº¡o Knowledge Graph vÃ  GraphRAG...")
    print("   GraphRAG = 3 bÆ°á»›c:")
    print("   1. Semantic Search: TÃ¬m node gáº§n nháº¥t báº±ng vector search (FAISS + embeddings)")
    print("   2. Expand Subgraph: Tá»« node tÃ¬m Ä‘Æ°á»£c â†’ má»Ÿ rá»™ng hÃ ng xÃ³m 1-2 hop â†’ láº¥y subgraph")
    print("   3. Build Context: Chuyá»ƒn subgraph â†’ text/triples Ä‘á»ƒ feed vÃ o LLM")
    
    try:
        # Initialize GraphRAG
        from chatbot.knowledge_graph import KpopKnowledgeGraph
        kg = KpopKnowledgeGraph()
        rag = GraphRAG(knowledge_graph=kg)
        
        # Show knowledge graph stats
        kg_stats = kg.get_statistics()
        print(f"\nâœ… Knowledge Graph (Biá»ƒu diá»…n máº¡ng xÃ£ há»™i dÆ°á»›i hÃ¬nh thá»©c Ä‘á»“ thá»‹ tri thá»©c):")
        print(f"   - Nodes (Entities): {kg_stats['total_nodes']:,}")
        print(f"   - Edges (Relationships): {kg_stats['total_edges']:,}")
        print(f"   - Entity types: {len(kg_stats['entity_types'])}")
        print(f"   - Relationship types: {len(kg_stats['relationship_types'])}")
        
        # Show entity types
        print(f"\n   Entity types:")
        for etype, count in list(kg_stats['entity_types'].items())[:5]:
            print(f"      - {etype}: {count}")
        
        # Show relationship types
        print(f"\n   Relationship types:")
        for rtype, count in list(kg_stats['relationship_types'].items())[:5]:
            print(f"      - {rtype}: {count}")
        
        # Test GraphRAG retrieval - Demo 3 bÆ°á»›c
        print(f"\nğŸ§ª Test GraphRAG retrieval (3 bÆ°á»›c):")
        test_queries = [
            "BTS cÃ³ bao nhiÃªu thÃ nh viÃªn?",
            "BLACKPINK thuá»™c cÃ´ng ty nÃ o?",
            "g-dragon vá»›i blackpink cÃ³ cÃ¹ng cÃ´ng ty khÃ´ng?"
        ]
        
        for query in test_queries:
            print(f"\n   Query: {query}")
            print(f"   ğŸ“ BÆ°á»›c 1: Semantic Search - TÃ¬m entities tá»« query")
            entities = rag.extract_entities(query)
            print(f"      âœ… Entities found: {len(entities)}")
            for e in entities[:3]:
                print(f"         - {e.get('text', e.get('id', 'N/A'))} ({e.get('type', 'N/A')}) - Score: {e.get('score', 0):.2f}")
            
            print(f"   ğŸ“ BÆ°á»›c 2: Expand Subgraph - Má»Ÿ rá»™ng neighbors 1-2 hop")
            context = rag.retrieve_context(query, max_entities=5, max_hops=2)
            print(f"      âœ… Entities: {len(context['entities'])}")
            print(f"      âœ… Relationships: {len(context['relationships'])}")
            print(f"      âœ… Facts: {len(context['facts'])}")
            
            if context['entities']:
                print(f"      ğŸ“ Expanded entities (tá»« Graph Traversal):")
                for e in context['entities'][:3]:
                    print(f"         - {e['id']} ({e['type']})")
            
            if context['relationships']:
                print(f"      ğŸ”— Relationships (tá»« Graph):")
                for r in context['relationships'][:2]:
                    print(f"         - {r['source']} --[{r['type']}]--> {r['target']}")
            
            print(f"   ğŸ“ BÆ°á»›c 3: Build Context - Format cho LLM")
            formatted = rag.format_context_for_llm(context, max_tokens=500)
            print(f"      âœ… Context length: {len(formatted)} chars")
            print(f"      ğŸ“„ Preview: {formatted[:200]}...")
        
        print(f"\nâœ… GraphRAG hoáº¡t Ä‘á»™ng Ä‘Ãºng vá»›i 3 bÆ°á»›c!")
        print(f"   âœ… BÆ°á»›c 1: Semantic Search (FAISS + embeddings)")
        print(f"   âœ… BÆ°á»›c 2: Expand Subgraph (Graph traversal)")
        print(f"   âœ… BÆ°á»›c 3: Build Context (Format triples/text)")
        print(f"   ğŸ“Œ GraphRAG chá»‰ lÃ  'Retrieval layer' - khÃ´ng suy luáº­n, khÃ´ng táº¡o cÃ¢u tráº£ lá»i")
        return True
        
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        import traceback
        traceback.print_exc()
        return False


def demo_3_multi_hop():
    """Demo 3: Multi-hop Reasoning - 1.5 Ä‘iá»ƒm"""
    print_section("3. DEMO: Multi-hop Reasoning trÃªn Äá»“ thá»‹")
    
    print("ğŸ”„ Äang khá»Ÿi táº¡o Multi-hop Reasoner...")
    
    try:
        from chatbot.knowledge_graph import KpopKnowledgeGraph
        kg = KpopKnowledgeGraph()
        reasoner = MultiHopReasoner(kg)
        
        # Test cases covering 1-hop, 2-hop, 3-hop
        # Bao gá»“m cÃ¡c test cases Ä‘Ã£ sá»­a: entity extraction vá»›i variants, multiple companies
        test_cases = [
            {
                "name": "1-hop: ThÃ nh viÃªn cá»§a BTS",
                "query": "ThÃ nh viÃªn cá»§a BTS",
                "method": reasoner.get_group_members,
                "args": ["BTS"],
                "expected_hops": 1
            },
            {
                "name": "1-hop: Membership check",
                "query": "BTS cÃ³ thÃ nh viÃªn Jungkook khÃ´ng?",
                "method": lambda q, e, h: reasoner.reason(q, e, h),
                "args": ["BTS cÃ³ thÃ nh viÃªn Jungkook khÃ´ng?", ["Jungkook", "BTS"], 1],
                "expected_hops": 1
            },
            {
                "name": "2-hop: CÃ´ng ty cá»§a Jungkook (Artist â†’ Group â†’ Company)",
                "query": "CÃ´ng ty quáº£n lÃ½ Jungkook",
                "method": reasoner.get_artist_company,
                "args": ["Jungkook"],
                "expected_hops": 2
            },
            {
                "name": "2-hop: CÃ¹ng cÃ´ng ty? (BTS vs SEVENTEEN)",
                "query": "BTS vÃ  SEVENTEEN cÃ³ cÃ¹ng cÃ´ng ty khÃ´ng?",
                "method": reasoner.check_same_company,
                "args": ["BTS", "SEVENTEEN"],
                "expected_hops": 2
            },
            {
                "name": "2-hop: CÃ¹ng cÃ´ng ty? (G-Dragon vs BLACKPINK) - Test variants",
                "query": "g-dragon vá»›i blackpink cÃ³ cÃ¹ng cÃ´ng ty hay hÃ£ng Ä‘Ä©a khÃ´ng?",
                "method": lambda q: reasoner.reason(q, [], 3),
                "args": ["g-dragon vá»›i blackpink cÃ³ cÃ¹ng cÃ´ng ty hay hÃ£ng Ä‘Ä©a khÃ´ng?"],
                "expected_hops": 2
            },
            {
                "name": "2-hop: CÃ¹ng nhÃ³m? (Lisa vs Jennie)",
                "query": "Lisa vÃ  Jennie cÃ³ cÃ¹ng nhÃ³m nháº¡c khÃ´ng?",
                "method": lambda q: reasoner.reason(q, [], 3),
                "args": ["Lisa vÃ  Jennie cÃ³ cÃ¹ng nhÃ³m nháº¡c khÃ´ng?"],
                "expected_hops": 1
            },
            {
                "name": "1-hop: Company cá»§a group (BLACKPINK cÃ³ nhiá»u companies)",
                "query": "CÃ´ng ty quáº£n lÃ½ BLACKPINK",
                "method": reasoner.get_company_of_group,
                "args": ["BLACKPINK"],
                "expected_hops": 1
            },
            {
                "name": "2-hop: Labelmates (CÃ¡c nhÃ³m cÃ¹ng cÃ´ng ty)",
                "query": "CÃ¡c nhÃ³m cÃ¹ng cÃ´ng ty vá»›i BTS",
                "method": reasoner.get_labelmates,
                "args": ["BTS"],
                "expected_hops": 2
            }
        ]
        
        print(f"\nğŸ§ª Test Multi-hop Reasoning (1-hop, 2-hop, 3-hop):\n")
        
        for i, test in enumerate(test_cases, 1):
            print(f"{i}. {test['name']}")
            print(f"   Query: {test['query']}")
            
            try:
                result = test['method'](*test['args'])
                
                if hasattr(result, 'steps') and hasattr(result, 'answer_text'):
                    hops = len(result.steps) if result.steps else 0
                    print(f"   âœ… Hops: {hops} (Expected: {test['expected_hops']})")
                    print(f"   âœ… Answer: {result.answer_text[:150]}")
                    print(f"   âœ… Confidence: {result.confidence:.1%}")
                    if result.steps:
                        print(f"   âœ… Reasoning Steps (Graph Traversal):")
                        for step in result.steps[:3]:  # Limit to 3 steps
                            print(f"      - Hop {step.hop_number}: {step.explanation[:80]}")
                            if step.target_entities:
                                print(f"        â†’ Entities: {', '.join(step.target_entities[:3])}")
                    if hasattr(result, 'answer_entities') and result.answer_entities:
                        print(f"   âœ… Answer Entities: {', '.join(result.answer_entities[:5])}")
                else:
                    print(f"   âš ï¸  Result khÃ´ng cÃ³ format Ä‘Ãºng (missing steps or answer_text)")
                    print(f"   Result type: {type(result)}")
                    if isinstance(result, str):
                        print(f"   Result: {result[:150]}")
            except Exception as e:
                print(f"   âš ï¸  Lá»—i: {e}")
                import traceback
                traceback.print_exc()
            
            print()
        
        print(f"âœ… Multi-hop Reasoning hoáº¡t Ä‘á»™ng Ä‘Ãºng!")
        print(f"   âœ… Há»— trá»£ 1-hop, 2-hop, 3-hop reasoning")
        print(f"   âœ… Sá»­ dá»¥ng graph traversal trÃªn Knowledge Graph (BFS/DFS)")
        print(f"   âœ… Xá»­ lÃ½ entity variants (g-dragon, blackpink, etc.)")
        print(f"   âœ… So sÃ¡nh multiple companies (khÃ´ng chá»‰ 1 company)")
        print(f"   âœ… Path-finding, Multi-hop Retriever, Reasoning Module")
        print(f"   ğŸ“Œ Multi-hop reasoning do Reasoner thá»±c hiá»‡n (graph algorithms)")
        print(f"   ğŸ“Œ KHÃ”NG dÃ¹ng LLM Ä‘á»ƒ suy luáº­n multi-hop")
        return True
        
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        import traceback
        traceback.print_exc()
        return False


def demo_4_evaluation_dataset():
    """Demo 4: Evaluation Dataset (2000+ questions) - 1 Ä‘iá»ƒm"""
    print_section("4. DEMO: Evaluation Dataset Generator")
    
    dataset_path = "data/evaluation_dataset.json"
    
    # Check if dataset exists
    if os.path.exists(dataset_path):
        print(f"ğŸ“‚ Dataset Ä‘Ã£ tá»“n táº¡i: {dataset_path}")
        with open(dataset_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        metadata = data.get('metadata', {})
        questions = data.get('questions', [])
        
        print(f"\nâœ… Dataset Statistics:")
        print(f"   - Tá»•ng sá»‘ cÃ¢u há»i: {metadata.get('total_questions', len(questions))}")
        print(f"   - YÃªu cáº§u: â‰¥ 2000 cÃ¢u há»i")
        print(f"   - Káº¿t quáº£: {'âœ… Äáº T' if metadata.get('total_questions', 0) >= 2000 else 'âŒ CHÆ¯A Äáº T'}")
        
        print(f"\n   PhÃ¢n bá»‘ theo sá»‘ hop:")
        for hop, count in metadata.get('by_hops', {}).items():
            print(f"      - {hop}-hop: {count} cÃ¢u")
        
        print(f"\n   PhÃ¢n bá»‘ theo loáº¡i:")
        for qtype, count in metadata.get('by_type', {}).items():
            print(f"      - {qtype}: {count} cÃ¢u")
        
        # Show sample questions
        print(f"\n   ğŸ“ Sample questions:")
        for q in questions[:5]:
            print(f"      - [{q['question_type']}] {q['question']}")
            print(f"        Answer: {q['answer']} (Hops: {q['hops']})")
        
        return True
    else:
        print(f"âš ï¸  Dataset chÆ°a tá»“n táº¡i. Táº¡o dataset má»›i? (y/n)")
        response = input().strip().lower()
        
        if response == 'y':
            print(f"\nğŸ”„ Äang táº¡o evaluation dataset (2000 cÃ¢u há»i)...")
            generator = EvaluationDatasetGenerator()
            stats = generator.generate_full_dataset(
                target_count=2000,
                output_path=dataset_path
            )
            
            print(f"\nâœ… Dataset Ä‘Ã£ Ä‘Æ°á»£c táº¡o!")
            print(f"   - Tá»•ng sá»‘: {stats['total_questions']} cÃ¢u há»i")
            return True
        else:
            print(f"â­ï¸  Bá» qua táº¡o dataset")
            return False


def demo_5_comparison():
    """Demo 5: Comparison vá»›i chatbot khÃ¡c - 0.5 Ä‘iá»ƒm"""
    print_section("5. DEMO: So sÃ¡nh vá»›i Chatbot phá»• biáº¿n")
    
    dataset_path = "data/evaluation_dataset.json"
    
    if not os.path.exists(dataset_path):
        print(f"âŒ Evaluation dataset chÆ°a tá»“n táº¡i. Cháº¡y demo 4 trÆ°á»›c!")
        return False
    
    print(f"ğŸ”„ Äang khá»Ÿi táº¡o chatbot vÃ  comparison framework...")
    print(f"   So sÃ¡nh vá»›i: ChatGPT, Gemini, Baseline")
    
    try:
        # Try to get Gemini API key from run_comparison_gemini.py
        gemini_key_from_file = None
        try:
            gemini_script_path = os.path.join(os.path.dirname(__file__), "run_comparison_gemini.py")
            if os.path.exists(gemini_script_path):
                with open(gemini_script_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    # Extract GEMINI_API_KEY value
                    import re
                    match = re.search(r'GEMINI_API_KEY\s*=\s*["\']([^"\']+)["\']', content)
                    if match:
                        gemini_key_from_file = match.group(1)
                        print(f"   âœ… ÄÃ£ tÃ¬m tháº¥y Gemini API key tá»« run_comparison_gemini.py")
        except Exception as e:
            pass  # Ignore errors when reading the file
        
        # Initialize chatbot
        chatbot = KpopChatbot(verbose=False)
        
        # Initialize comparison with API keys from environment or file
        openai_key = os.getenv("OPENAI_API_KEY")
        google_key = os.getenv("GOOGLE_API_KEY") or gemini_key_from_file
        
        # Set in environment if found from file
        if gemini_key_from_file and not os.getenv("GOOGLE_API_KEY"):
            os.environ["GOOGLE_API_KEY"] = gemini_key_from_file
            google_key = gemini_key_from_file
        
        comparison = ChatbotComparison(
            kpop_chatbot=chatbot,
            openai_api_key=openai_key,
            google_api_key=google_key
        )
        
        # Load dataset
        questions = comparison.load_evaluation_dataset(dataset_path)
        print(f"âœ… Loaded {len(questions)} questions from dataset")
        
        # Show sample questions
        print(f"\nğŸ“ Sample questions from dataset:")
        for q in questions[:3]:
            print(f"   - [{q['question_type']}] {q['question']}")
            print(f"     Answer: {q['answer']} (Hops: {q['hops']})")
        
        # Run comparison (limited for demo)
        print(f"\nğŸ”„ Äang cháº¡y comparison (sample 50 questions cho demo)...")
        print(f"   âš ï¸  LÆ°u Ã½: Demo chá»‰ cháº¡y 50 cÃ¢u há»i Ä‘á»ƒ nhanh")
        print(f"   ğŸ’¡ Äá»ƒ cháº¡y full, dÃ¹ng: python src/run_chatbot.py --mode compare")
        
        # Check API keys (after loading from file)
        has_openai = os.getenv("OPENAI_API_KEY") is not None
        has_google = google_key is not None
        
        print(f"\n   API Keys:")
        print(f"   - OpenAI (ChatGPT): {'âœ…' if has_openai else 'âŒ (Set OPENAI_API_KEY env var)'}")
        if has_google:
            if gemini_key_from_file and not os.getenv("GOOGLE_API_KEY"):
                print(f"   - Google (Gemini): âœ… (Ä‘Ã£ láº¥y tá»« run_comparison_gemini.py)")
            else:
                print(f"   - Google (Gemini): âœ…")
        else:
            print(f"   - Google (Gemini): âŒ (Set GOOGLE_API_KEY env var)")
            print(f"\n   ğŸ’¡ Äá»ƒ set Google API key:")
            print(f"      PowerShell: $env:GOOGLE_API_KEY='YOUR_KEY'")
            print(f"      Hoáº·c: python src/set_api_keys.py --google YOUR_KEY")
            print(f"      Xem thÃªm: docs/HOW_TO_SET_API_KEYS.md")
        
        results = comparison.compare_chatbots(
            questions,
            include_chatgpt=has_openai,
            include_gemini=has_google,
            include_baseline=True,
            max_questions=50  # Limited for demo
        )
        
        print(f"\nâœ… Comparison hoÃ n thÃ nh!")
        print(f"\nğŸ“Š Results:")
        for result in results:
            # Check if result is a ChatbotEvaluation object
            if hasattr(result, 'chatbot_name'):
                print(f"   - {result.chatbot_name}:")
                print(f"     Accuracy: {result.accuracy:.1%}")
                print(f"     Avg Response Time: {result.avg_response_time:.2f}s")
                if result.accuracy_by_hops:
                    print(f"     By Hops:")
                    for hop, acc in result.accuracy_by_hops.items():
                        print(f"       {hop}-hop: {acc:.1%}")
            else:
                # Skip if it's not a ChatbotEvaluation object
                continue
        
        print(f"\nğŸ“ Results saved to: data/comparison_results.json")
        
        return True
        
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        import traceback
        traceback.print_exc()
        return False


def demo_full_chatbot():
    """Demo: Full Chatbot Integration - TÃ­ch há»£p táº¥t cáº£ components"""
    print_section("6. DEMO: Full Chatbot Integration (Táº¥t cáº£ Components)")
    
    print("ğŸ”„ Äang khá»Ÿi táº¡o chatbot vá»›i táº¥t cáº£ components...")
    print("   - Knowledge Graph")
    print("   - GraphRAG")
    print("   - Multi-hop Reasoning")
    print("   - Small LLM (Qwen2-0.5B)")
    
    try:
        chatbot = KpopChatbot(verbose=True)
        
        # Test queries covering all requirements
        # Bao gá»“m cÃ¡c test cases Ä‘Ã£ sá»­a: entity variants, same company/group questions
        test_queries = [
            {
                "query": "BTS cÃ³ bao nhiÃªu thÃ nh viÃªn?",
                "description": "1-hop: ThÃ nh viÃªn cá»§a nhÃ³m",
                "expected_components": ["GraphRAG", "Multi-hop", "LLM"]
            },
            {
                "query": "BTS cÃ³ thÃ nh viÃªn Jungkook khÃ´ng?",
                "description": "1-hop: Membership check (Æ°u tiÃªn reasoning)",
                "expected_components": ["GraphRAG", "Multi-hop", "Reasoning-first"]
            },
            {
                "query": "CÃ´ng ty nÃ o quáº£n lÃ½ BLACKPINK?",
                "description": "1-hop: Company cá»§a group (cÃ³ thá»ƒ nhiá»u companies)",
                "expected_components": ["GraphRAG", "Multi-hop", "LLM"]
            },
            {
                "query": "BTS vÃ  SEVENTEEN cÃ³ cÃ¹ng cÃ´ng ty khÃ´ng?",
                "description": "2-hop: So sÃ¡nh cÃ´ng ty (so sÃ¡nh táº¥t cáº£ companies)",
                "expected_components": ["GraphRAG", "Multi-hop", "LLM"]
            },
            {
                "query": "g-dragon vá»›i blackpink cÃ³ cÃ¹ng cÃ´ng ty hay hÃ£ng Ä‘Ä©a khÃ´ng?",
                "description": "2-hop: So sÃ¡nh cÃ´ng ty vá»›i entity variants (g-dragon, blackpink)",
                "expected_components": ["GraphRAG", "Multi-hop", "Entity-variants", "LLM"]
            },
            {
                "query": "Lisa vÃ  Jennie cÃ³ cÃ¹ng nhÃ³m nháº¡c khÃ´ng?",
                "description": "1-hop: So sÃ¡nh nhÃ³m (same group check)",
                "expected_components": ["GraphRAG", "Multi-hop", "Reasoning-first"]
            },
            {
                "query": "CÃ¡c nhÃ³m cÃ¹ng cÃ´ng ty vá»›i BTS lÃ  gÃ¬?",
                "description": "2-hop: Labelmates",
                "expected_components": ["GraphRAG", "Multi-hop", "LLM"]
            }
        ]
        
        session_id = chatbot.create_session()
        
        print(f"\nğŸ§ª Test Chatbot vá»›i cÃ¡c cÃ¢u há»i:\n")
        
        for i, test in enumerate(test_queries, 1):
            query = test['query']
            print(f"{i}. {test['description']}")
            print(f"   â“ Query: {query}")
            
            result = chatbot.chat(
                query,
                session_id,
                use_multi_hop=True,
                max_hops=3,
                use_llm=True,  # DÃ¹ng LLM Ä‘á»ƒ Ä‘Ã¡p á»©ng yÃªu cáº§u bÃ i táº­p
                return_details=True
            )
            
            print(f"   ğŸ¤– Response: {result['response'][:200]}")
            print(f"   ğŸ“Š Entities: {result['entities_found']}, Hops: {result['reasoning_hops']}")
            
            # Show which components were used
            if result.get('reasoning'):
                print(f"   âœ… Multi-hop Reasoning: {result['reasoning']['type']}")
            if result.get('context'):
                print(f"   âœ… GraphRAG: {len(result['context']['entities'])} entities retrieved")
            print()
        
        print(f"âœ… Chatbot hoáº¡t Ä‘á»™ng Ä‘Ãºng vá»›i táº¥t cáº£ components!")
        return True
        
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Main demo function."""
    print("\n" + "="*70)
    print("  ğŸ¤ K-POP KNOWLEDGE GRAPH CHATBOT - DEMO")
    print("="*70)
    print("\nDemo táº¥t cáº£ cÃ¡c tÃ­nh nÄƒng Ä‘á»ƒ trÃ¬nh bÃ y bÃ i táº­p:")
    print("  (4.5 Ä‘iá»ƒm) XÃ¢y dá»±ng chatbot dá»±a trÃªn Ä‘á»“ thá»‹ tri thá»©c")
    print("    (1 Ä‘iá»ƒm) Small LLM (â‰¤1B params)")
    print("    (0.5 Ä‘iá»ƒm) GraphRAG trÃªn Ä‘á»“ thá»‹ tri thá»©c")
    print("    (1.5 Ä‘iá»ƒm) Multi-hop Reasoning")
    print("    (1 Ä‘iá»ƒm) Evaluation Dataset (2000+ questions)")
    print("    (0.5 Ä‘iá»ƒm) Comparison vá»›i chatbot phá»• biáº¿n")
    print("\n" + "="*70)
    
    results = {}
    
    # Run demos
    results['1_small_llm'] = demo_1_small_llm()
    results['2_graphrag'] = demo_2_graphrag()
    results['3_multi_hop'] = demo_3_multi_hop()
    results['4_evaluation'] = demo_4_evaluation_dataset()
    results['5_comparison'] = demo_5_comparison()
    results['full_chatbot'] = demo_full_chatbot()
    
    # Summary
    print_section("TÃ“M Táº®T Káº¾T QUáº¢")
    
    print("ğŸ“Š Káº¿t quáº£ cÃ¡c pháº§n demo:\n")
    print(f"  (1 Ä‘iá»ƒm) Small LLM (â‰¤1B):           {'âœ… Äáº T' if results['1_small_llm'] else 'âŒ CHÆ¯A Äáº T'}")
    print(f"  (0.5 Ä‘iá»ƒm) GraphRAG:                  {'âœ… Äáº T' if results['2_graphrag'] else 'âŒ CHÆ¯A Äáº T'}")
    print(f"  (1.5 Ä‘iá»ƒm) Multi-hop Reasoning:       {'âœ… Äáº T' if results['3_multi_hop'] else 'âŒ CHÆ¯A Äáº T'}")
    print(f"  (1 Ä‘iá»ƒm) Evaluation Dataset:       {'âœ… Äáº T' if results['4_evaluation'] else 'âŒ CHÆ¯A Äáº T'}")
    print(f"  (0.5 Ä‘iá»ƒm) Comparison:                {'âœ… Äáº T' if results['5_comparison'] else 'âŒ CHÆ¯A Äáº T'}")
    print(f"  Full Chatbot Integration:  {'âœ… Äáº T' if results['full_chatbot'] else 'âŒ CHÆ¯A Äáº T'}")
    
    # Calculate total score
    total_score = 0
    if results['1_small_llm']: total_score += 1.0
    if results['2_graphrag']: total_score += 0.5
    if results['3_multi_hop']: total_score += 1.5
    if results['4_evaluation']: total_score += 1.0
    if results['5_comparison']: total_score += 0.5
    
    print(f"\n  ğŸ“Š Tá»•ng Ä‘iá»ƒm: {total_score}/4.5")
    
    all_passed = all(results.values())
    
    print(f"\n{'='*70}")
    if all_passed:
        print("  âœ… Táº¤T Cáº¢ DEMO Äá»€U THÃ€NH CÃ”NG!")
    else:
        print("  âš ï¸  Má»˜T Sá» DEMO CÃ“ Lá»–I - KIá»‚M TRA Láº I")
    print(f"{'='*70}\n")
    
    print("ğŸ“ CÃ¡c file quan trá»ng:")
    print("  - Evaluation Dataset: data/evaluation_dataset.json")
    print("  - Comparison Results: data/comparison_results.json")
    print("  - Knowledge Graph: data/merged_kpop_data.json")
    print("\nğŸ’¡ Äá»ƒ cháº¡y tá»«ng pháº§n riÃªng:")
    print("  - python src/run_chatbot.py --mode cli")
    print("  - python src/run_chatbot.py --mode ui")
    print("  - python src/run_chatbot.py --mode eval")
    print("  - python src/run_chatbot.py --mode compare")


if __name__ == "__main__":
    main()

