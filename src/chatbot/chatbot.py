"""
Main Chatbot Module for K-pop Knowledge Graph

This module integrates all components:
- Knowledge Graph
- GraphRAG
- Multi-hop Reasoning
- Small LLM

Provides a unified interface for the K-pop chatbot.
"""

import json
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from datetime import datetime

from .knowledge_graph import KpopKnowledgeGraph
from .knowledge_graph_neo4j import KpopKnowledgeGraphNeo4j
from .graph_rag import GraphRAG
from .multi_hop_reasoning import MultiHopReasoner, ReasoningResult
from .small_llm import SmallLLM, get_llm, TRANSFORMERS_AVAILABLE


@dataclass
class ChatMessage:
    """A single chat message."""
    role: str  # 'user' or 'assistant'
    content: str
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    metadata: Dict = field(default_factory=dict)


@dataclass
class ChatSession:
    """A chat session with history."""
    session_id: str
    messages: List[ChatMessage] = field(default_factory=list)
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    
    def add_message(self, role: str, content: str, metadata: Dict = None):
        """Add a message to the session."""
        self.messages.append(ChatMessage(
            role=role,
            content=content,
            metadata=metadata or {}
        ))
        
    def get_history(self, max_turns: int = 5) -> List[Dict]:
        """Get conversation history for context."""
        history = []
        for msg in self.messages[-max_turns * 2:]:
            history.append({
                "role": msg.role,
                "content": msg.content
            })
        return history


class KpopChatbot:
    """
    K-pop Knowledge Graph Chatbot.
    
    Combines GraphRAG retrieval with multi-hop reasoning
    and small LLM generation for answering K-pop questions.
    """
    
    def __init__(
        self,
        data_path: str = "data/merged_kpop_data.json",
        llm_model: str = "qwen2-0.5b",
        use_embeddings: bool = True,
        verbose: bool = True
    ):
        """
        Initialize the chatbot.
        
        Args:
            data_path: Path to merged K-pop data
            llm_model: Model key for small LLM
            use_embeddings: Whether to use semantic embeddings
            verbose: Print initialization progress
        """
        self.verbose = verbose
        self.sessions: Dict[str, ChatSession] = {}
        
        # Initialize components
        if verbose:
            print("ğŸ”„ Initializing K-pop Chatbot...")
            
        # 1. Knowledge Graph
        if verbose:
            print("  ğŸ“Š Loading Knowledge Graph...")
        self.kg = KpopKnowledgeGraph(data_path)
        
        # 2. GraphRAG
        if verbose:
            print("  ğŸ” Initializing GraphRAG...")
        # Pass LLM to GraphRAG Ä‘á»ƒ dÃ¹ng cho understanding (náº¿u cÃ³)
        # LLM sáº½ Ä‘Æ°á»£c load sau, nÃªn pass None lÃºc Ä‘áº§u, sáº½ set sau
        self.rag = GraphRAG(
            knowledge_graph=self.kg,
            use_cache=True,
            llm_for_understanding=None  # Sáº½ set sau khi LLM load xong
        )
        
        # 3. Multi-hop Reasoner
        if verbose:
            print("  ğŸ§  Initializing Multi-hop Reasoner...")
        self.reasoner = MultiHopReasoner(self.kg)
        
        # 4. Small LLM (optional)
        self.llm = None
        if llm_model:
            if verbose:
                print(f"  ğŸ¤– Loading LLM: {llm_model}...")
            try:
                self.llm = get_llm(llm_model)
                # Set LLM cho GraphRAG Ä‘á»ƒ dÃ¹ng cho understanding
                self.rag.llm_for_understanding = self.llm
            except Exception as e:
                if verbose:
                    print(f"  âš ï¸ LLM loading failed: {e}")
                    print("  ğŸ’¡ Using fallback mode (context-based responses)")
                self.llm = None
        else:
            if verbose:
                print("  ğŸ¤– LLM skipped (graph-only mode)")
            
        if verbose:
            print("âœ… Chatbot initialized successfully!")
            
    def create_session(self, session_id: str = None) -> str:
        """Create a new chat session."""
        if session_id is None:
            session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
        self.sessions[session_id] = ChatSession(session_id=session_id)
        return session_id
        
    def get_session(self, session_id: str) -> Optional[ChatSession]:
        """Get an existing session."""
        return self.sessions.get(session_id)
        
    def chat(
        self,
        query: str,
        session_id: str = None,
        use_multi_hop: bool = True,
        max_hops: int = 3,
        return_details: bool = False,
        use_llm: bool = True
    ) -> Dict:
        """
        Process a chat query and return response.
        
        Args:
            query: User's question
            session_id: Session ID for conversation history
            use_multi_hop: Enable multi-hop reasoning
            max_hops: Maximum reasoning hops
            return_details: Include detailed reasoning info
            
        Returns:
            Response dictionary with answer and metadata
        """
        # Get or create session
        if session_id and session_id in self.sessions:
            session = self.sessions[session_id]
        else:
            session_id = self.create_session(session_id)
            session = self.sessions[session_id]
            
        # Add user message
        session.add_message("user", query)
        
        # ============================================
        # BÆ¯á»šC 1: GRAPHRAG - Láº¤Y CONTEXT Tá»ª Äá»’ THá»Š TRI THá»¨C
        # ============================================
        # âœ… GraphRAG LUÃ”N Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ láº¥y context tá»« Knowledge Graph
        # GraphRAG thá»±c hiá»‡n 3 bÆ°á»›c:
        # 1. Semantic Search: TÃ¬m node gáº§n nháº¥t báº±ng vector search (FAISS + embeddings)
        # 2. Expand Subgraph: Tá»« node tÃ¬m Ä‘Æ°á»£c â†’ má»Ÿ rá»™ng hÃ ng xÃ³m 1-2 hop â†’ láº¥y subgraph
        # 3. Build Context: Chuyá»ƒn subgraph â†’ text/triples Ä‘á»ƒ feed vÃ o LLM
        # 
        # Táº¤T Cáº¢ thÃ´ng tin Ä‘á»u láº¥y tá»« Äá»’ THá»Š TRI THá»¨C (Knowledge Graph), khÃ´ng pháº£i tá»« LLM memory
        context = self.rag.retrieve_context(
            query,
            max_entities=5,
            max_hops=max_hops
        )
        
        # 2.5. Check if this is a membership Yes/No question - use reasoning directly
        query_lower = query.lower()
        is_membership_question = (
            any(kw in query_lower for kw in ['cÃ³ pháº£i', 'pháº£i', 'lÃ  thÃ nh viÃªn', 'is a member', 'belongs to', 'cÃ³ thÃ nh viÃªn']) and
            any(kw in query_lower for kw in ['thÃ nh viÃªn', 'member'])
        )
        
        # Check if this is a "list members" question: "Ai lÃ  thÃ nh viÃªn", "Who are members"
        is_list_members_question = any(kw in query_lower for kw in [
            'ai lÃ  thÃ nh viÃªn', 'who are', 'thÃ nh viÃªn cá»§a', 'members of',
            'thÃ nh viÃªn nhÃ³m', 'thÃ nh viÃªn ban nháº¡c', 'cÃ³ nhá»¯ng thÃ nh viÃªn'
        ]) and 'cÃ³ pháº£i' not in query_lower and 'khÃ´ng' not in query_lower
        
        # Check if this is a "same group" question - use reasoning directly
        is_same_group_question = any(kw in query_lower for kw in ['cÃ¹ng nhÃ³m', 'cÃ¹ng nhÃ³m nháº¡c', 'same group', 'cÃ¹ng ban nháº¡c'])
        
        # Check if this is a "same company" question - use reasoning directly
        # Má»Ÿ rá»™ng patterns Ä‘á»ƒ detect nhiá»u cÃ¡ch há»i hÆ¡n
        is_same_company_question = any(kw in query_lower for kw in [
            'cÃ¹ng cÃ´ng ty', 'same company', 'cÃ¹ng hÃ£ng', 'cÃ¹ng label', 'cÃ¹ng hÃ£ng Ä‘Ä©a',
            'cÃ¹ng cÃ´ng ty hay', 'cÃ¹ng hÃ£ng hay', 'cÃ¹ng cÃ´ng ty khÃ´ng', 'cÃ¹ng hÃ£ng khÃ´ng',
            'cÃ³ cÃ¹ng cÃ´ng ty', 'cÃ³ cÃ¹ng hÃ£ng', 'cÃ³ cÃ¹ng label'
        ])
        
        # Check if this is a "list members" question: "Ai lÃ  thÃ nh viÃªn", "Who are members"
        is_list_members_question = any(kw in query_lower for kw in [
            'ai lÃ  thÃ nh viÃªn', 'who are', 'thÃ nh viÃªn cá»§a', 'members of',
            'thÃ nh viÃªn nhÃ³m', 'thÃ nh viÃªn ban nháº¡c', 'cÃ³ nhá»¯ng thÃ nh viÃªn'
        ]) and 'cÃ³ pháº£i' not in query_lower and 'khÃ´ng' not in query_lower
        
        # ============================================
        # BÆ¯á»šC 2: MULTI-HOP REASONING - SUY LUáº¬N TRÃŠN Äá»’ THá»Š
        # ============================================
        # âœ… Äáº£m báº£o multi-hop reasoning LUÃ”N Ä‘Æ°á»£c sá»­ dá»¥ng khi enabled
        # Multi-hop reasoning sá»­ dá»¥ng Äá»’ THá»Š TRI THá»¨C Ä‘á»ƒ:
        # - TÃ¬m paths giá»¯a entities (BFS/DFS trÃªn graph)
        # - Traverse relationships (MEMBER_OF, MANAGED_BY, etc.)
        # - So sÃ¡nh entities qua nhiá»u hops
        # 
        # Táº¤T Cáº¢ suy luáº­n Ä‘á»u dá»±a trÃªn Äá»’ THá»Š TRI THá»¨C, khÃ´ng pháº£i LLM reasoning
        reasoning_result = None
        if use_multi_hop:
            # âœ… CHIáº¾N LÆ¯á»¢C AN TOÃ€N: Rule-based extraction + KG validation trÆ°á»›c khi reasoning
            # 
            # Æ¯u tiÃªn extract entities cho same_group/same_company/list_members questions báº±ng rule-based
            # VÃ¬ Ä‘Ã¢y lÃ  cÃ¢u há»i factual, cáº§n entities chÃ­nh xÃ¡c Ä‘á»ƒ reasoning Ä‘Ãºng
            if is_same_group_question or is_same_company_question or is_list_members_question:
                # LUÃ”N force extract entities báº±ng rule-based (nhanh, chÃ­nh xÃ¡c)
                # Bá» qua GraphRAG náº¿u khÃ´ng tÃ¬m Ä‘á»§ (GraphRAG cÃ³ thá»ƒ extract sai)
                extracted = self._extract_entities_for_membership(query)
                
                # Vá»›i list_members_question, chá»‰ cáº§n 1 entity (group)
                min_entities = 1 if is_list_members_question else 2
                
                if len(extracted) >= min_entities:
                    # âœ… VALIDATE: Verify táº¥t cáº£ entities vá»›i KG trÆ°á»›c khi reasoning
                    validated_entities = []
                    for e in extracted:
                        entity_data = self.kg.get_entity(e)
                        if entity_data:  # Chá»‰ dÃ¹ng náº¿u validate thÃ nh cÃ´ng
                            validated_entities.append(e)
                    
                    if len(validated_entities) >= min_entities:
                        # CÃ³ Ä‘á»§ entities Ä‘Ã£ validate â†’ dÃ¹ng ngay Ä‘á»ƒ reasoning (nhanh vÃ  chÃ­nh xÃ¡c)
                        # âš ï¸ QUAN TRá»ŒNG: Multi-hop reasoning do Reasoner thá»±c hiá»‡n (graph algorithm)
                        # KHÃ”NG giao cho LLM nhá»
                        reasoning_result = self.reasoner.reason(
                            query,
                            start_entities=validated_entities,
                            max_hops=max_hops
                        )
                        # Update context vá»›i entities Ä‘Ã£ validate
                        for e in validated_entities:
                            if not any(existing['id'].lower() == e.lower() for existing in context['entities']):
                                entity_data = self.kg.get_entity(e)
                                if entity_data:
                                    context['entities'].append({
                                        'id': e,
                                        'type': entity_data.get('label', 'Unknown'),
                                        'score': 0.9  # High score vÃ¬ Ä‘Ã£ verify vá»›i KG
                                    })
                elif len(extracted) == 1:
                    # Chá»‰ cÃ³ 1 entity â†’ váº«n thá»­ reasoning (cÃ³ thá»ƒ tÃ¬m thÃªm tá»« graph)
                    reasoning_result = self.reasoner.reason(
                        query,
                        start_entities=extracted,
                        max_hops=max_hops
                    )
                else:
                    # KhÃ´ng tÃ¬m Ä‘Æ°á»£c entities â†’ reasoner sáº½ tá»± extract
                    reasoning_result = self.reasoner.reason(
                        query,
                        start_entities=[],
                        max_hops=max_hops
                    )
            elif is_membership_question and len(context['entities']) < 2:
                # Membership question: try to extract entities náº¿u GraphRAG khÃ´ng tÃ¬m Ä‘á»§
                extracted = self._extract_entities_for_membership(query)
                if extracted:
                    # Add to context for consistency
                    for e in extracted:
                        if not any(existing['id'].lower() == e.lower() for existing in context['entities']):
                            entity_data = self.kg.get_entity(e)
                            if entity_data:
                                context['entities'].append({
                                    'id': e,
                                    'type': entity_data.get('label', 'Unknown'),
                                    'score': 0.8
                                })
            
            # âœ… LUÃ”N cháº¡y multi-hop reasoning náº¿u chÆ°a cÃ³ result
            # QUAN TRá»ŒNG: Reasoning váº«n do Äá»’ THá»Š thá»±c hiá»‡n (graph traversal, path search)
            # LLM chá»‰ dÃ¹ng Ä‘á»ƒ hiá»ƒu Ä‘áº§u vÃ o (intent, entities, relations) â†’ khÃ´ng lÃ m reasoning
            if reasoning_result is None:
                if context['entities']:
                    entities = [e['id'] for e in context['entities']]
                    
                    # Sá»­ dá»¥ng multi_hop_depth tá»« LLM understanding náº¿u cÃ³
                    # (LLM Ä‘Ã£ detect depth â†’ dÃ¹ng Ä‘á»ƒ optimize graph traversal)
                    detected_depth = max_hops
                    for e in context['entities']:
                        if e.get('multi_hop_depth'):
                            detected_depth = max(detected_depth, e.get('multi_hop_depth', max_hops))
                            break
                    
                    reasoning_result = self.reasoner.reason(
                        query,
                        start_entities=entities,
                        max_hops=detected_depth  # Sá»­ dá»¥ng depth tá»« LLM understanding
                    )
                else:
                    # KhÃ´ng cÃ³ entities â†’ reasoner sáº½ tá»± extract
                    reasoning_result = self.reasoner.reason(
                        query,
                        start_entities=[],
                        max_hops=max_hops
                    )
        
        # ============================================
        # BÆ¯á»šC 3: FORMAT CONTEXT CHO LLM (Tá»« GraphRAG - Knowledge Graph)
        # ============================================
        # âœ… LLM LUÃ”N nháº­n context tá»« GraphRAG (yÃªu cáº§u bÃ i táº­p)
        # Context bao gá»“m:
        # - Entities tá»« Ä‘á»“ thá»‹ (nodes)
        # - Relationships tá»« Ä‘á»“ thá»‹ (edges)
        # - Facts tá»« Ä‘á»“ thá»‹ (triples)
        # - Paths tá»« Ä‘á»“ thá»‹ (multi-hop paths)
        # 
        # Táº¤T Cáº¢ context Ä‘á»u tá»« Äá»’ THá»Š TRI THá»¨C, LLM chá»‰ nháº­n vÃ  format thÃ nh cÃ¢u tráº£ lá»i
        # Giá»›i háº¡n context Ä‘á»ƒ trÃ¡nh vÆ°á»£t quÃ¡ max_length cá»§a model
        # QUAN TRá»ŒNG: Giáº£m context size Ä‘á»ƒ trÃ¡nh LLM bá»‹ nhiá»…u (1969 entities â†’ quÃ¡ nhiá»u!)
        if reasoning_result and reasoning_result.confidence >= 0.6:
            # CÃ³ reasoning result tá»‘t â†’ giáº£m context size (chá»‰ láº¥y essentials)
            formatted_context = self.rag.format_context_for_llm(context, max_tokens=5000)
        else:
            # KhÃ´ng cÃ³ reasoning result hoáº·c confidence tháº¥p â†’ cáº§n nhiá»u context hÆ¡n
            formatted_context = self.rag.format_context_for_llm(context, max_tokens=10000)
        
        # Add reasoning info to context (Multi-hop reasoning results tá»« Ä‘á»“ thá»‹)
        # Reasoning results cÅ©ng Ä‘Æ°á»£c táº¡o tá»« Äá»’ THá»Š TRI THá»¨C (graph traversal)
        if reasoning_result:
            formatted_context += f"\n\n=== Káº¾T QUáº¢ SUY LUáº¬N MULTI-HOP (Tá»« Äá»“ Thá»‹ Tri Thá»©c) ===\n{reasoning_result.explanation}"
            if reasoning_result.steps:
                formatted_context += f"\n\nSá»‘ bÆ°á»›c suy luáº­n: {len(reasoning_result.steps)}-hop"
                for i, step in enumerate(reasoning_result.steps[:3], 1):
                    formatted_context += f"\n  BÆ°á»›c {i}: {step.explanation[:100]}"
        
        # ============================================
        # BÆ¯á»šC 4: GENERATE RESPONSE - LLM Táº O CÃ‚U TRáº¢ Lá»œI Tá»ª CONTEXT
        # ============================================
        # âœ… YÃŠU Cáº¦U BÃ€I Táº¬P: "Lá»±a chá»n má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhá»" â†’ PHáº¢I dÃ¹ng LLM
        # LLM NHáº¬N context tá»« Knowledge Graph (GraphRAG) vÃ  táº¡o cÃ¢u tráº£ lá»i tá»± nhiÃªn
        # 
        # LLM KHÃ”NG tá»± nghÄ© ra thÃ´ng tin - CHá»ˆ format context tá»« Ä‘á»“ thá»‹ thÃ nh cÃ¢u tráº£ lá»i
        # Táº¥t cáº£ facts Ä‘á»u tá»« Äá»’ THá»Š TRI THá»¨C:
        # - Entities: tá»« nodes trong graph
        # - Relationships: tá»« edges trong graph  
        # - Facts: tá»« triples (source, relationship, target) trong graph
        # - Reasoning: tá»« graph traversal (paths, hops)
        
        # If reasoning found a direct answer for membership, same group, or same company, use it (more accurate than LLM)
        # QUAN TRá»ŒNG: Æ¯u tiÃªn reasoning result cho cÃ¡c cÃ¢u há»i factual (trÃ¡nh LLM hallucinate)
        if (is_membership_question or is_same_group_question or is_same_company_question) and reasoning_result and reasoning_result.answer_text:
            # For membership/same group/same company questions, ALWAYS prioritize reasoning result if available
            # Reasoning is more accurate than LLM for factual checks
            if reasoning_result.confidence >= 0.6:  # Lower threshold Ä‘á»ƒ Æ°u tiÃªn reasoning
                # Use reasoning result directly (more accurate, trÃ¡nh LLM hallucinate)
                response = reasoning_result.answer_text
                if reasoning_result.answer_entities:
                    entities_str = ", ".join(reasoning_result.answer_entities[:10])
                    if entities_str and entities_str not in response:
                        response += f"\n\nDanh sÃ¡ch: {entities_str}"
            else:
                # Low confidence, still use LLM but with reasoning context
                if self.llm and use_llm:
                    formatted_context += f"\n\n=== Káº¾T QUáº¢ SUY LUáº¬N ===\n{reasoning_result.answer_text}\n{reasoning_result.explanation}\n\nHÃ£y sá»­ dá»¥ng káº¿t quáº£ suy luáº­n nÃ y Ä‘á»ƒ tráº£ lá»i."
                    history = session.get_history(max_turns=3)
                    response = self.llm.generate(
                        query,
                        context=formatted_context,
                        history=history
                    )
                else:
                    response = reasoning_result.answer_text
        elif self.llm and use_llm:
            # âœ… Sá»¬ Dá»¤NG Small LLM vá»›i context tá»« Knowledge Graph (Ä‘Ãºng yÃªu cáº§u)
            history = session.get_history(max_turns=3)
            response = self.llm.generate(
                query,
                context=formatted_context,  # Context tá»« GraphRAG (Knowledge Graph)
                history=history
            )
        elif reasoning_result and reasoning_result.answer_text:
            # Fallback: Náº¿u LLM khÃ´ng available, dÃ¹ng reasoning result
            # (NhÆ°ng Æ°u tiÃªn dÃ¹ng LLM Ä‘á»ƒ Ä‘Ã¡p á»©ng yÃªu cáº§u bÃ i táº­p)
            response = reasoning_result.answer_text
            if reasoning_result.answer_entities:
                entities_str = ", ".join(reasoning_result.answer_entities[:10])
                if len(reasoning_result.answer_entities) > 10:
                    entities_str += f" vÃ  {len(reasoning_result.answer_entities) - 10} khÃ¡c"
                if entities_str and entities_str not in response:
                    response += f"\n\nDanh sÃ¡ch: {entities_str}"
        elif context['facts']:
            # Fallback: DÃ¹ng facts tá»« Knowledge Graph
            response = "Dá»±a trÃªn Ä‘á»“ thá»‹ tri thá»©c:\n" + "\n".join(f"â€¢ {f}" for f in context['facts'][:5])
        else:
            response = "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan trong Ä‘á»“ thá»‹ tri thá»©c."
                
        # Add assistant message
        session.add_message("assistant", response, {
            "entities": [e['id'] for e in context['entities']],
            "reasoning_type": reasoning_result.reasoning_type.value if reasoning_result else None
        })
        
        # Build response
        result = {
            "session_id": session_id,
            "query": query,
            "response": response,
            "entities_found": len(context['entities']),
            "reasoning_hops": len(reasoning_result.steps) if reasoning_result else 0
        }
        
        if return_details:
            result["context"] = context
            result["reasoning"] = {
                "type": reasoning_result.reasoning_type.value if reasoning_result else None,
                "steps": [
                    {
                        "hop": s.hop_number,
                        "operation": s.operation,
                        "explanation": s.explanation
                    }
                    for s in reasoning_result.steps
                ] if reasoning_result else [],
                "confidence": reasoning_result.confidence if reasoning_result else 0
            }
            result["formatted_context"] = formatted_context
            
        return result
        
    def answer_yes_no(
        self,
        query: str,
        return_details: bool = False
    ) -> Dict:
        """
        Answer a Yes/No question.
        
        Args:
            query: Yes/No question
            return_details: Include detailed info
            
        Returns:
            Answer dictionary
        """
        query_lower = query.lower()
        
        # Get context
        context = self.rag.retrieve_context(query, max_entities=5, max_hops=2)
        formatted_context = self.rag.format_context_for_llm(context)
        
        # Perform reasoning
        entities = [e['id'] for e in context['entities']]
        reasoning_result = self.reasoner.reason(query, entities, max_hops=2)
        
        # Check if reasoning result already has a Yes/No answer
        if reasoning_result and reasoning_result.answer_text:
            answer_text_lower = reasoning_result.answer_text.lower()
            if answer_text_lower.startswith('cÃ³') or 'lÃ  thÃ nh viÃªn' in answer_text_lower:
                return {
                    "query": query,
                    "answer": "CÃ³",
                    "confidence": reasoning_result.confidence,
                    "explanation": reasoning_result.explanation
                }
            elif answer_text_lower.startswith('khÃ´ng') or 'khÃ´ng pháº£i' in answer_text_lower:
                return {
                    "query": query,
                    "answer": "KhÃ´ng",
                    "confidence": reasoning_result.confidence,
                    "explanation": reasoning_result.explanation
                }
        
        # Rule-based answer FIRST (more accurate for knowledge graph queries)
        answer = None
        confidence = 0.0
        
        # Pattern 1: "X cÃ³ pháº£i lÃ  thÃ nh viÃªn cá»§a Y khÃ´ng?" 
        if 'thÃ nh viÃªn' in query_lower or 'member' in query_lower:
            # Find artist and group in context
            artist_entity = None
            group_entity = None
            
            for entity in context['entities']:
                if entity['type'] == 'Artist':
                    artist_entity = entity
                elif entity['type'] == 'Group':
                    group_entity = entity
            
            # If we have both artist and group, check membership directly
            if artist_entity and group_entity:
                artist_name = artist_entity['id']
                group_name = group_entity['id']
                groups = self.kg.get_artist_groups(artist_name)
                
                if group_name in groups:
                    answer = "CÃ³"
                    confidence = 1.0
                else:
                    answer = "KhÃ´ng"
                    confidence = 1.0
            elif artist_entity:
                # Only have artist, check all groups
                artist_name = artist_entity['id']
                groups = self.kg.get_artist_groups(artist_name)
                # Check if any group is mentioned in query or context
                query_groups = [e['id'] for e in context['entities'] if e['type'] == 'Group']
                if query_groups:
                    # Check if artist is member of any mentioned group
                    if any(g in groups for g in query_groups):
                        answer = "CÃ³"
                        confidence = 1.0
                    else:
                        answer = "KhÃ´ng"
                        confidence = 0.9
                else:
                    # No group found, check if group name is in query text
                    for group in groups:
                        if group.lower() in query_lower:
                            answer = "CÃ³"
                            confidence = 1.0
                            break
                    if answer is None:
                        answer = "KhÃ´ng"
                        confidence = 0.8
            else:
                # No artist found
                answer = "KhÃ´ng"
                confidence = 0.7
                
        # Pattern 2: "X thuá»™c cÃ´ng ty Y" (True/False check)
        elif 'thuá»™c cÃ´ng ty' in query_lower or 'thuá»™c company' in query_lower:
            # Extract company name from query (after "thuá»™c cÃ´ng ty")
            for entity in context['entities']:
                if entity['type'] == 'Group':
                    company = self.kg.get_group_company(entity['id'])
                    if company and company.lower() in query_lower:
                        answer = "ÄÃºng"
                        confidence = 1.0
                        break
                    elif company:
                        answer = "Sai"
                        confidence = 0.9
                        break
            if answer is None:
                answer = "Sai"
                confidence = 0.7
                
        # Pattern 3: "X vÃ  Y cÃ³ cÃ¹ng cÃ´ng ty khÃ´ng?"
        elif 'cÃ¹ng cÃ´ng ty' in query_lower or 'same company' in query_lower:
            if len(context['entities']) >= 2:
                result = self.reasoner.check_same_company(
                    context['entities'][0]['id'],
                    context['entities'][1]['id']
                )
                if result.answer_entities:
                    answer = "CÃ³"
                    confidence = 1.0
                else:
                    answer = "KhÃ´ng"
                    confidence = 0.9
                    
        # Fallback: Use reasoning result
        if answer is None:
            answer_text = reasoning_result.answer_text.lower() if reasoning_result else ""
            if any(word in answer_text for word in ['cÃ³', 'Ä‘Ãºng', 'yes', 'thuá»™c', 'lÃ ', 'cÃ¹ng']):
                answer = "CÃ³"
                confidence = reasoning_result.confidence if reasoning_result else 0.6
            elif any(word in answer_text for word in ['khÃ´ng', 'sai', 'no', 'khÃ¡c', 'khÃ´ng rÃµ']):
                answer = "KhÃ´ng"
                confidence = reasoning_result.confidence if reasoning_result else 0.6
            else:
                # Try LLM as last resort
                if self.llm:
                    try:
                        llm_result = self.llm.evaluate_yes_no(query, formatted_context)
                        answer = llm_result['answer']
                        confidence = llm_result['confidence']
                    except:
                        answer = "KhÃ´ng"
                        confidence = 0.5
                else:
                    answer = "KhÃ´ng"
                    confidence = 0.5
                
        result = {
            "query": query,
            "answer": answer,
            "confidence": confidence,
            "explanation": reasoning_result.explanation if reasoning_result else ""
        }
        
        if return_details:
            result["context"] = context
            result["reasoning"] = reasoning_result
            
        return result
        
    def answer_multiple_choice(
        self,
        query: str,
        choices: List[str],
        return_details: bool = False
    ) -> Dict:
        """
        Answer a multiple choice question.
        
        Args:
            query: Question
            choices: List of choices
            return_details: Include detailed info
            
        Returns:
            Answer dictionary
        """
        query_lower = query.lower()
        
        # Get context
        context = self.rag.retrieve_context(query, max_entities=5, max_hops=2)
        formatted_context = self.rag.format_context_for_llm(context)
        
        # Perform reasoning
        entities = [e['id'] for e in context['entities']]
        reasoning_result = self.reasoner.reason(query, entities, max_hops=2)
        
        selected_index = None
        selected_choice = None
        confidence = 0.0
        
        # ============================================
        # SMART ANSWER SELECTION BASED ON QUERY TYPE
        # ============================================
        
        # Pattern 1: "CÃ´ng ty nÃ o quáº£n lÃ½ X?" - find company in choices
        if 'cÃ´ng ty' in query_lower or 'company' in query_lower:
            for entity in context['entities']:
                if entity['type'] == 'Group':
                    company = self.kg.get_group_company(entity['id'])
                    if company:
                        # Find matching choice
                        for i, choice in enumerate(choices):
                            if company.lower() in choice.lower() or choice.lower() in company.lower():
                                selected_index = i
                                selected_choice = choices[i]
                                confidence = 1.0
                                break
                    break
                    
        # Pattern 2: "X thuá»™c nhÃ³m nÃ o?" - find group in choices
        elif 'nhÃ³m nÃ o' in query_lower or 'thuá»™c nhÃ³m' in query_lower:
            for entity in context['entities']:
                if entity['type'] == 'Artist':
                    groups = self.kg.get_artist_groups(entity['id'])
                    for group in groups:
                        for i, choice in enumerate(choices):
                            if group.lower() in choice.lower() or choice.lower() in group.lower():
                                selected_index = i
                                selected_choice = choices[i]
                                confidence = 1.0
                                break
                        if selected_index is not None:
                            break
                    break
                    
        # Pattern 3: "NhÃ³m nÃ o cÃ¹ng cÃ´ng ty vá»›i X?" - find labelmates in choices
        elif 'cÃ¹ng cÃ´ng ty' in query_lower or 'labelmate' in query_lower:
            for entity in context['entities']:
                if entity['type'] == 'Group':
                    labelmates = self.reasoner.get_labelmates(entity['id'])
                    for labelmate in labelmates.answer_entities:
                        for i, choice in enumerate(choices):
                            if labelmate.lower() in choice.lower() or choice.lower() in labelmate.lower():
                                selected_index = i
                                selected_choice = choices[i]
                                confidence = 0.9
                                break
                        if selected_index is not None:
                            break
                    break
        
        # Fallback: Score-based selection using context and reasoning result
        if selected_index is None:
            # Combine context and reasoning for better matching
            search_text = formatted_context.lower()
            if reasoning_result:
                search_text += " " + reasoning_result.answer_text.lower()
                search_text += " " + " ".join(reasoning_result.answer_entities).lower()
            
            scores = []
            for i, choice in enumerate(choices):
                score = 0
                choice_clean = choice.lower().strip()
                
                # Exact match - highest score
                if choice_clean in search_text:
                    score += 10
                    
                # Word matching
                choice_words = [w for w in choice_clean.split() if len(w) > 2]
                for word in choice_words:
                    if word in search_text:
                        score += 2
                        
                # Entity matching
                for entity in context['entities']:
                    if entity['id'].lower() in choice_clean:
                        score += 3
                        
                scores.append(score)
                
            max_score = max(scores) if scores else 0
            if max_score > 0:
                selected_index = scores.index(max_score)
                selected_choice = choices[selected_index]
                confidence = min(max_score / 10, 1.0)
            else:
                # Last resort: try LLM
                if self.llm:
                    try:
                        llm_result = self.llm.evaluate_multiple_choice(query, choices, formatted_context)
                        selected_index = llm_result['selected_index']
                        selected_choice = llm_result['selected_choice']
                        confidence = llm_result['confidence']
                    except:
                        selected_index = 0  # Default to first choice
                        selected_choice = choices[0]
                        confidence = 0.25
                else:
                    selected_index = 0
                    selected_choice = choices[0]
                    confidence = 0.25
                
        result = {
            "query": query,
            "choices": choices,
            "selected_choice": selected_choice,
            "selected_index": selected_index,
            "selected_letter": chr(65 + selected_index) if selected_index is not None else None,
            "confidence": confidence
        }
        
        if return_details:
            result["context"] = context
            result["formatted_context"] = formatted_context
            
        return result
    
    def _extract_entities_for_membership(self, query: str) -> List[str]:
        """
        Extract entities from query for membership questions.
        Tries to find artist and group names even if GraphRAG didn't find them.
        """
        entities = []
        query_lower = query.lower()
        
        # Try to find group names (case-insensitive)
        all_groups = [node for node, data in self.kg.graph.nodes(data=True) 
                     if data.get('label') == 'Group']
        
        # Try to find artist names (case-insensitive)
        all_artists = [node for node, data in self.kg.graph.nodes(data=True) 
                      if data.get('label') == 'Artist']
        
        # Search for group name in query (case-insensitive)
        # Xá»­ lÃ½ variants: "blackpink", "black pink", "BLACKPINK"
        for group in all_groups:
            group_lower = group.lower()
            group_variants = [
                group_lower,
                group_lower.replace('-', ' '),
                group_lower.replace('-', ''),
                group_lower.replace(' ', ''),  # "black pink" â†’ "blackpink"
            ]
            if any(variant in query_lower for variant in group_variants if len(variant) >= 3):
                entities.append(group)
                break
        
        # Search for artist names in query (case-insensitive) - TÃŒM Táº¤T Cáº¢, khÃ´ng chá»‰ 1
        # QUAN TRá»ŒNG: Xá»­ lÃ½ node cÃ³ Ä‘uÃ´i nhÆ° "Lisa (ca sÄ©)", "Jennie (rapper)"
        found_artists = []
        query_words_list = query_lower.split()  # List Ä‘á»ƒ giá»¯ thá»© tá»±
        query_text = query_lower  # Full query text Ä‘á»ƒ check substring
        
        for artist in all_artists:
            artist_lower = artist.lower()
            # Extract base name (khÃ´ng cÃ³ Ä‘uÃ´i)
            base_name = self._normalize_entity_name(artist)
            base_name_lower = base_name.lower()
            
            # Táº¡o variants Ä‘á»ƒ match vá»›i nhiá»u format: "g-dragon", "g dragon", "gdragon", "blackpink"
            base_name_variants = [
                base_name_lower,
                base_name_lower.replace('-', ' '),  # "g-dragon" â†’ "g dragon"
                base_name_lower.replace('-', ''),    # "g-dragon" â†’ "gdragon"
                base_name_lower.replace(' ', ''),    # "black pink" â†’ "blackpink"
            ]
            
            # Method 1: Check náº¿u base name hoáº·c variants lÃ  má»™t tá»« trong query (exact match)
            # VÃ­ dá»¥: query "lisa cÃ³ cÃ¹ng nhÃ³m" â†’ word "lisa" match vá»›i base_name "lisa"
            if any(variant in query_words_list for variant in base_name_variants):
                if artist not in found_artists:
                    found_artists.append(artist)
                    continue
            
            # Method 2: Check náº¿u base name hoáº·c variants xuáº¥t hiá»‡n trong query (substring match)
            # VÃ­ dá»¥: query "jungkook vÃ  lisa" â†’ "jungkook" match vá»›i "Jungkook"
            # QUAN TRá»ŒNG: Xá»­ lÃ½ "g-dragon" vÃ  "blackpink" (lowercase, khÃ´ng space)
            if any(variant in query_text for variant in base_name_variants if len(variant) >= 3):
                if artist not in found_artists:
                    found_artists.append(artist)
                    continue
            
            # Method 3: Check tá»«ng word trong query vá»›i base name vÃ  variants
            for word in query_words_list:
                if len(word) < 3:  # Skip short words
                    continue
                # Exact match vá»›i base name hoáº·c variants
                if word in base_name_variants or word == base_name_lower:
                    if artist not in found_artists:
                        found_artists.append(artist)
                        break
                # Partial match: word lÃ  má»™t pháº§n cá»§a base name hoáº·c ngÆ°á»£c láº¡i
                elif (word in base_name_lower and len(word) >= 3) or (base_name_lower in word and len(base_name_lower) >= 3):
                    if artist not in found_artists:
                        found_artists.append(artist)
                        break
                # Xá»­ lÃ½ tÃªn cÃ³ dáº¥u gáº¡ch ngang: "g-dragon" match vá»›i "g" vÃ  "dragon"
                elif '-' in base_name_lower:
                    base_parts = base_name_lower.split('-')
                    if word in base_parts and len(word) >= 3:
                        # Check xem cÃ³ part khÃ¡c cÅ©ng trong query khÃ´ng
                        other_parts = [p for p in base_parts if p != word]
                        if any(p in query_lower for p in other_parts):
                            if artist not in found_artists:
                                found_artists.append(artist)
                                break
        
        # ThÃªm táº¥t cáº£ artists tÃ¬m Ä‘Æ°á»£c (khÃ´ng chá»‰ 1)
        entities.extend(found_artists)
        
        # Náº¿u chÆ°a tÃ¬m Ä‘á»§, try fuzzy matching vá»›i tá»«ng word
        # QUAN TRá»ŒNG: Chá»‰ match vá»›i artists/groups, khÃ´ng match vá»›i albums/songs (trÃ¡nh sai)
        if len(entities) < 2:
            words = query_lower.split()
            # Filter out common Vietnamese words
            stop_words = {'cÃ³', 'vÃ ', 'cÃ¹ng', 'nhÃ³m', 'nháº¡c', 'khÃ´ng', 'lÃ ', 'thuá»™c', 'cá»§a', 'vá»›i', 'hay', 'hoáº·c'}
            words = [w for w in words if w not in stop_words and len(w) >= 3]
            
            for word in words:
                # Try exact match (case-insensitive) vá»›i artists only (trÃ¡nh match albums/songs)
                for artist in all_artists:
                    base_name = self._normalize_entity_name(artist)
                    base_name_lower = base_name.lower()
                    # Exact match vá»›i base name hoáº·c variants (xá»­ lÃ½ dáº¥u gáº¡ch ngang)
                    base_name_variants = [
                        base_name_lower,
                        base_name_lower.replace('-', ' '),
                        base_name_lower.replace('-', ''),
                        base_name_lower.replace(' ', ''),
                    ]
                    if word in base_name_variants or base_name_lower == word:
                        if artist not in entities:
                            entities.append(artist)
                            break
                    # Xá»­ lÃ½ tÃªn cÃ³ dáº¥u gáº¡ch ngang: "g-dragon" match vá»›i "g" vÃ  "dragon"
                    if '-' in base_name_lower:
                        base_parts = base_name_lower.split('-')
                        if word in base_parts and len(word) >= 3:
                            # Check xem cÃ³ part khÃ¡c cÅ©ng trong query khÃ´ng
                            other_parts = [p for p in base_parts if p != word]
                            if any(p in query_lower for p in other_parts):
                                if artist not in entities:
                                    entities.append(artist)
                                    break
                
                # Try exact match vá»›i groups (cÅ©ng xá»­ lÃ½ variants)
                for group in all_groups:
                    group_lower = group.lower()
                    group_variants = [
                        group_lower,
                        group_lower.replace('-', ' '),
                        group_lower.replace('-', ''),
                        group_lower.replace(' ', ''),
                    ]
                    if word in group_variants or group_lower == word:
                        if group not in entities:
                            entities.append(group)
                            break
                        break
                    # Partial match - word lÃ  má»™t pháº§n cá»§a node name
                    elif word in node_lower and len(word) >= 3:
                        node_data = self.kg.get_entity(node)
                        if node_data and node_data.get('label') in ['Artist', 'Group']:
                            if node not in entities:
                                entities.append(node)
                            break
        
        # Return táº¥t cáº£ entities tÃ¬m Ä‘Æ°á»£c (khÃ´ng giá»›i háº¡n 2)
        return entities[:10]  # Return max 10 entities Ä‘á»ƒ Ä‘áº£m báº£o tÃ¬m Ä‘á»§
    
    def _normalize_entity_name(self, entity_name: str) -> str:
        """
        Normalize entity name báº±ng cÃ¡ch remove suffixes trong parentheses.
        
        VÃ­ dá»¥:
        - "Lisa (ca sÄ©)" â†’ "Lisa"
        - "BLACKPINK (nhÃ³m nháº¡c)" â†’ "BLACKPINK"
        - "BTS (rapper)" â†’ "BTS"
        
        Args:
            entity_name: Entity name cÃ³ thá»ƒ cÃ³ Ä‘uÃ´i
            
        Returns:
            Base name (khÃ´ng cÃ³ Ä‘uÃ´i)
        """
        import re
        # Remove suffixes trong parentheses: (ca sÄ©), (nhÃ³m nháº¡c), (rapper), etc.
        normalized = re.sub(r'\s*\([^)]+\)\s*$', '', entity_name)
        return normalized.strip()
        
    # =========== Specialized Query Methods ===========
    
    def get_group_members(self, group_name: str) -> Dict:
        """Get members of a K-pop group."""
        result = self.reasoner.get_group_members(group_name)
        return {
            "group": group_name,
            "members": result.answer_entities,
            "member_count": len(result.answer_entities),
            "answer": result.answer_text
        }
        
    def get_group_company(self, group_name: str) -> Dict:
        """Get company managing a group."""
        result = self.reasoner.get_company_of_group(group_name)
        return {
            "group": group_name,
            "company": result.answer_entities[0] if result.answer_entities else None,
            "answer": result.answer_text
        }
        
    def check_same_company(self, entity1: str, entity2: str) -> Dict:
        """Check if two entities are under the same company."""
        result = self.reasoner.check_same_company(entity1, entity2)
        return {
            "entity1": entity1,
            "entity2": entity2,
            "same_company": len(result.answer_entities) > 0,
            "common_company": result.answer_entities[0] if result.answer_entities else None,
            "answer": result.answer_text
        }
        
    def get_labelmates(self, entity: str) -> Dict:
        """Get all groups/artists under same company."""
        result = self.reasoner.get_labelmates(entity)
        return {
            "entity": entity,
            "labelmates": result.answer_entities,
            "count": len(result.answer_entities),
            "answer": result.answer_text
        }
        
    def find_path(self, source: str, target: str) -> Dict:
        """Find relationship path between two entities."""
        path = self.kg.find_path(source, target)
        
        if path:
            details = self.kg.get_path_details(path)
            path_str = " â†’ ".join([
                f"{d['entity']}({d['type']})" for d in details
            ])
            return {
                "source": source,
                "target": target,
                "path_found": True,
                "path": path,
                "hops": len(path) - 1,
                "description": path_str
            }
        else:
            return {
                "source": source,
                "target": target,
                "path_found": False,
                "path": [],
                "hops": -1,
                "description": f"KhÃ´ng tÃ¬m tháº¥y Ä‘Æ°á»ng Ä‘i tá»« {source} Ä‘áº¿n {target}"
            }
            
    def get_statistics(self) -> Dict:
        """Get chatbot and knowledge graph statistics."""
        kg_stats = self.kg.get_statistics()
        return {
            "knowledge_graph": kg_stats,
            "active_sessions": len(self.sessions),
            "llm_available": self.llm is not None,
            "embeddings_available": self.rag.embedder is not None
        }


def main():
    """Test the chatbot."""
    print("="*60)
    print("ğŸ¤ K-pop Knowledge Graph Chatbot Demo")
    print("="*60)
    
    # Initialize chatbot
    chatbot = KpopChatbot(
        llm_model="qwen2-0.5b",
        verbose=True
    )
    
    # Print statistics
    print("\nğŸ“Š Statistics:")
    stats = chatbot.get_statistics()
    print(f"  Nodes: {stats['knowledge_graph']['total_nodes']}")
    print(f"  Edges: {stats['knowledge_graph']['total_edges']}")
    print(f"  LLM: {'âœ…' if stats['llm_available'] else 'âŒ'}")
    print(f"  Embeddings: {'âœ…' if stats['embeddings_available'] else 'âŒ'}")
    
    # Test queries
    test_queries = [
        "BTS cÃ³ bao nhiÃªu thÃ nh viÃªn?",
        "CÃ´ng ty nÃ o quáº£n lÃ½ BLACKPINK?",
        "BTS vÃ  SEVENTEEN cÃ³ cÃ¹ng cÃ´ng ty khÃ´ng?",
    ]
    
    print("\n" + "="*60)
    print("ğŸ§ª Running Test Queries")
    print("="*60)
    
    session_id = chatbot.create_session()
    
    for query in test_queries:
        print(f"\nâ“ Query: {query}")
        result = chatbot.chat(query, session_id, return_details=True)
        print(f"ğŸ¤– Response: {result['response']}")
        print(f"ğŸ“ Entities: {result['entities_found']}, Hops: {result['reasoning_hops']}")
        
    # Test specialized queries
    print("\n" + "="*60)
    print("ğŸ§ª Specialized Queries")
    print("="*60)
    
    print("\nğŸ‘¥ BTS Members:")
    result = chatbot.get_group_members("BTS")
    print(f"  {result['answer']}")
    
    print("\nğŸ¢ BTS Company:")
    result = chatbot.get_group_company("BTS")
    print(f"  {result['answer']}")
    
    print("\nğŸ” Same Company Check (BTS vs SEVENTEEN):")
    result = chatbot.check_same_company("BTS", "SEVENTEEN")
    print(f"  {result['answer']}")


if __name__ == "__main__":
    main()

