"""
Main Chatbot Module for K-pop Knowledge Graph

This module integrates all components:
- Knowledge Graph
- GraphRAG
- Multi-hop Reasoning
- Small LLM

Provides a unified interface for the K-pop chatbot.
"""

import json
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from datetime import datetime

# Support running both as a package (streamlit) and as a script (python .../run_chatbot.py)
try:
    from .knowledge_graph import KpopKnowledgeGraph
    from .knowledge_graph_neo4j import KpopKnowledgeGraphNeo4j
    from .graph_rag import GraphRAG
    from .multi_hop_reasoning import MultiHopReasoner, ReasoningResult, ReasoningStep, ReasoningType
    from .small_llm import SmallLLM, get_llm, TRANSFORMERS_AVAILABLE
except ImportError:  # Fallback for no-package context
    from knowledge_graph import KpopKnowledgeGraph
    from knowledge_graph_neo4j import KpopKnowledgeGraphNeo4j
    from graph_rag import GraphRAG
    from multi_hop_reasoning import MultiHopReasoner, ReasoningResult, ReasoningStep, ReasoningType
    from small_llm import SmallLLM, get_llm, TRANSFORMERS_AVAILABLE


@dataclass
class ChatMessage:
    """A single chat message."""
    role: str  # 'user' or 'assistant'
    content: str
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    metadata: Dict = field(default_factory=dict)


@dataclass
class ChatSession:
    """A chat session with history."""
    session_id: str
    messages: List[ChatMessage] = field(default_factory=list)
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    
    def add_message(self, role: str, content: str, metadata: Dict = None):
        """Add a message to the session."""
        self.messages.append(ChatMessage(
            role=role,
            content=content,
            metadata=metadata or {}
        ))
        
    def get_history(self, max_turns: int = 5) -> List[Dict]:
        """Get conversation history for context."""
        history = []
        for msg in self.messages[-max_turns * 2:]:
            history.append({
                "role": msg.role,
                "content": msg.content
            })
        return history


class KpopChatbot:
    """
    K-pop Knowledge Graph Chatbot.
    
    Combines GraphRAG retrieval with multi-hop reasoning
    and small LLM generation for answering K-pop questions.
    """
    
    def __init__(
        self,
        data_path: str = "data/korean_artists_graph_bfs.json",
        llm_model: str = "qwen2-0.5b",
        use_embeddings: bool = True,
        verbose: bool = True
    ):
        """
        Initialize the chatbot.
        
        Args:
            data_path: Path to merged K-pop data
            llm_model: Model key for small LLM
            use_embeddings: Whether to use semantic embeddings
            verbose: Print initialization progress
        """
        self.verbose = verbose
        self.sessions: Dict[str, ChatSession] = {}
        
        # Initialize components
        if verbose:
            print("üîÑ Initializing K-pop Chatbot...")
            
        # 1. Knowledge Graph
        if verbose:
            print("  üìä Loading Knowledge Graph...")
        self.kg = KpopKnowledgeGraph(data_path)
        
        # 2. GraphRAG
        if verbose:
            print("  üîç Initializing GraphRAG...")
        # Pass LLM to GraphRAG ƒë·ªÉ d√πng cho understanding (n·∫øu c√≥)
        # LLM s·∫Ω ƒë∆∞·ª£c load sau, n√™n pass None l√∫c ƒë·∫ßu, s·∫Ω set sau
        self.rag = GraphRAG(
            knowledge_graph=self.kg,
            use_cache=True,
            llm_for_understanding=None  # S·∫Ω set sau khi LLM load xong
        )
        
        # 3. Multi-hop Reasoner
        if verbose:
            print("  üß† Initializing Multi-hop Reasoner...")
        # Pass GraphRAG ƒë·ªÉ reasoner c√≥ th·ªÉ d√πng LLM extract entities khi thi·∫øu
        self.reasoner = MultiHopReasoner(self.kg, graph_rag=self.rag)
        
        # 4. Small LLM (optional)
        self.llm = None
        if llm_model:
            if verbose:
                print(f"  ü§ñ Loading LLM: {llm_model}...")
            try:
                self.llm = get_llm(llm_model)
                # Set LLM cho GraphRAG ƒë·ªÉ d√πng cho understanding
                self.rag.llm_for_understanding = self.llm
            except Exception as e:
                if verbose:
                    print(f"  ‚ö†Ô∏è LLM loading failed: {e}")
                    print("  üí° Using fallback mode (context-based responses)")
                self.llm = None
        else:
            if verbose:
                print("  ü§ñ LLM skipped (graph-only mode)")
            
        if verbose:
            print("‚úÖ Chatbot initialized successfully!")
            
    def create_session(self, session_id: str = None) -> str:
        """Create a new chat session."""
        if session_id is None:
            session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
        self.sessions[session_id] = ChatSession(session_id=session_id)
        return session_id
        
    def get_session(self, session_id: str) -> Optional[ChatSession]:
        """Get an existing session."""
        return self.sessions.get(session_id)
        
    def chat(
        self,
        query: str,
        session_id: str = None,
        use_multi_hop: bool = True,
        max_hops: int = 3,
        return_details: bool = False,
        use_llm: bool = True
    ) -> Dict:
        """
        Process a chat query and return response.
        
        Args:
            query: User's question
            session_id: Session ID for conversation history
            use_multi_hop: Enable multi-hop reasoning
            max_hops: Maximum reasoning hops
            return_details: Include detailed reasoning info
            
        Returns:
            Response dictionary with answer and metadata
        """
        # Get or create session
        if session_id and session_id in self.sessions:
            session = self.sessions[session_id]
        else:
            session_id = self.create_session(session_id)
            session = self.sessions[session_id]
            
        # Add user message
        session.add_message("user", query)
        
        # ============================================
        # B∆Ø·ªöC 1: GRAPHRAG - L·∫§Y CONTEXT T·ª™ ƒê·ªí TH·ªä TRI TH·ª®C
        # ============================================
        # ‚úÖ GraphRAG LU√îN ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ l·∫•y context t·ª´ Knowledge Graph
        # GraphRAG th·ª±c hi·ªán 3 b∆∞·ªõc:
        # 1. Semantic Search: T√¨m node g·∫ßn nh·∫•t b·∫±ng vector search (FAISS + embeddings)
        # 2. Expand Subgraph: T·ª´ node t√¨m ƒë∆∞·ª£c ‚Üí m·ªü r·ªông h√†ng x√≥m 1-2 hop ‚Üí l·∫•y subgraph
        # 3. Build Context: Chuy·ªÉn subgraph ‚Üí text/triples ƒë·ªÉ feed v√†o LLM
        # 
        # T·∫§T C·∫¢ th√¥ng tin ƒë·ªÅu l·∫•y t·ª´ ƒê·ªí TH·ªä TRI TH·ª®C (Knowledge Graph), kh√¥ng ph·∫£i t·ª´ LLM memory
        
        # ============================================
        # B∆Ø·ªöC 1: GRAPHRAG - RETRIEVE CONTEXT (rule-based tr∆∞·ªõc, LLM fallback)
        # ============================================
        # ‚úÖ Rule-based ch·∫°y TR∆Ø·ªöC trong retrieve_context() ‚Üí extract_entities()
        # LLM ch·ªâ ƒë∆∞·ª£c g·ªçi khi rule-based kh√¥ng ƒë·ªß ho·∫∑c kh√¥ng hi·ªÉu
        context = self.rag.retrieve_context(
            query,
            max_entities=5,
            max_hops=max_hops
        )
        
        # 2.5. Check if this is a membership Yes/No question - use reasoning directly
        import re
        query_clean = re.sub(r"[^\w\s\-]", " ", query.lower())
        query_lower = " ".join(query_clean.split())
        
        # ‚úÖ Rule-based intent detection TR∆Ø·ªöC
        is_membership_question = (
            any(kw in query_lower for kw in ['c√≥ ph·∫£i', 'ph·∫£i', 'l√† th√†nh vi√™n', 'is a member', 'belongs to', 'c√≥ th√†nh vi√™n']) and
            any(kw in query_lower for kw in ['th√†nh vi√™n', 'member'])
        )
        
        # Check if this is a "list members" question: "Ai l√† th√†nh vi√™n", "Who are members"
        is_list_members_question = any(kw in query_lower for kw in [
            'ai l√† th√†nh vi√™n', 'who are', 'th√†nh vi√™n c·ªßa', 'members of',
            'th√†nh vi√™n nh√≥m', 'th√†nh vi√™n ban nh·∫°c', 'c√≥ nh·ªØng th√†nh vi√™n'
        ]) and 'c√≥ ph·∫£i' not in query_lower and 'kh√¥ng' not in query_lower
        
        # Check if this is an "artist group" question: "Lisa thu·ªôc nh√≥m nh·∫°c n√†o"
        is_artist_group_question = any(kw in query_lower for kw in [
            'thu·ªôc nh√≥m', 'thu·ªôc nh√≥m nh·∫°c', 'nh√≥m n√†o', 'nh√≥m nh·∫°c n√†o',
            'belongs to group', 'group of', 'nh√≥m c·ªßa'
        ]) and 'c√πng' not in query_lower  # Tr√°nh nh·∫ßm v·ªõi "c√πng nh√≥m"
        
        # Check if this is a "same group" question - use reasoning directly
        is_same_group_question = any(kw in query_lower for kw in [
            'c√πng nh√≥m', 'c√πng nh√≥m nh·∫°c', 'c√πng m·ªôt nh√≥m', 'c√πng m·ªôt nh√≥m nh·∫°c',
            'same group', 'c√πng ban nh·∫°c', 'chung nh√≥m', 'chung nh√≥m nh·∫°c'
        ])
        
        # ‚úÖ LLM FALLBACK: Ch·ªâ g·ªçi LLM khi rule-based kh√¥ng detect ƒë∆∞·ª£c intent
        # V√≠ d·ª•: "c√πng m·ªôt nh√≥m nh·∫°c" c√≥ th·ªÉ kh√¥ng match pattern n·∫øu rule-based miss t·ª´ "m·ªôt"
        llm_intent = None
        if self.rag.llm_for_understanding and not (is_same_group_question or is_artist_group_question or is_membership_question or is_list_members_question):
            # Rule-based kh√¥ng detect ƒë∆∞·ª£c ‚Üí d√πng LLM ƒë·ªÉ hi·ªÉu bi·∫øn th·ªÉ ng√¥n ng·ªØ
            try:
                llm_result = self.rag._extract_entities_with_llm(query)
                if llm_result and len(llm_result) > 0:
                    llm_intent = llm_result[0].get('intent', '')
                    # Update intent flags d·ª±a tr√™n LLM
                    if llm_intent == 'same_group':
                        is_same_group_question = True
                    elif llm_intent == 'membership':
                        if 'nh√≥m' in query_lower:
                            is_artist_group_question = True
                        else:
                            is_membership_question = True
            except Exception as e:
                # N·∫øu LLM fail, gi·ªØ nguy√™n rule-based
                pass
        
        # Check if this is a "same company" question - use reasoning directly
        # M·ªü r·ªông patterns ƒë·ªÉ detect nhi·ªÅu c√°ch h·ªèi h∆°n
        is_same_company_question = any(kw in query_lower for kw in [
            'c√πng c√¥ng ty', 'same company', 'c√πng h√£ng', 'c√πng label', 'c√πng h√£ng ƒëƒ©a',
            'c√πng c√¥ng ty hay', 'c√πng h√£ng hay', 'c√πng c√¥ng ty kh√¥ng', 'c√πng h√£ng kh√¥ng',
            'c√≥ c√πng c√¥ng ty', 'c√≥ c√πng h√£ng', 'c√≥ c√πng label'
        ])
        
        # ========== C√ÅC PATTERN M·ªöI ƒê·ªÇ TR√ÅNH HALLUCINATION ==========
        
        # Pattern: "X thu·ªôc c√¥ng ty n√†o?", "C√¥ng ty n√†o qu·∫£n l√Ω X?", "X l√† ngh·ªá sƒ© c·ªßa c√¥ng ty n√†o?"
        is_find_company_question = (
            ('thu·ªôc c√¥ng ty n√†o' in query_lower) or
            ('c√¥ng ty n√†o' in query_lower and ('qu·∫£n l√Ω' in query_lower or 's·ªü h·ªØu' in query_lower)) or
            ('l√† ngh·ªá sƒ© c·ªßa c√¥ng ty n√†o' in query_lower) or
            ('thu·ªôc h√£ng n√†o' in query_lower) or
            ('thu·ªôc label n√†o' in query_lower) or
            (('nh√≥m nh·∫°c' in query_lower or 'nh√≥m' in query_lower) and 'thu·ªôc' in query_lower and 'c√¥ng ty' in query_lower)
        )
        
        # Pattern: "Ai h√°t b√†i X?", "Ca sƒ© h√°t b√†i X l√† ai?", "B√†i X do ai h√°t?"
        is_who_sings_question = (
            ('ai h√°t' in query_lower and ('b√†i' in query_lower or 'ca kh√∫c' in query_lower)) or
            ('ca sƒ©' in query_lower and 'h√°t b√†i' in query_lower) or
            ('ngh·ªá sƒ©' in query_lower and ('h√°t b√†i' in query_lower or 'th·ªÉ hi·ªán' in query_lower)) or
            (('b√†i h√°t' in query_lower or 'ca kh√∫c' in query_lower) and ('do ai' in query_lower or 'c·ªßa ai' in query_lower)) or
            ('ai th·ªÉ hi·ªán' in query_lower) or
            ('ca sƒ© h√°t' in query_lower and 'l√† ai' in query_lower)
        )
        
        # Pattern: "Album X thu·ªôc nh√≥m n√†o?", "Album X c·ªßa nh√≥m n√†o?"
        is_album_belongs_to_question = (
            ('album' in query_lower) and
            (('thu·ªôc' in query_lower and ('nh√≥m' in query_lower or 'ai' in query_lower)) or
             ('c·ªßa nh√≥m n√†o' in query_lower) or
             ('do nh√≥m n√†o' in query_lower) or
             ('thu·ªôc v·ªÅ nh√≥m' in query_lower) or
             ('thu·ªôc v·ªÅ' in query_lower and 'nh√≥m' in query_lower))
        )
        
        # Pattern: "B√†i h√°t X n·∫±m trong album n√†o?", "B√†i X thu·ªôc album n√†o?"
        is_song_in_which_album_question = (
            (('b√†i h√°t' in query_lower or 'ca kh√∫c' in query_lower or 'b√†i' in query_lower) and
             ('n·∫±m trong album n√†o' in query_lower or 'thu·ªôc album n√†o' in query_lower or 
              'trong album n√†o' in query_lower or '·ªü album n√†o' in query_lower))
        )
        
        # ========== END PATTERN M·ªöI ==========
        
        # B·ªï sung nh·∫≠n d·∫°ng cho c√°c c√¢u h·ªèi ƒëa d·∫°ng trong dataset ƒë√°nh gi√°
        is_genre_question = 'th·ªÉ lo·∫°i' in query_lower or 'genre' in query_lower
        # C√¢u h·ªèi v·ªÅ nƒÉm ho·∫°t ƒë·ªông/ph√°t h√†nh/th√†nh l·∫≠p
        is_year_question = (
            ('nƒÉm' in query_lower) and
            ('ho·∫°t ƒë·ªông' in query_lower or 'ph√°t h√†nh' in query_lower or 'th√†nh l·∫≠p' in query_lower)
        )
        is_song_in_album_question = (
            ('b√†i h√°t' in query_lower and 'album' in query_lower)
            or ('contains' in query_lower and 'released' in query_lower)
        )
        is_company_via_group_question = (
            'c√¥ng ty n√†o qu·∫£n l√Ω' in query_lower
            or ('ƒë∆∞·ª£c qu·∫£n l√Ω b·ªüi' in query_lower and 'nh√≥m' in query_lower)
            or ('qu·∫£n l√Ω' in query_lower and 'nh√≥m' in query_lower)
        )
        is_occupation_question = 'ngh·ªÅ nghi·ªáp' in query_lower or 'occupation' in query_lower
        is_artist_song_question = ('b√†i h√°t' in query_lower and ('tr√¨nh b√†y' in query_lower or 'h√°t' in query_lower))
        is_artist_album_question = ('album' in query_lower and ('ph√°t h√†nh' in query_lower or 'ra m·∫Øt' in query_lower))
        is_artist_genre_question = is_genre_question and ('ngh·ªá sƒ©' in query_lower or 'artist' in query_lower or 'ca sƒ©' in query_lower)
        is_same_occupation_question = is_occupation_question and any(kw in query_lower for kw in ['ai', 'ngh·ªá sƒ©', 'artist'])
        is_album_song_group_question = ('album' in query_lower and 'b√†i h√°t' in query_lower and 'nh√≥m' in query_lower)
        is_three_hop_hint = ('qua' in query_lower and 'r·ªìi' in query_lower) or ('th√¥ng qua' in query_lower and 'sau ƒë√≥' in query_lower)
        # 3-hop ki·ªÉu Song -> Artist -> Group -> Company (t·ª´ b·ªô ƒë√°nh gi√°)
        is_song_company_chain_question = (
            ('b√†i h√°t' in query_lower and ('c√¥ng ty' in query_lower or 'label' in query_lower))
            or '(3-hop)' in query_lower
            or ('qua' in query_lower and 'nh√≥m' in query_lower and 'c√¥ng ty' in query_lower)
        )
        # C√¢u h·ªèi v·ªÅ c√¥ng ty/th·ªÉ lo·∫°i c·ªßa nh√≥m nh·∫°c ƒë√£ th·ªÉ hi·ªán ca kh√∫c X
        is_song_group_company_question = (
            ('b√†i h√°t' in query_lower or 'ca kh√∫c' in query_lower) and
            ('nh√≥m nh·∫°c' in query_lower or 'nh√≥m' in query_lower) and
            ('th·ªÉ hi·ªán' in query_lower or 'tr√¨nh b√†y' in query_lower or 'ƒë√£' in query_lower) and
            ('c√¥ng ty' in query_lower or 'company' in query_lower or 'label' in query_lower or 'h√£ng' in query_lower)
        )
        is_song_group_genre_question = (
            ('b√†i h√°t' in query_lower or 'ca kh√∫c' in query_lower) and
            ('nh√≥m nh·∫°c' in query_lower or 'nh√≥m' in query_lower) and
            ('th·ªÉ hi·ªán' in query_lower or 'tr√¨nh b√†y' in query_lower or 'ƒë√£' in query_lower) and
            ('th·ªÉ lo·∫°i' in query_lower or 'genre' in query_lower or 'd√≤ng nh·∫°c' in query_lower)
        )
        
        # C√¢u h·ªèi 3-hop: Song ‚Üí Artist ‚Üí Group ‚Üí Genre
        is_song_artist_group_genre_question = (
            ('b√†i h√°t' in query_lower or 'ca kh√∫c' in query_lower) and
            ('ca sƒ©' in query_lower or 'ngh·ªá sƒ©' in query_lower or 'artist' in query_lower) and
            ('nh√≥m nh·∫°c' in query_lower or 'nh√≥m' in query_lower) and
            ('th·ªÉ hi·ªán' in query_lower or 'tr√¨nh b√†y' in query_lower or 'c√≥' in query_lower) and
            ('th·ªÉ lo·∫°i' in query_lower or 'genre' in query_lower or 'd√≤ng nh·∫°c' in query_lower)
        )
        
        # C√¢u h·ªèi v·ªÅ th·ªÉ lo·∫°i c·ªßa nh√≥m nh·∫°c ƒë√£ ra m·∫Øt album X (Album ‚Üí Group ‚Üí Genre)
        is_album_group_genre_question = (
            ('album' in query_lower) and
            ('nh√≥m nh·∫°c' in query_lower or 'nh√≥m' in query_lower or 'group' in query_lower) and
            ('ra m·∫Øt' in query_lower or 'ph√°t h√†nh' in query_lower or 'ƒë√£' in query_lower) and
            ('th·ªÉ lo·∫°i' in query_lower or 'genre' in query_lower or 'd√≤ng nh·∫°c' in query_lower)
        )
        
        # C√¢u h·ªèi v·ªÅ ngh·ªÅ nghi·ªáp c·ªßa ca sƒ© ƒë√£ ra m·∫Øt album X (Album ‚Üí Artist ‚Üí Occupation)
        is_album_artist_occupation_question = (
            ('album' in query_lower) and
            ('ca sƒ©' in query_lower or 'ngh·ªá sƒ©' in query_lower or 'artist' in query_lower) and
            ('ra m·∫Øt' in query_lower or 'ph√°t h√†nh' in query_lower or 'ƒë√£' in query_lower) and
            ('ngh·ªÅ nghi·ªáp' in query_lower or 'occupation' in query_lower or 'vai tr√≤' in query_lower)
        )
        
        # X√°c ƒë·ªãnh label k·ª≥ v·ªçng t·ª´ c√¢u h·ªèi ƒë·ªÉ l·ªçc th·ª±c th·ªÉ ƒë√∫ng lo·∫°i
        # QUAN TR·ªåNG: V·ªõi same_group question, KH√îNG include Company ƒë·ªÉ tr√°nh extract sai
        expected_labels = set()
        if is_same_group_question or is_list_members_question or 'nh√≥m' in query_lower or 'ban nh·∫°c' in query_lower:
            expected_labels.add('Group')
        if is_membership_question or 'ngh·ªá sƒ©' in query_lower or 'ca sƒ©' in query_lower or 'artist' in query_lower:
            expected_labels.add('Artist')
        # QUAN TR·ªåNG: Ch·ªâ th√™m Company n·∫øu KH√îNG ph·∫£i same_group question
        # ƒë·ªÉ tr√°nh extract Company entities cho same_group questions
        if (is_same_company_question or is_company_via_group_question or 'c√¥ng ty' in query_lower or 'label' in query_lower or 'h√£ng' in query_lower) \
            and not is_same_group_question:
            expected_labels.add('Company')
        if 'b√†i h√°t' in query_lower or 'song' in query_lower:
            expected_labels.add('Song')
        if 'album' in query_lower:
            expected_labels.add('Album')
        if is_genre_question or 'th·ªÉ lo·∫°i' in query_lower or 'genre' in query_lower:
            expected_labels.add('Genre')
        if is_occupation_question or 'ngh·ªÅ' in query_lower:
            expected_labels.add('Occupation')
        if is_song_company_chain_question:
            expected_labels.update({'Song', 'Artist', 'Group', 'Company'})
        
        # Check if this is a "list members" question: "Ai l√† th√†nh vi√™n", "Who are members"
        is_list_members_question = any(kw in query_lower for kw in [
            'ai l√† th√†nh vi√™n', 'who are', 'th√†nh vi√™n c·ªßa', 'members of',
            'th√†nh vi√™n nh√≥m', 'th√†nh vi√™n ban nh·∫°c', 'c√≥ nh·ªØng th√†nh vi√™n'
        ]) and 'c√≥ ph·∫£i' not in query_lower and 'kh√¥ng' not in query_lower
        
        # ============================================
        # B∆Ø·ªöC 2: MULTI-HOP REASONING - SUY LU·∫¨N TR√äN ƒê·ªí TH·ªä
        # ============================================
        # ‚úÖ ƒê·∫£m b·∫£o multi-hop reasoning LU√îN ƒë∆∞·ª£c s·ª≠ d·ª•ng khi enabled
        # Multi-hop reasoning s·ª≠ d·ª•ng ƒê·ªí TH·ªä TRI TH·ª®C ƒë·ªÉ:
        # - T√¨m paths gi·ªØa entities (BFS/DFS tr√™n graph)
        # - Traverse relationships (MEMBER_OF, MANAGED_BY, etc.)
        # - So s√°nh entities qua nhi·ªÅu hops
        # 
        # T·∫§T C·∫¢ suy lu·∫≠n ƒë·ªÅu d·ª±a tr√™n ƒê·ªí TH·ªä TRI TH·ª®C, kh√¥ng ph·∫£i LLM reasoning
        reasoning_result = None
        if use_multi_hop:
            # ‚úÖ CHI·∫æN L∆Ø·ª¢C AN TO√ÄN: Rule-based extraction + KG validation tr∆∞·ªõc khi reasoning
            # 
            # ∆Øu ti√™n extract entities cho same_group/same_company/list_members questions b·∫±ng rule-based
            # V√¨ ƒë√¢y l√† c√¢u h·ªèi factual, c·∫ßn entities ch√≠nh x√°c ƒë·ªÉ reasoning ƒë√∫ng
            eval_pattern_question = (
                is_same_group_question or
                is_same_company_question or
                is_list_members_question or
                is_genre_question or
                is_song_in_album_question or
                is_company_via_group_question or
                is_occupation_question or
                is_artist_song_question or
                is_artist_album_question or
                is_artist_genre_question or
                is_same_occupation_question or
                is_album_song_group_question or
                is_three_hop_hint or
                is_song_company_chain_question or
                is_song_group_company_question or
                is_song_group_genre_question or
                is_song_artist_group_genre_question or
                is_album_group_genre_question or
                is_album_artist_occupation_question or
                # ========== PATTERN M·ªöI ==========
                is_find_company_question or
                is_who_sings_question or
                is_album_belongs_to_question or
                is_song_in_which_album_question
                # ========== END PATTERN M·ªöI ==========
            )
            
            if is_same_group_question or is_same_company_question or is_list_members_question or is_artist_group_question:
                # ‚úÖ CHI·∫æN L∆Ø·ª¢C HYBRID: Rule-based + LLM understanding
                # 1. Th·ª≠ rule-based tr∆∞·ªõc (nhanh, ch√≠nh x√°c cho t√™n chu·∫©n)
                extracted = self._extract_entities_for_membership(query, expected_labels=expected_labels)
                
                # V·ªõi list_members_question v√† artist_group_question, ch·ªâ c·∫ßn 1 entity
                min_entities = 1 if (is_list_members_question or is_artist_group_question) else 2
                
                # 2. N·∫øu rule-based kh√¥ng ƒë·ªß ‚Üí d√πng LLM understanding (fallback)
                if len(extracted) < min_entities and self.rag.llm_for_understanding:
                    try:
                        # G·ªçi LLM ƒë·ªÉ extract entities
                        llm_entities = self.rag._extract_entities_with_llm(query)
                        # Validate v√† th√™m v√†o extracted
                        for llm_e in llm_entities:
                            entity_id = llm_e.get('text', '')
                            if entity_id and entity_id not in extracted:
                                # Validate v·ªõi KG
                                entity_data = self.kg.get_entity(entity_id)
                                if entity_data:
                                    extracted.append(entity_id)
                                    # Update context
                                    if not any(existing['id'].lower() == entity_id.lower() for existing in context['entities']):
                                        context['entities'].append({
                                            'id': entity_id,
                                            'type': entity_data.get('label', 'Unknown'),
                                            'score': llm_e.get('score', 0.8)
                                        })
                    except Exception as e:
                        # N·∫øu LLM fail, ti·∫øp t·ª•c v·ªõi rule-based
                        pass
                
                if len(extracted) >= min_entities:
                    # ‚úÖ VALIDATE: Verify t·∫•t c·∫£ entities v·ªõi KG tr∆∞·ªõc khi reasoning
                    validated_entities = []
                    for e in extracted:
                        entity_data = self.kg.get_entity(e)
                        if entity_data:  # Ch·ªâ d√πng n·∫øu validate th√†nh c√¥ng
                            validated_entities.append(e)
                    
                    if len(validated_entities) >= min_entities:
                        # C√≥ ƒë·ªß entities ƒë√£ validate ‚Üí d√πng ngay ƒë·ªÉ reasoning (nhanh v√† ch√≠nh x√°c)
                        # ‚ö†Ô∏è QUAN TR·ªåNG: Multi-hop reasoning do Reasoner th·ª±c hi·ªán (graph algorithm)
                        # KH√îNG giao cho LLM nh·ªè
                        reasoning_result = self.reasoner.reason(
                            query,
                            start_entities=validated_entities,
                            max_hops=max_hops
                        )
                        # Update context v·ªõi entities ƒë√£ validate
                        for e in validated_entities:
                            if not any(existing['id'].lower() == e.lower() for existing in context['entities']):
                                entity_data = self.kg.get_entity(e)
                                if entity_data:
                                    context['entities'].append({
                                        'id': e,
                                        'type': entity_data.get('label', 'Unknown'),
                                        'score': 0.9  # High score v√¨ ƒë√£ verify v·ªõi KG
                                    })
                elif len(extracted) == 1 and (is_artist_group_question or is_list_members_question):
                    # Ch·ªâ c√≥ 1 entity v√† ƒë√¢y l√† c√¢u h·ªèi ch·ªâ c·∫ßn 1 entity ‚Üí OK
                    reasoning_result = self.reasoner.reason(
                        query,
                        start_entities=extracted,
                        max_hops=max_hops
                    )
                elif len(extracted) == 1:
                    # Ch·ªâ c√≥ 1 entity ‚Üí v·ªõi same_company/same_group questions, c·∫ßn ƒë·ªß 2
                    if is_same_company_question or is_same_group_question:
                        # Th·ª≠ extract l·∫°i v·ªõi logic m·∫°nh h∆°n
                        # Ho·∫∑c ƒë·ªÉ reasoner t·ª± extract t·ª´ query
                        reasoning_result = self.reasoner.reason(
                            query,
                            start_entities=extracted,  # C√≥ 1 entity, reasoner s·∫Ω extract th√™m
                            max_hops=max_hops
                        )
                        # N·∫øu reasoner v·∫´n kh√¥ng extract ƒë∆∞·ª£c ƒë·ªß 2, s·∫Ω tr·∫£ v·ªÅ l·ªói r√µ r√†ng
                    else:
                        # V·ªõi c√°c c√¢u h·ªèi kh√°c, 1 entity c√≥ th·ªÉ ƒë·ªß
                        reasoning_result = self.reasoner.reason(
                            query,
                            start_entities=extracted,
                            max_hops=max_hops
                        )
                else:
                    # Kh√¥ng t√¨m ƒë∆∞·ª£c entities ‚Üí reasoner s·∫Ω t·ª± extract
                    reasoning_result = self.reasoner.reason(
                        query,
                        start_entities=[],
                        max_hops=max_hops
                    )
            # ========== X·ª¨ L√ù C√ÅC PATTERN FACTUAL M·ªöI ==========
            elif is_find_company_question or is_who_sings_question or is_album_belongs_to_question or is_song_in_which_album_question:
                # ƒê√¢y l√† c√°c c√¢u h·ªèi factual c·∫ßn truy v·∫•n tr·ª±c ti·∫øp t·ª´ Knowledge Graph
                extracted = self._extract_entities_for_membership(query, expected_labels=expected_labels)
                
                if extracted:
                    # Validate entities v·ªõi KG
                    validated_entities = []
                    for e in extracted:
                        entity_data = self.kg.get_entity(e)
                        if entity_data:
                            validated_entities.append(e)
                    
                    if validated_entities:
                        # ========== DIRECT GRAPH QUERY ==========
                        if is_find_company_question:
                            # T√¨m c√¥ng ty qu·∫£n l√Ω entity
                            for entity_id in validated_entities:
                                entity_data = self.kg.get_entity(entity_id)
                                if entity_data:
                                    # Ki·ªÉm tra infobox tr∆∞·ªõc
                                    infobox = entity_data.get('infobox', {})
                                    company_info = infobox.get('H√£ng ƒëƒ©a') or infobox.get('C√¥ng ty') or infobox.get('Label')
                                    if company_info:
                                        reasoning_result = ReasoningResult(
                                            query=query,
                                            reasoning_type=ReasoningType.CHAIN,
                                            steps=[ReasoningStep(hop_number=1, operation='get_company', source_entities=[entity_id], relationship='HAS_COMPANY', target_entities=[company_info], explanation=f"L·∫•y c√¥ng ty t·ª´ infobox c·ªßa {entity_id}")],
                                            answer_entities=[company_info],
                                            answer_text=f"{entity_id} thu·ªôc c√¥ng ty/h√£ng ƒëƒ©a: {company_info}",
                                            confidence=0.95,
                                            explanation=f"T√¨m th·∫•y th√¥ng tin c√¥ng ty trong infobox c·ªßa {entity_id}"
                                        )
                                        break
                                    # N·∫øu kh√¥ng c√≥ trong infobox, t√¨m qua edges MANAGED_BY
                                    neighbors = self.kg.get_neighbors(entity_id)
                                    for neighbor, rel_type in neighbors:
                                        if rel_type == 'MANAGED_BY':
                                            reasoning_result = ReasoningResult(
                                                query=query,
                                                reasoning_type=ReasoningType.CHAIN,
                                                steps=[ReasoningStep(hop_number=1, operation='get_company', source_entities=[entity_id], relationship=rel_type, target_entities=[neighbor], explanation=f"L·∫•y c√¥ng ty t·ª´ edge {rel_type}")],
                                                answer_entities=[neighbor],
                                                answer_text=f"{entity_id} ƒë∆∞·ª£c qu·∫£n l√Ω b·ªüi c√¥ng ty: {neighbor}",
                                                confidence=0.95,
                                                explanation=f"T√¨m th·∫•y quan h·ªá MANAGED_BY t·ª´ {entity_id} ƒë·∫øn {neighbor}"
                                            )
                                            break
                        
                        elif is_who_sings_question:
                            # T√¨m ca sƒ© h√°t b√†i h√°t
                            for entity_id in validated_entities:
                                entity_data = self.kg.get_entity(entity_id)
                                if entity_data and entity_data.get('label') == 'Song':
                                    # T√¨m ai SINGS b√†i n√†y (incoming edge)
                                    # Ho·∫∑c ki·ªÉm tra infobox
                                    infobox = entity_data.get('infobox', {})
                                    artist_info = infobox.get('ƒê∆∞·ª£c th·ª±c hi·ªán b·ªüi') or infobox.get('Ca sƒ©') or infobox.get('Ngh·ªá sƒ©')
                                    if artist_info:
                                        reasoning_result = ReasoningResult(
                                            query=query,
                                            reasoning_type=ReasoningType.CHAIN,
                                            steps=[ReasoningStep(hop_number=1, operation='get_singer', source_entities=[entity_id], relationship='SUNG_BY', target_entities=[artist_info], explanation=f"L·∫•y ca sƒ© t·ª´ infobox c·ªßa {entity_id}")],
                                            answer_entities=[artist_info],
                                            answer_text=f"B√†i h√°t '{entity_id}' ƒë∆∞·ª£c th·ªÉ hi·ªán b·ªüi: {artist_info}",
                                            confidence=0.95,
                                            explanation=f"T√¨m th·∫•y th√¥ng tin ca sƒ© trong infobox"
                                        )
                                        break
                                    # T√¨m qua reverse edges
                                    for src, tgt, edge_type in self.kg.graph.edges(data='type'):
                                        if tgt == entity_id and edge_type == 'SINGS':
                                            reasoning_result = ReasoningResult(
                                                query=query,
                                                reasoning_type=ReasoningType.CHAIN,
                                                steps=[ReasoningStep(hop_number=1, operation='get_singer', source_entities=[src], relationship='SINGS', target_entities=[entity_id], explanation=f"T√¨m ca sƒ© h√°t b√†i {entity_id}")],
                                                answer_entities=[src],
                                                answer_text=f"B√†i h√°t '{entity_id}' ƒë∆∞·ª£c th·ªÉ hi·ªán b·ªüi: {src}",
                                                confidence=0.95,
                                                explanation=f"T√¨m th·∫•y quan h·ªá SINGS t·ª´ {src}"
                                            )
                                            break
                        
                        elif is_album_belongs_to_question:
                            # T√¨m nh√≥m/ngh·ªá sƒ© ra album
                            # ƒê·∫ßu ti√™n, th·ª≠ extract t√™n album t·ª´ query
                            album_name = self._extract_album_name_from_query(query)
                            found_album = False
                            
                            # N·∫øu extract ƒë∆∞·ª£c album name, t√¨m tr·ª±c ti·∫øp
                            if album_name:
                                entity_data = self.kg.get_entity(album_name)
                                if entity_data and entity_data.get('label') == 'Album':
                                    found_album = True
                                    infobox = entity_data.get('infobox', {})
                                    artist_info = infobox.get('ƒê∆∞·ª£c th·ª±c hi·ªán b·ªüi') or infobox.get('Ngh·ªá sƒ©') or infobox.get('Ca sƒ©')
                                    if artist_info:
                                        reasoning_result = ReasoningResult(
                                            query=query,
                                            reasoning_type=ReasoningType.CHAIN,
                                            steps=[ReasoningStep(hop_number=1, operation='get_artist', source_entities=[album_name], relationship='RELEASED_BY', target_entities=[artist_info], explanation=f"L·∫•y ngh·ªá sƒ© t·ª´ infobox c·ªßa {album_name}")],
                                            answer_entities=[artist_info],
                                            answer_text=f"Album '{album_name}' thu·ªôc v·ªÅ: {artist_info}",
                                            confidence=0.95,
                                            explanation=f"T√¨m th·∫•y th√¥ng tin ngh·ªá sƒ© trong infobox"
                                        )
                                    else:
                                        # T√¨m qua edges
                                        for src, tgt, edge_type in self.kg.graph.edges(data='type'):
                                            if tgt == album_name and edge_type == 'RELEASED':
                                                reasoning_result = ReasoningResult(
                                                    query=query,
                                                    reasoning_type=ReasoningType.CHAIN,
                                                    steps=[ReasoningStep(hop_number=1, operation='get_artist', source_entities=[src], relationship='RELEASED', target_entities=[album_name], explanation=f"T√¨m ngh·ªá sƒ© ph√°t h√†nh album {album_name}")],
                                                    answer_entities=[src],
                                                    answer_text=f"Album '{album_name}' thu·ªôc v·ªÅ: {src}",
                                                    confidence=0.95,
                                                    explanation=f"T√¨m th·∫•y quan h·ªá RELEASED t·ª´ {src}"
                                                )
                                                break
                            
                            # N·∫øu kh√¥ng extract ƒë∆∞·ª£c ho·∫∑c kh√¥ng t√¨m th·∫•y, th·ª≠ v·ªõi validated_entities
                            if not found_album:
                                for entity_id in validated_entities:
                                    entity_data = self.kg.get_entity(entity_id)
                                    if entity_data and entity_data.get('label') == 'Album':
                                        found_album = True
                                        infobox = entity_data.get('infobox', {})
                                        artist_info = infobox.get('ƒê∆∞·ª£c th·ª±c hi·ªán b·ªüi') or infobox.get('Ngh·ªá sƒ©') or infobox.get('Ca sƒ©')
                                        if artist_info:
                                            reasoning_result = ReasoningResult(
                                                query=query,
                                                reasoning_type=ReasoningType.CHAIN,
                                                steps=[ReasoningStep(hop_number=1, operation='get_artist', source_entities=[entity_id], relationship='RELEASED_BY', target_entities=[artist_info], explanation=f"L·∫•y ngh·ªá sƒ© t·ª´ infobox c·ªßa {entity_id}")],
                                                answer_entities=[artist_info],
                                                answer_text=f"Album '{entity_id}' thu·ªôc v·ªÅ: {artist_info}",
                                                confidence=0.95,
                                                explanation=f"T√¨m th·∫•y th√¥ng tin ngh·ªá sƒ© trong infobox"
                                            )
                                            break
                                        # T√¨m qua edges
                                        for src, tgt, edge_type in self.kg.graph.edges(data='type'):
                                            if tgt == entity_id and edge_type == 'RELEASED':
                                                reasoning_result = ReasoningResult(
                                                    query=query,
                                                    reasoning_type=ReasoningType.CHAIN,
                                                    steps=[ReasoningStep(hop_number=1, operation='get_artist', source_entities=[src], relationship='RELEASED', target_entities=[entity_id], explanation=f"T√¨m ngh·ªá sƒ© ph√°t h√†nh album {entity_id}")],
                                                    answer_entities=[src],
                                                    answer_text=f"Album '{entity_id}' thu·ªôc v·ªÅ: {src}",
                                                    confidence=0.95,
                                                    explanation=f"T√¨m th·∫•y quan h·ªá RELEASED t·ª´ {src}"
                                                )
                                                break
                            
                            # N·∫øu v·∫´n kh√¥ng t√¨m th·∫•y album ‚Üí tr·∫£ v·ªÅ l·ªói r√µ r√†ng
                            if not found_album and reasoning_result is None:
                                # Extract t√™n album t·ª´ query ƒë·ªÉ b√°o l·ªói ch√≠nh x√°c
                                import re
                                album_match = re.search(r'album\s+["\']?([^"\'?]+)["\']?', query, re.IGNORECASE)
                                album_mentioned = album_match.group(1).strip() if album_match else "ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p"
                                reasoning_result = ReasoningResult(
                                    query=query,
                                    reasoning_type=ReasoningType.CHAIN,
                                    steps=[],
                                    answer_entities=[],
                                    answer_text=f"Kh√¥ng t√¨m th·∫•y album '{album_mentioned}' trong Knowledge Graph. Album n√†y c√≥ th·ªÉ ch∆∞a ƒë∆∞·ª£c thu th·∫≠p trong h·ªá th·ªëng.",
                                    confidence=0.0,
                                    explanation=f"Album '{album_mentioned}' not found in Knowledge Graph"
                                )
                        
                        elif is_song_in_which_album_question:
                            # T√¨m album ch·ª©a b√†i h√°t
                            for entity_id in validated_entities:
                                entity_data = self.kg.get_entity(entity_id)
                                if entity_data and entity_data.get('label') == 'Song':
                                    infobox = entity_data.get('infobox', {})
                                    album_info = infobox.get('T√™n album') or infobox.get('Album') or infobox.get('M√¥ t·∫£ album')
                                    if album_info:
                                        reasoning_result = ReasoningResult(
                                            query=query,
                                            reasoning_type=ReasoningType.CHAIN,
                                            steps=[ReasoningStep(hop_number=1, operation='get_album', source_entities=[entity_id], relationship='IN_ALBUM', target_entities=[album_info], explanation=f"L·∫•y album t·ª´ infobox c·ªßa {entity_id}")],
                                            answer_entities=[album_info],
                                            answer_text=f"B√†i h√°t '{entity_id}' n·∫±m trong album: {album_info}",
                                            confidence=0.95,
                                            explanation=f"T√¨m th·∫•y th√¥ng tin album trong infobox"
                                        )
                                        break
                                    # T√¨m qua edges CONTAINS (album contains song)
                                    for src, tgt, edge_type in self.kg.graph.edges(data='type'):
                                        if tgt == entity_id and edge_type == 'CONTAINS':
                                            reasoning_result = ReasoningResult(
                                                query=query,
                                                reasoning_type=ReasoningType.CHAIN,
                                                steps=[ReasoningStep(hop_number=1, operation='get_album', source_entities=[src], relationship='CONTAINS', target_entities=[entity_id], explanation=f"T√¨m album ch·ª©a b√†i h√°t {entity_id}")],
                                                answer_entities=[src],
                                                answer_text=f"B√†i h√°t '{entity_id}' n·∫±m trong album: {src}",
                                                confidence=0.95,
                                                explanation=f"T√¨m th·∫•y quan h·ªá CONTAINS t·ª´ album {src}"
                                            )
                                            break
                        
                        # N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c k·∫øt qu·∫£, v·∫´n g·ªçi reasoner
                        if reasoning_result is None:
                            reasoning_result = self.reasoner.reason(
                                query,
                                start_entities=validated_entities,
                                max_hops=max_hops
                            )
                else:
                    # Kh√¥ng t√¨m ƒë∆∞·ª£c entity ‚Üí tr·∫£ v·ªÅ l·ªói r√µ r√†ng thay v√¨ ƒë·ªÉ LLM hallucinate
                    reasoning_result = ReasoningResult(
                        query=query,
                        reasoning_type=ReasoningType.CHAIN,
                        steps=[],
                        answer_entities=[],
                        answer_text="Kh√¥ng t√¨m th·∫•y th·ª±c th·ªÉ ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong Knowledge Graph. Vui l√≤ng ki·ªÉm tra l·∫°i t√™n.",
                        confidence=0.0,
                        explanation="Entity not found in Knowledge Graph"
                    )
            # ========== END X·ª¨ L√ù PATTERN M·ªöI ==========
            
            elif (eval_pattern_question or is_artist_group_question) and len(context['entities']) < 2:
                # Membership question: try to extract entities n·∫øu GraphRAG kh√¥ng t√¨m ƒë·ªß
                extracted = self._extract_entities_for_membership(query, expected_labels=expected_labels)
                if extracted:
                    # Add to context for consistency
                    for e in extracted:
                        if not any(existing['id'].lower() == e.lower() for existing in context['entities']):
                            entity_data = self.kg.get_entity(e)
                            if entity_data:
                                context['entities'].append({
                                    'id': e,
                                    'type': entity_data.get('label', 'Unknown'),
                                    'score': 0.8
                                })
            
            # ‚úÖ LU√îN ch·∫°y multi-hop reasoning n·∫øu ch∆∞a c√≥ result
            # QUAN TR·ªåNG: Reasoning v·∫´n do ƒê·ªí TH·ªä th·ª±c hi·ªán (graph traversal, path search)
            # LLM ch·ªâ d√πng ƒë·ªÉ hi·ªÉu ƒë·∫ßu v√†o (intent, entities, relations) ‚Üí kh√¥ng l√†m reasoning
            if reasoning_result is None:
                if context['entities']:
                    entities = [e['id'] for e in context['entities']]
                    
                    # S·ª≠ d·ª•ng multi_hop_depth t·ª´ LLM understanding n·∫øu c√≥
                    # (LLM ƒë√£ detect depth ‚Üí d√πng ƒë·ªÉ optimize graph traversal)
                    detected_depth = max_hops
                    for e in context['entities']:
                        if e.get('multi_hop_depth'):
                            detected_depth = max(detected_depth, e.get('multi_hop_depth', max_hops))
                            break
                    
                    reasoning_result = self.reasoner.reason(
                        query,
                        start_entities=entities,
                        max_hops=detected_depth  # S·ª≠ d·ª•ng depth t·ª´ LLM understanding
                    )
                else:
                    # Kh√¥ng c√≥ entities ‚Üí reasoner s·∫Ω t·ª± extract
                    reasoning_result = self.reasoner.reason(
                        query,
                        start_entities=[],
                        max_hops=max_hops
                    )
        
        # ============================================
        # B∆Ø·ªöC 3: FORMAT CONTEXT CHO LLM (T·ª´ GraphRAG - Knowledge Graph)
        # ============================================
        # ‚úÖ LLM LU√îN nh·∫≠n context t·ª´ GraphRAG (y√™u c·∫ßu b√†i t·∫≠p)
        # Context bao g·ªìm:
        # - Entities t·ª´ ƒë·ªì th·ªã (nodes)
        # - Relationships t·ª´ ƒë·ªì th·ªã (edges)
        # - Facts t·ª´ ƒë·ªì th·ªã (triples)
        # - Paths t·ª´ ƒë·ªì th·ªã (multi-hop paths)
        # 
        # T·∫§T C·∫¢ context ƒë·ªÅu t·ª´ ƒê·ªí TH·ªä TRI TH·ª®C, LLM ch·ªâ nh·∫≠n v√† format th√†nh c√¢u tr·∫£ l·ªùi
        # Gi·ªõi h·∫°n context ƒë·ªÉ tr√°nh v∆∞·ª£t qu√° max_length c·ªßa model
        # QUAN TR·ªåNG: Gi·∫£m context size ƒë·ªÉ tr√°nh LLM b·ªã nhi·ªÖu (1969 entities ‚Üí qu√° nhi·ªÅu!)
        if reasoning_result and reasoning_result.confidence >= 0.6:
            # C√≥ reasoning result t·ªët ‚Üí gi·∫£m context size (ch·ªâ l·∫•y essentials)
            formatted_context = self.rag.format_context_for_llm(context, max_tokens=5000)
        else:
            # Kh√¥ng c√≥ reasoning result ho·∫∑c confidence th·∫•p ‚Üí c·∫ßn nhi·ªÅu context h∆°n
            formatted_context = self.rag.format_context_for_llm(context, max_tokens=10000)
        
        # Add reasoning info to context (Multi-hop reasoning results t·ª´ ƒë·ªì th·ªã)
        # Reasoning results c≈©ng ƒë∆∞·ª£c t·∫°o t·ª´ ƒê·ªí TH·ªä TRI TH·ª®C (graph traversal)
        if reasoning_result:
            formatted_context += f"\n\n=== K·∫æT QU·∫¢ SUY LU·∫¨N MULTI-HOP (T·ª´ ƒê·ªì Th·ªã Tri Th·ª©c) ===\n{reasoning_result.explanation}"
            if reasoning_result.steps:
                formatted_context += f"\n\nS·ªë b∆∞·ªõc suy lu·∫≠n: {len(reasoning_result.steps)}-hop"
                for i, step in enumerate(reasoning_result.steps[:3], 1):
                    formatted_context += f"\n  B∆∞·ªõc {i}: {step.explanation[:100]}"
        
        # ============================================
        # B∆Ø·ªöC 4: GENERATE RESPONSE - LLM T·∫†O C√ÇU TR·∫¢ L·ªúI T·ª™ CONTEXT
        # ============================================
        # ‚úÖ Y√äU C·∫¶U B√ÄI T·∫¨P: "L·ª±a ch·ªçn m·ªôt m√¥ h√¨nh ng√¥n ng·ªØ nh·ªè" ‚Üí PH·∫¢I d√πng LLM
        # LLM NH·∫¨N context t·ª´ Knowledge Graph (GraphRAG) v√† t·∫°o c√¢u tr·∫£ l·ªùi t·ª± nhi√™n
        # 
        # LLM KH√îNG t·ª± nghƒ© ra th√¥ng tin - CH·ªà format context t·ª´ ƒë·ªì th·ªã th√†nh c√¢u tr·∫£ l·ªùi
        # T·∫•t c·∫£ facts ƒë·ªÅu t·ª´ ƒê·ªí TH·ªä TRI TH·ª®C:
        # - Entities: t·ª´ nodes trong graph
        # - Relationships: t·ª´ edges trong graph  
        # - Facts: t·ª´ triples (source, relationship, target) trong graph
        # - Reasoning: t·ª´ graph traversal (paths, hops)
        
        # Nh·∫≠n di·ªán c√¢u h·ªèi gi·ªõi thi·ªáu ƒë·ªÉ th√™m infobox ƒë·∫ßy ƒë·ªß v√†o context
        intro_keywords = ['gi·ªõi thi·ªáu v·ªÅ', 'gi·ªõi thi·ªáu s∆° l∆∞·ª£c v·ªÅ', 'gi·ªõi thi·ªáu ng·∫Øn g·ªçn v·ªÅ']
        is_intro_question = any(kw in query_lower for kw in intro_keywords) or (
            ('l√† ai' in query_lower or 'l√† nh√≥m nh·∫°c n√†o' in query_lower or 'l√† ca sƒ© n√†o' in query_lower)
            and len(context.get('entities', [])) >= 1
        )
        
        # N·∫øu l√† c√¢u h·ªèi gi·ªõi thi·ªáu, th√™m infobox ƒë·∫ßy ƒë·ªß v√†o context
        if is_intro_question and context.get('entities'):
            main_entity_id = context['entities'][0]['id']
            entity_data = self.kg.get_entity(main_entity_id)
            if entity_data:
                infobox = entity_data.get('infobox', {})
                if infobox:
                    # Format infobox ƒë·∫ßy ƒë·ªß th√†nh text ƒë·ªÉ LLM d·ªÖ di·ªÖn ƒë·∫°t
                    infobox_text = f"\n\n=== TH√îNG TIN CHI TI·∫æT V·ªÄ {main_entity_id} (Infobox) ==="
                    for key, value in infobox.items():
                        if value:  # Ch·ªâ hi·ªÉn th·ªã fields c√≥ gi√° tr·ªã
                            infobox_text += f"\n{key}: {value}"
                    formatted_context += infobox_text
        
        # ‚úÖ QUAN TR·ªåNG: ∆ØU TI√äN T·∫§T C·∫¢ REASONING RESULT TR∆Ø·ªöC
        # N·∫øu c√≥ reasoning result v·ªõi answer_text ‚Üí LU√îN d√πng reasoning (tr√°nh LLM hallucination)
        # Ch·ªâ d√πng LLM khi KH√îNG c√≥ reasoning result ho·∫∑c reasoning result kh√¥ng c√≥ answer_text
        use_reasoning_result = (
            reasoning_result is not None and 
            reasoning_result.answer_text is not None and 
            len(reasoning_result.answer_text.strip()) > 0
        )
        
        # Nh·∫≠n di·ªán c√¢u h·ªèi v·ªÅ nƒÉm ho·∫°t ƒë·ªông - c√≥ th·ªÉ d√πng LLM ƒë·ªÉ di·ªÖn ƒë·∫°t l·∫°i t·ª± nhi√™n h∆°n
        # Nh∆∞ng th√¥ng tin v·∫´n t·ª´ KG (infobox v√† graph)
        is_year_question_for_llm = is_year_question and use_reasoning_result
        
        if use_reasoning_result and not is_year_question_for_llm:
            # For membership/same group/same company questions, ALWAYS prioritize reasoning result if available
            # Reasoning is more accurate than LLM for factual checks
            # ‚úÖ QUAN TR·ªåNG: LU√îN d√πng reasoning result tr·ª±c ti·∫øp, KH√îNG qua LLM ƒë·ªÉ tr√°nh hallucination
            response = reasoning_result.answer_text
            if reasoning_result.answer_entities:
                entities_str = ", ".join(reasoning_result.answer_entities[:10])
                if entities_str and entities_str not in response:
                    response += f"\n\nDanh s√°ch: {entities_str}"
            # ‚úÖ B·ªè qua LLM generation cho same_group/same_company/song-group questions ƒë·ªÉ tr√°nh tr·∫£ l·ªùi sai
        elif use_reasoning_result and is_year_question_for_llm:
            # C√¢u h·ªèi v·ªÅ nƒÉm ho·∫°t ƒë·ªông: D√πng LLM ƒë·ªÉ di·ªÖn ƒë·∫°t l·∫°i t·ª± nhi√™n h∆°n
            # Nh∆∞ng th√¥ng tin v·∫´n t·ª´ KG (infobox v√† graph)
            history = session.get_history(max_turns=3)
            
            # Th√™m infobox c·ªßa c√°c entities li√™n quan v√†o context (ch·ªâ l·∫•y th√¥ng tin v·ªÅ nƒÉm)
            year_context = formatted_context
            if reasoning_result.answer_entities:
                for entity_id in reasoning_result.answer_entities[:3]:  # T·ªëi ƒëa 3 entities
                    entity_data = self.kg.get_entity(entity_id)
                    if entity_data:
                        infobox = entity_data.get('infobox', {})
                        if infobox:
                            # Ch·ªâ l·∫•y nƒÉm ho·∫°t ƒë·ªông t·ª´ infobox
                            year_info = infobox.get('NƒÉm ho·∫°t ƒë·ªông') or infobox.get('Ph√°t h√†nh') or infobox.get('NƒÉm th√†nh l·∫≠p')
                            if year_info:
                                entity_display = self.reasoner._normalize_entity_name(entity_id)
                                year_context += f"\n\n=== Th√¥ng tin nƒÉm c·ªßa {entity_display} (t·ª´ Infobox) ===\n"
                                year_context += f"NƒÉm ho·∫°t ƒë·ªông/ph√°t h√†nh/th√†nh l·∫≠p: {year_info}"
            
            # Prompt ƒë·ªÉ LLM di·ªÖn ƒë·∫°t l·∫°i m·ªôt c√°ch t·ª± nhi√™n, CH·ªà v·ªÅ nƒÉm ho·∫°t ƒë·ªông
            llm_query = (
                f"D·ª±a tr√™n th√¥ng tin t·ª´ Knowledge Graph trong CONTEXT b√™n d∆∞·ªõi, "
                f"h√£y tr·∫£ l·ªùi c√¢u h·ªèi sau m·ªôt c√°ch t·ª± nhi√™n v√† m·∫°ch l·∫°c b·∫±ng ti·∫øng Vi·ªát (CH·ªà v·ªÅ nƒÉm ho·∫°t ƒë·ªông/ph√°t h√†nh/th√†nh l·∫≠p): {query}\n\n"
                f"Th√¥ng tin t·ª´ reasoning: {reasoning_result.answer_text}\n\n"
                f"Y√äU C·∫¶U: Ch·ªâ tr·∫£ l·ªùi v·ªÅ nƒÉm ho·∫°t ƒë·ªông/ph√°t h√†nh/th√†nh l·∫≠p, kh√¥ng th√™m th√¥ng tin kh√°c nh∆∞ c√¥ng ty, th·ªÉ lo·∫°i, th√†nh vi√™n, v.v. "
                f"Di·ªÖn ƒë·∫°t l·∫°i m·ªôt c√°ch t·ª± nhi√™n nh∆∞ng gi·ªØ nguy√™n th√¥ng tin v·ªÅ nƒÉm t·ª´ Knowledge Graph."
            )
            
            response = self.llm.generate(
                llm_query,
                context=year_context,
                history=history
            )
        elif self.llm and use_llm:
            # ‚úÖ S·ª¨ D·ª§NG Small LLM v·ªõi context t·ª´ Knowledge Graph (ch·ªâ khi KH√îNG c√≥ reasoning result)
            history = session.get_history(max_turns=3)
            
            llm_query = query
            if is_intro_question and context.get('entities'):
                # L·∫•y entity ch√≠nh t·ª´ context (∆∞u ti√™n entity ƒë·∫ßu ti√™n)
                main_entity = context['entities'][0]['id']
                base_name = main_entity
                try:
                    # D√πng reasoner ƒë·ªÉ normalize t√™n (b·ªè h·∫≠u t·ªë nh∆∞ "(nh√≥m nh·∫°c)", "(ca sƒ©)")
                    base_name = self.reasoner._normalize_entity_name(main_entity)
                except Exception:
                    pass
                
                # Prompt chuy√™n bi·ªát cho gi·ªõi thi·ªáu entity - y√™u c·∫ßu LLM di·ªÖn ƒë·∫°t l·∫°i t·ª´ infobox
                llm_query = (
                    f"H√£y gi·ªõi thi·ªáu v·ªÅ th·ª±c th·ªÉ K-pop '{base_name}' b·∫±ng ti·∫øng Vi·ªát (2-4 c√¢u). "
                    f"S·ª≠ d·ª•ng th√¥ng tin t·ª´ ph·∫ßn 'Infobox' trong CONTEXT b√™n d∆∞·ªõi, di·ªÖn ƒë·∫°t l·∫°i m·ªôt c√°ch t·ª± nhi√™n, "
                    f"kh√¥ng ch·ªâ li·ªát k√™ c√°c tr∆∞·ªùng th√¥ng tin. N·∫øu c√≥ th√¥ng tin v·ªÅ nƒÉm ho·∫°t ƒë·ªông, th√†nh vi√™n, c√¥ng ty, th·ªÉ lo·∫°i, "
                    f"h√£y k·∫øt h·ª£p ch√∫ng th√†nh m·ªôt ƒëo·∫°n vƒÉn m·∫°ch l·∫°c. C√¢u h·ªèi g·ªëc: {query}"
                )
            
            response = self.llm.generate(
                llm_query,
                context=formatted_context,  # Context t·ª´ GraphRAG (Knowledge Graph) + infobox ƒë·∫ßy ƒë·ªß n·∫øu l√† c√¢u h·ªèi gi·ªõi thi·ªáu
                history=history
            )
        elif context['facts']:
            # Fallback: D√πng facts t·ª´ Knowledge Graph
            response = "D·ª±a tr√™n ƒë·ªì th·ªã tri th·ª©c:\n" + "\n".join(f"‚Ä¢ {f}" for f in context['facts'][:5])
        else:
            response = "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong ƒë·ªì th·ªã tri th·ª©c."
                
        # Add assistant message
        session.add_message("assistant", response, {
            "entities": [e['id'] for e in context['entities']],
            "reasoning_type": reasoning_result.reasoning_type.value if reasoning_result else None
        })
        
        # Build response
        result = {
            "session_id": session_id,
            "query": query,
            "response": response,
            "entities_found": len(context['entities']),
            "reasoning_hops": len(reasoning_result.steps) if reasoning_result else 0
        }
        
        if return_details:
            result["context"] = context
            result["reasoning"] = {
                "type": reasoning_result.reasoning_type.value if reasoning_result else None,
                "steps": [
                    {
                        "hop": s.hop_number,
                        "operation": s.operation,
                        "explanation": s.explanation
                    }
                    for s in reasoning_result.steps
                ] if reasoning_result else [],
                "confidence": reasoning_result.confidence if reasoning_result else 0
            }
            result["formatted_context"] = formatted_context
            
        return result
        
    def _resolve_pronouns(self, query: str, context: Dict) -> str:
        """
        Resolve pronouns like "nh√≥m ƒë√≥", "nh√≥m n√†y", "c√¥ng ty ƒë√≥" to actual entity names.
        
        Args:
            query: Original query
            context: Context with extracted entities
            
        Returns:
            Query with pronouns resolved
        """
        import re
        
        resolved_query = query
        entities = context.get('entities', [])
        
        if not entities:
            return resolved_query
        
        # Find the most recently mentioned entity of each type
        groups = [e for e in entities if self.kg.get_entity_type(e['id']) == 'Group']
        companies = [e for e in entities if self.kg.get_entity_type(e['id']) == 'Company']
        artists = [e for e in entities if self.kg.get_entity_type(e['id']) == 'Artist']
        
        # Also extract from query text directly (for cases like "Tiffany (nh√≥m Girls' Generation-TTS)")
        # Extract group names mentioned in parentheses
        group_pattern = r'\(nh√≥m\s+([^)]+)\)'
        for match in re.finditer(group_pattern, query, re.IGNORECASE):
            group_name = match.group(1).strip()
            # Try to find this group in KG
            group_entity = self.kg.get_entity(group_name)
            if group_entity:
                if not any(e['id'] == group_name for e in groups):
                    groups.append({'id': group_name, 'type': 'Group'})
        
        # Resolve "nh√≥m ƒë√≥", "nh√≥m n√†y"
        if groups:
            latest_group = groups[-1]['id']  # Most recent group
            resolved_query = re.sub(
                r'\b(nh√≥m|group)\s+(ƒë√≥|n√†y|kia)\b',
                latest_group,
                resolved_query,
                flags=re.IGNORECASE
            )
        
        # Resolve "c√¥ng ty ƒë√≥", "c√¥ng ty n√†y"
        if companies:
            latest_company = companies[-1]['id']  # Most recent company
            resolved_query = re.sub(
                r'\b(c√¥ng ty|company)\s+(ƒë√≥|n√†y|kia)\b',
                latest_company,
                resolved_query,
                flags=re.IGNORECASE
            )
        
        return resolved_query
    
    def _normalize_company(self, company_id: str) -> str:
        """
        Normalize company id/name for robust matching.
        Handles common aliases / case / spacing.
        """
        if not company_id:
            return ""
        
        cid = company_id.strip()
        # Remove prefix if present
        cid = cid.replace("Company_", "")
        cid_lower = cid.lower()
        
        alias_map = {
            # Big 4
            "yg entertainment": ["yg", "yg ent", "yg entertainment", "company_yg entertainment", "yg-ent"],
            "jyp entertainment": ["jyp", "jyp ent", "jyp entertainment", "company_jyp entertainment", "j.y.p"],
            "sm entertainment": ["sm", "sm ent", "sm entertainment", "company_sm entertainment"],
            "hybe": ["hybe", "hybe corporation", "big hit", "big hit entertainment", "bighit", "company_hybe", "company_big hit entertainment"],
            "big hit entertainment": ["big hit", "bighit", "hybe", "hybe corporation", "company_big hit entertainment"],

            # Mid/other
            "cube entertainment": ["cube", "cube ent", "company_cube", "company_cube entertainment"],
            "woollim entertainment": ["woollim", "woollim ent", "company_woollim entertainment"],
            "stone music entertainment": ["stone music", "stone", "company_stone music", "company_stone music entertainment"],
            "ist entertainment": ["ist", "play m", "fave", "company_ist entertainment", "company_play m", "company_fave"],
            "core contents media": ["mbk", "mbk entertainment", "core contents media", "company_core contents media", "company_mbk entertainment"],
            "mbk entertainment": ["mbk", "mbk ent", "mbk entertainment", "company_mbk entertainment", "core contents media"],
            "source music": ["source music", "company_source music", "source-music"],
            "pledis entertainment": ["pledis", "pledis ent", "company_pledis entertainment"],
            "starship entertainment": ["starship", "company_starship entertainment"],
            "fnc entertainment": ["fnc", "company_fnc entertainment"],
            "ymc entertainment": ["ymc", "company_ymc", "company_ymc entertainment", "ymc ent"],
            "emi music japan": ["emi", "emi music japan", "company_emi music japan"],
            "loen entertainment": ["loen", "kakao m", "kakao entertainment", "company_loen entertainment", "company_kakao m"],
            "dsp media": ["dsp", "company_dsp media", "dspmedia"],
            "ist": ["ist", "company_ist"],
            "woollim": ["woollim", "company_woollim"],
            "stone music": ["stone music", "company_stone music"],
            "yuehua entertainment": ["yuehua", "company_yuehua", "company_yuehua entertainment"],
            "wm entertainment": ["wm", "company_wm entertainment"],
        }
        
        for norm, aliases in alias_map.items():
            if cid_lower == norm:
                return norm
            if cid_lower in aliases:
                return norm
        return cid_lower

    def _company_matches(self, company_a: str, company_b: str) -> bool:
        """
        Flexible company matching using alias normalization.
        """
        if not company_a or not company_b:
            return False
        norm_a = self._normalize_company(company_a)
        norm_b = self._normalize_company(company_b)
        if norm_a == norm_b:
            return True
        # substring check after normalization
        return norm_a in norm_b or norm_b in norm_a

    def answer_yes_no(
        self,
        query: str,
        return_details: bool = False,
        max_hops_override: int = None
    ) -> Dict:
        """
        Answer a Yes/No question.
        
        Args:
            query: Yes/No question
            return_details: Include detailed info
            
        Returns:
            Answer dictionary
        """
        try:
            query_lower = query.lower()
            
            # Get context
            context = self.rag.retrieve_context(query, max_entities=5, max_hops=max_hops_override or 3)
            
            # Resolve pronouns BEFORE reasoning
            resolved_query = self._resolve_pronouns(query, context)
            if resolved_query != query:
                # Re-retrieve context with resolved query for better entity extraction
                context = self.rag.retrieve_context(resolved_query, max_entities=5, max_hops=max_hops_override or 3)
                query_lower = resolved_query.lower()
            
            formatted_context = self.rag.format_context_for_llm(context)
            
            # Perform reasoning
            entities = [e['id'] for e in context['entities']]
            reasoning_result = self.reasoner.reason(query, entities, max_hops=max_hops_override or 3)
        except Exception as e:
            # Error handling - return a safe default
            return {
                "query": query,
                "answer": "Kh√¥ng",
                "confidence": 0.0,
                "explanation": f"Error during processing: {str(e)}"
            }
        
        # Check if reasoning result already has a Yes/No answer
        if reasoning_result and reasoning_result.answer_text:
            answer_text_lower = reasoning_result.answer_text.lower()
            if answer_text_lower.startswith('c√≥') or 'l√† th√†nh vi√™n' in answer_text_lower:
                return {
                    "query": query,
                    "answer": "C√≥",
                    "confidence": reasoning_result.confidence,
                    "explanation": reasoning_result.explanation
                }
            elif answer_text_lower.startswith('kh√¥ng') or 'kh√¥ng ph·∫£i' in answer_text_lower:
                return {
                    "query": query,
                    "answer": "Kh√¥ng",
                    "confidence": reasoning_result.confidence,
                    "explanation": reasoning_result.explanation
                }
        
        # Rule-based answer FIRST (more accurate for knowledge graph queries)
        answer = None
        confidence = 0.0
        
        # ============================================
        # QUAN TR·ªåNG: Th·ª© t·ª± pattern matching
        # ∆Øu ti√™n pattern ƒë∆°n gi·∫£n (1-hop) tr∆∞·ªõc pattern ph·ª©c t·∫°p (2-hop, 3-hop)
        # ƒê·ªÉ tr√°nh conflict v√† ƒë·∫£m b·∫£o 1-hop questions ƒë∆∞·ª£c x·ª≠ l√Ω ƒë√∫ng
        # ============================================
        
        # Pattern 1: "X c√≥ ph·∫£i l√† th√†nh vi√™n c·ªßa Y kh√¥ng?" 
        if 'th√†nh vi√™n' in query_lower or 'member' in query_lower:
            # Find artist and group in context
            artist_entity = None
            group_entity = None
            
            for entity in context['entities']:
                if entity['type'] == 'Artist':
                    artist_entity = entity
                elif entity['type'] == 'Group':
                    group_entity = entity
            
            # If we have both artist and group, check membership directly
            if artist_entity and group_entity:
                artist_name = artist_entity['id']
                group_name = group_entity['id']
                groups = self.kg.get_artist_groups(artist_name)
                
                if group_name in groups:
                    answer = "C√≥"
                    confidence = 1.0
                else:
                    answer = "Kh√¥ng"
                    confidence = 1.0
            elif artist_entity:
                # Only have artist, check all groups
                artist_name = artist_entity['id']
                groups = self.kg.get_artist_groups(artist_name)
                # Check if any group is mentioned in query or context
                query_groups = [e['id'] for e in context['entities'] if e['type'] == 'Group']
                if query_groups:
                    # Check if artist is member of any mentioned group
                    if any(g in groups for g in query_groups):
                        answer = "C√≥"
                        confidence = 1.0
                    else:
                        answer = "Kh√¥ng"
                        confidence = 0.9
                else:
                    # No group found, check if group name is in query text
                    for group in groups:
                        if group.lower() in query_lower:
                            answer = "C√≥"
                            confidence = 1.0
                            break
                    if answer is None:
                        answer = "Kh√¥ng"
                        confidence = 0.8
            else:
                # No artist found
                answer = "Kh√¥ng"
                confidence = 0.7
                
        # Pattern 2: "X thu·ªôc c√¥ng ty Y" ho·∫∑c "nh√≥m ƒë√≥ thu·ªôc c√¥ng ty Y" (True/False check)
        # QUAN TR·ªåNG: Ch·ªâ match khi KH√îNG c√≥ "c√πng c√¥ng ty" ho·∫∑c "v√†" (ƒë·ªÉ tr√°nh conflict v·ªõi Pattern 3)
        # Include: "thu·ªôc c√¥ng ty", "do ... qu·∫£n l√Ω", "ƒë∆∞·ª£c qu·∫£n l√Ω b·ªüi"
        elif (('thu·ªôc c√¥ng ty' in query_lower or 'thu·ªôc company' in query_lower or 
               ('do' in query_lower and 'qu·∫£n l√Ω' in query_lower) or
               'ƒë∆∞·ª£c qu·∫£n l√Ω b·ªüi' in query_lower)) \
             and 'v√†' not in query_lower \
             and 'c√πng c√¥ng ty' not in query_lower \
             and 'chung c√¥ng ty' not in query_lower \
             and 'ƒë·ªÅu' not in query_lower:
            # Extract company name from query
            import re
            company_match = re.search(r'(?:company_|c√¥ng ty\s+)([\w\s]+)', query_lower)
            query_company = None
            if company_match:
                    query_company = 'Company_' + company_match.group(1).strip()
            
            # Try to find company entity
            if not query_company:
                for entity in context['entities']:
                    if self.kg.get_entity_type(entity['id']) == 'Company':
                        query_company = entity['id']
                        break
            
            entity_found = False
            matched_entity = None
            
            # X·ª≠ l√Ω c·∫£ Artist v√† Group - ∆∞u ti√™n Group n·∫øu c√≥ "nh√≥m" trong query
            entities_to_check = context['entities']
            
            # N·∫øu query c√≥ "nh√≥m ƒë√≥" ho·∫∑c group mention, ∆∞u ti√™n check groups
            if 'nh√≥m' in query_lower:
                entities_to_check = [e for e in entities_to_check if self.kg.get_entity_type(e['id']) == 'Group'] or entities_to_check
            
            for entity in entities_to_check:
                entity_id = entity['id']
                entity_type = self.kg.get_entity_type(entity_id) or entity.get('type', 'Unknown')
                
                # L·∫•y c√¥ng ty c·ªßa entity
                companies = set()
                if entity_type == 'Group':
                    company = self.kg.get_group_company(entity_id)
                    if company:
                        companies.add(company)
                    # Also get all companies
                    companies.update(self.kg.get_group_companies(entity_id))
                elif entity_type == 'Artist':
                    # Artist c√≥ th·ªÉ thu·ªôc c√¥ng ty qua Group ho·∫∑c tr·ª±c ti·∫øp
                    companies.update(self.kg.get_artist_companies(entity_id))
                    # Th·ª≠ qua Group
                    groups = self.kg.get_artist_groups(entity_id)
                    for group in groups:
                        companies.update(self.kg.get_group_companies(group))
                
                # Ki·ªÉm tra c√¥ng ty c√≥ trong query kh√¥ng
                if companies and query_company:
                    entity_found = True
                    # Normalize company names for comparison
                    query_company_norm = query_company.lower().replace('company_', '').strip()
                    for comp in companies:
                        comp_norm = comp.lower().replace('company_', '').strip()
                        # Check exact match or substring
                        if self._company_matches(comp, query_company):
                            answer = "ƒê√∫ng"
                            confidence = 1.0
                            matched_entity = entity_id
                            break
                    
                    if answer == "ƒê√∫ng":
                        break
                    
                    # N·∫øu ƒë√£ check nh∆∞ng kh√¥ng match
                    if not matched_entity:
                        answer = "Sai"
                        confidence = 0.9
                        matched_entity = entity_id
            
            if not entity_found:
                # Kh√¥ng t√¨m th·∫•y entity ho·∫∑c entity kh√¥ng c√≥ c√¥ng ty
                answer = "Sai"
                confidence = 0.7
                
        # Pattern 2b: "X v√† Y thu·ªôc c√πng c√¥ng ty qu·∫£n l√Ω" (True/False check - two entities)
        # Ch·ªâ x·ª≠ l√Ω c√¢u kh·∫≥ng ƒë·ªãnh, kh√¥ng ph·∫£i c√¢u h·ªèi yes/no
        elif ('thu·ªôc c√πng c√¥ng ty' in query_lower or ('thu·ªôc' in query_lower and 'c√πng c√¥ng ty' in query_lower)) \
             and 'c√≥' not in query_lower and 'kh√¥ng' not in query_lower:
            # Ensure we have at least two entities
            if len(context['entities']) < 2:
                extracted = self._extract_entities_for_membership(
                    query,
                    expected_labels={'Artist', 'Group', 'Company'}
                )
                for ent in extracted:
                    if not any(e['id'] == ent for e in context['entities']):
                        ent_type = self.kg.get_entity_type(ent) or 'Unknown'
                        context['entities'].append({'id': ent, 'type': ent_type})
            
            if len(context['entities']) >= 2:
                # Th·ª≠ T·∫§T C·∫¢ c·∫∑p entity (Artist-Artist, Artist-Group, Group-Group)
                found_match = False
                for i in range(len(context['entities'])):
                    if found_match:
                        break
                    for j in range(i + 1, len(context['entities'])):
                        a = context['entities'][i]['id']
                        b = context['entities'][j]['id']
                        a_type = self.kg.get_entity_type(a) or context['entities'][i].get('type', 'Unknown')
                        b_type = self.kg.get_entity_type(b) or context['entities'][j].get('type', 'Unknown')
                        
                        # L·∫•y c√¥ng ty c·ªßa c·∫£ hai entity (x·ª≠ l√Ω c·∫£ Artist v√† Group)
                        companies_a = set()
                        if a_type == 'Artist':
                            companies_a.update(self.kg.get_artist_companies(a))
                            # Th√™m c√¥ng ty qua Group
                            for group in self.kg.get_artist_groups(a):
                                group_companies = self.kg.get_group_companies(group)
                                companies_a.update(group_companies)
                        elif a_type == 'Group':
                            companies_a.update(self.kg.get_group_companies(a))
                        elif a_type == 'Company':
                            companies_a.add(a)
                        
                        companies_b = set()
                        if b_type == 'Artist':
                            companies_b.update(self.kg.get_artist_companies(b))
                            # Th√™m c√¥ng ty qua Group
                            for group in self.kg.get_artist_groups(b):
                                group_companies = self.kg.get_group_companies(group)
                                companies_b.update(group_companies)
                        elif b_type == 'Group':
                            companies_b.update(self.kg.get_group_companies(b))
                        elif b_type == 'Company':
                            companies_b.add(b)
                        
                        # Ki·ªÉm tra giao t·∫≠p c√¥ng ty (d√πng alias matching)
                        if companies_a and companies_b:
                            matched = False
                            for ca in companies_a:
                                for cb in companies_b:
                                    if self._company_matches(ca, cb):
                                        matched = True
                                        break
                                if matched:
                                    break
                            if matched:
                                answer = "ƒê√∫ng"
                                confidence = 0.95
                                found_match = True
                                break
                if not found_match:
                    answer = "Sai"
                    confidence = 0.9
            else:
                answer = "Sai"
                confidence = 0.7

        # Pattern 3a: "X ƒë·ªÅu tr·ª±c thu·ªôc Company_Y" ho·∫∑c "X v√† Y ƒë·ªÅu tr·ª±c thu·ªôc Company_Z"
        elif 'ƒë·ªÅu tr·ª±c thu·ªôc' in query_lower:
            # Extract company name from query
            import re
            company_match = re.search(r'(?:company_|c√¥ng ty\s+)([\w\s]+)', query_lower)
            query_company = None
            if company_match:
                query_company = 'Company_' + company_match.group(1).strip()
            
            # Find company entity
            if not query_company:
                for entity in context['entities']:
                    if self.kg.get_entity_type(entity['id']) == 'Company':
                        query_company = entity['id']
                        break
            
            if query_company:
                # Check all entities (Artist or Group) belong to this company
                all_belong = True
                entities_to_check = [e for e in context['entities'] if self.kg.get_entity_type(e['id']) in ['Artist', 'Group']]
                
                if not entities_to_check:
                    # Try to extract more entities
                    extracted = self._extract_entities_for_membership(
                        query,
                        expected_labels={'Artist', 'Group'}
                    )
                    for ent in extracted:
                        entities_to_check.append({'id': ent, 'type': self.kg.get_entity_type(ent) or 'Unknown'})
                
                for entity in entities_to_check:
                    entity_id = entity['id']
                    entity_type = self.kg.get_entity_type(entity_id) or entity.get('type', 'Unknown')
                    
                    companies = set()
                    if entity_type == 'Artist':
                        companies.update(self.kg.get_artist_companies(entity_id))
                        for group in self.kg.get_artist_groups(entity_id):
                            companies.update(self.kg.get_group_companies(group))
                    elif entity_type == 'Group':
                        companies.update(self.kg.get_group_companies(entity_id))
                    
                    found = False
                    for comp in companies:
                        if self._company_matches(comp, query_company):
                            found = True
                            break
                    if not found:
                        all_belong = False
                        break
                
                answer = "C√≥" if all_belong else "Kh√¥ng"
                confidence = 0.95
            else:
                answer = "Kh√¥ng"
                confidence = 0.7
        
        # Pattern 3b: "X ƒë·ªÅu thu·ªôc nh√≥m Y" ho·∫∑c "X v√† Y ƒë·ªÅu thu·ªôc nh√≥m Z"
        elif ('ƒë·ªÅu thu·ªôc nh√≥m' in query_lower or 'ƒë·ªÅu l√† th√†nh vi√™n' in query_lower) and 'c√πng' not in query_lower:
            # Extract group name from query
            group_mentioned = None
            for entity in context['entities']:
                if self.kg.get_entity_type(entity['id']) == 'Group':
                    group_mentioned = entity['id']
                    break
            
            # If no group found in entities, try to extract from query text
            if not group_mentioned:
                # Look for group names in query
                all_groups = self.kg.get_entities_by_type('Group')
                for group in all_groups:
                    if group.lower() in query_lower:
                        group_mentioned = group
                        break
            
            if group_mentioned:
                # Check all artists in context are members of this group
                all_in_group = True
                for entity in context['entities']:
                    if self.kg.get_entity_type(entity['id']) == 'Artist':
                        groups = self.kg.get_artist_groups(entity['id'])
                        if group_mentioned not in groups:
                            all_in_group = False
                            break
                
                answer = "C√≥" if all_in_group else "Kh√¥ng"
                confidence = 0.95
            else:
                answer = "Kh√¥ng"
                confidence = 0.7

        # Pattern 4: "X v√† Y c√≥ c√πng nh√≥m kh√¥ng?" ho·∫∑c "X c√≥ chung nh√≥m v·ªõi Y kh√¥ng?" (same group)
        elif ('c√πng nh√≥m' in query_lower or 'same group' in query_lower or 'c√πng nh√≥m nh·∫°c' in query_lower or 'chung nh√≥m' in query_lower):
            # Ensure we have at least two entities
            if len(context['entities']) < 2:
                extracted = self._extract_entities_for_membership(
                    query,
                    expected_labels={'Artist', 'Group'}
                )
                for ent in extracted:
                    if not any(e['id'] == ent for e in context['entities']):
                        ent_type = self.kg.get_entity_type(ent) or 'Unknown'
                        context['entities'].append({'id': ent, 'type': ent_type})
            
            if len(context['entities']) >= 2:
                # Th·ª≠ T·∫§T C·∫¢ c·∫∑p entity (Artist-Artist, Artist-Group, Group-Group)
                found_match = False
                for i in range(len(context['entities'])):
                    if found_match:
                        break
                    for j in range(i + 1, len(context['entities'])):
                        a = context['entities'][i]['id']
                        b = context['entities'][j]['id']
                        a_type = self.kg.get_entity_type(a) or context['entities'][i].get('type', 'Unknown')
                        b_type = self.kg.get_entity_type(b) or context['entities'][j].get('type', 'Unknown')
                        
                        # L·∫•y nh√≥m c·ªßa c·∫£ hai entity
                        groups_a = set()
                        if a_type == 'Artist':
                            groups_a.update(self.kg.get_artist_groups(a))
                        elif a_type == 'Group':
                            groups_a.add(a)  # Group ch√≠nh n√≥
                        
                        groups_b = set()
                        if b_type == 'Artist':
                            groups_b.update(self.kg.get_artist_groups(b))
                        elif b_type == 'Group':
                            groups_b.add(b)  # Group ch√≠nh n√≥
                        
                        # Ki·ªÉm tra giao t·∫≠p nh√≥m
                        if groups_a and groups_b and groups_a.intersection(groups_b):
                            answer = "C√≥"
                            confidence = 0.95
                            found_match = True
                            break
                if not found_match:
                    answer = "Kh√¥ng"
                    confidence = 0.9
            else:
                answer = "Kh√¥ng"
                confidence = 0.7
                
        # Ensure we have at least two entities for same-company checks (SAU khi ƒë√£ x·ª≠ l√Ω same-group)
        # QUAN TR·ªåNG: Ch·ªâ extract Company entities n·∫øu l√† same-company question, KH√îNG extract cho same-group
        if (('c√πng c√¥ng ty' in query_lower or 'same company' in query_lower or 'thu·ªôc c√πng c√¥ng ty' in query_lower)
            and ('c√πng nh√≥m' not in query_lower and 'same group' not in query_lower and 'c√πng nh√≥m nh·∫°c' not in query_lower)) \
            and len(context['entities']) < 2:
            extracted = self._extract_entities_for_membership(
                query,
                expected_labels={'Artist', 'Group', 'Company'}
            )
            for ent in extracted:
                if not any(e['id'] == ent for e in context['entities']):
                    context['entities'].append({'id': ent, 'type': self.kg.get_entity_type(ent) or 'Unknown'})
        
        # Pattern 3: "X v√† Y c√≥ c√πng c√¥ng ty kh√¥ng?" ho·∫∑c "X c√≥ chung c√¥ng ty v·ªõi Y kh√¥ng?" (Yes/No question)
        # Ch·ªâ x·ª≠ l√Ω c√¢u h·ªèi yes/no, kh√¥ng ph·∫£i c√¢u kh·∫≥ng ƒë·ªãnh true/false
        # L∆∞u √Ω: "c√≥ chung c√¥ng ty v·ªõi" c√≥ th·ªÉ c√≥ negation, c·∫ßn ki·ªÉm tra k·ªπ
        # Patterns: "c√πng c√¥ng ty", "c√πng thu·ªôc m·ªôt c√¥ng ty", "chung c√¥ng ty v·ªõi", "ƒë·ªìng c√¥ng ty", "same company"
        # QUAN TR·ªåNG: Ch·ªâ match khi c√≥ "v√†" ho·∫∑c "v·ªõi" (2 entities) ƒë·ªÉ tr√°nh conflict v·ªõi Pattern 2
        elif (('c√πng c√¥ng ty' in query_lower or 'c√πng thu·ªôc m·ªôt c√¥ng ty' in query_lower or
               'same company' in query_lower or 'chung c√¥ng ty' in query_lower or 'ƒë·ªìng c√¥ng ty' in query_lower) \
             and ('c√≥' in query_lower or 'kh√¥ng' in query_lower or 'ch·ª©' in query_lower or 'ph·∫£i kh√¥ng' in query_lower) \
             and ('v√†' in query_lower or 'v·ªõi' in query_lower or len(context['entities']) >= 2)) \
             and 'thu·ªôc c√πng c√¥ng ty' not in query_lower:
            if len(context['entities']) >= 2:
                # Th·ª≠ T·∫§T C·∫¢ c·∫∑p entity (Artist-Artist, Artist-Group, Group-Group)
                found_match = False
                for i in range(len(context['entities'])):
                    if found_match:
                        break
                    for j in range(i + 1, len(context['entities'])):
                        a = context['entities'][i]['id']
                        b = context['entities'][j]['id']
                        a_type = self.kg.get_entity_type(a) or context['entities'][i].get('type', 'Unknown')
                        b_type = self.kg.get_entity_type(b) or context['entities'][j].get('type', 'Unknown')
                        
                        # D√πng reasoner tr∆∞·ªõc (n·∫øu c√≥)
                        try:
                            result = self.reasoner.check_same_company(a, b)
                            if result.answer_entities:
                                answer = "C√≥"
                                confidence = 1.0
                                found_match = True
                                break
                        except:
                            pass
                        
                        # Fallback: Th·ª≠ giao t·∫≠p c√¥ng ty (x·ª≠ l√Ω c·∫£ Artist v√† Group)
                        companies_a = set()
                        if a_type == 'Artist':
                            companies_a.update(self.kg.get_artist_companies(a))
                            # Th√™m c√¥ng ty qua Group
                            for group in self.kg.get_artist_groups(a):
                                group_companies = self.kg.get_group_companies(group)
                                companies_a.update(group_companies)
                        elif a_type == 'Group':
                            companies_a.update(self.kg.get_group_companies(a))
                        elif a_type == 'Company':
                            companies_a.add(a)
                        
                        companies_b = set()
                        if b_type == 'Artist':
                            companies_b.update(self.kg.get_artist_companies(b))
                            # Th√™m c√¥ng ty qua Group
                            for group in self.kg.get_artist_groups(b):
                                group_companies = self.kg.get_group_companies(group)
                                companies_b.update(group_companies)
                        elif b_type == 'Group':
                            companies_b.update(self.kg.get_group_companies(b))
                        elif b_type == 'Company':
                            companies_b.add(b)
                        
                        # Ki·ªÉm tra giao t·∫≠p c√¥ng ty
                        if companies_a and companies_b and companies_a.intersection(companies_b):
                            answer = "C√≥"
                            confidence = 0.95
                            found_match = True
                            break
                if not found_match:
                    answer = "Kh√¥ng"
                    confidence = 0.9
                    
        # Pattern 3a: "X ƒë·ªÅu tr·ª±c thu·ªôc Company_Y" ho·∫∑c "X v√† Y ƒë·ªÅu tr·ª±c thu·ªôc Company_Z"
        # QUAN TR·ªåNG: Ch·ªâ match khi c√≥ "ƒë·ªÅu tr·ª±c thu·ªôc" (kh√¥ng ph·∫£i ch·ªâ "company")
        elif 'ƒë·ªÅu tr·ª±c thu·ªôc' in query_lower:
            # Extract company name from query
            import re
            company_match = re.search(r'(?:company_|c√¥ng ty\s+)([\w\s]+)', query_lower)
            query_company = None
            if company_match:
                query_company = 'Company_' + company_match.group(1).strip()
            
            # Find company entity
            if not query_company:
                for entity in context['entities']:
                    if self.kg.get_entity_type(entity['id']) == 'Company':
                        query_company = entity['id']
                        break
            
            if query_company:
                # Check all entities (Artist or Group) belong to this company
                all_belong = True
                entities_to_check = [e for e in context['entities'] if self.kg.get_entity_type(e['id']) in ['Artist', 'Group']]
                
                if not entities_to_check:
                    # Try to extract more entities
                    extracted = self._extract_entities_for_membership(
                        query,
                        expected_labels={'Artist', 'Group'}
                    )
                    for ent in extracted:
                        entities_to_check.append({'id': ent, 'type': self.kg.get_entity_type(ent) or 'Unknown'})
                
                for entity in entities_to_check:
                    entity_id = entity['id']
                    entity_type = self.kg.get_entity_type(entity_id) or entity.get('type', 'Unknown')
                    
                    companies = set()
                    if entity_type == 'Artist':
                        companies.update(self.kg.get_artist_companies(entity_id))
                        for group in self.kg.get_artist_groups(entity_id):
                            companies.update(self.kg.get_group_companies(group))
                    elif entity_type == 'Group':
                        companies.update(self.kg.get_group_companies(entity_id))
                    
                    # Normalize company names for comparison
                    query_company_norm = query_company.lower().replace('company_', '').strip()
                    found = False
                    for comp in companies:
                        comp_norm = comp.lower().replace('company_', '').strip()
                        if query_company_norm == comp_norm or query_company_norm in comp_norm or comp_norm in query_company_norm:
                            found = True
                            break
                        if comp.lower() == query_company.lower():
                            found = True
                            break
                    
                    if not found:
                        all_belong = False
                        break
                
                answer = "C√≥" if all_belong else "Kh√¥ng"
                confidence = 0.95
            else:
                answer = "Kh√¥ng"
                confidence = 0.7
        
        # Pattern 3b: "X ƒë·ªÅu thu·ªôc nh√≥m Y" ho·∫∑c "X v√† Y ƒë·ªÅu thu·ªôc nh√≥m Z"
        elif ('ƒë·ªÅu thu·ªôc nh√≥m' in query_lower or 'ƒë·ªÅu l√† th√†nh vi√™n' in query_lower) and 'c√πng' not in query_lower:
            # Extract group name from query
            group_mentioned = None
            for entity in context['entities']:
                if self.kg.get_entity_type(entity['id']) == 'Group':
                    group_mentioned = entity['id']
                    break
            
            # If no group found in entities, try to extract from query text
            if not group_mentioned:
                # Look for group names in query
                all_groups = self.kg.get_entities_by_type('Group')
                for group in all_groups:
                    if group.lower() in query_lower:
                        group_mentioned = group
                        break
            
            if group_mentioned:
                # Check all artists in context are members of this group
                all_in_group = True
                for entity in context['entities']:
                    if self.kg.get_entity_type(entity['id']) == 'Artist':
                        groups = self.kg.get_artist_groups(entity['id'])
                        if group_mentioned not in groups:
                            all_in_group = False
                            break
                
                answer = "C√≥" if all_in_group else "Kh√¥ng"
                confidence = 0.95
            else:
                answer = "Kh√¥ng"
                confidence = 0.7
        
        # Pattern 4: "X v√† Y c√≥ c√πng nh√≥m kh√¥ng?" ho·∫∑c "X c√≥ chung nh√≥m v·ªõi Y kh√¥ng?" (same group)
        elif ('c√πng nh√≥m' in query_lower or 'same group' in query_lower or 'c√πng nh√≥m nh·∫°c' in query_lower or 'chung nh√≥m' in query_lower):
            # Ensure we have at least two entities
            if len(context['entities']) < 2:
                extracted = self._extract_entities_for_membership(
                    query,
                    expected_labels={'Artist', 'Group'}
                )
                for ent in extracted:
                    if not any(e['id'] == ent for e in context['entities']):
                        ent_type = self.kg.get_entity_type(ent) or 'Unknown'
                        context['entities'].append({'id': ent, 'type': ent_type})
            
            if len(context['entities']) >= 2:
                # Th·ª≠ T·∫§T C·∫¢ c·∫∑p entity (Artist-Artist, Artist-Group, Group-Group)
                found_match = False
                for i in range(len(context['entities'])):
                    if found_match:
                        break
                    for j in range(i + 1, len(context['entities'])):
                        a = context['entities'][i]['id']
                        b = context['entities'][j]['id']
                        a_type = self.kg.get_entity_type(a) or context['entities'][i].get('type', 'Unknown')
                        b_type = self.kg.get_entity_type(b) or context['entities'][j].get('type', 'Unknown')
                        
                        # L·∫•y nh√≥m c·ªßa c·∫£ hai entity
                        groups_a = set()
                        if a_type == 'Artist':
                            groups_a.update(self.kg.get_artist_groups(a))
                        elif a_type == 'Group':
                            groups_a.add(a)  # Group ch√≠nh n√≥
                        
                        groups_b = set()
                        if b_type == 'Artist':
                            groups_b.update(self.kg.get_artist_groups(b))
                        elif b_type == 'Group':
                            groups_b.add(b)  # Group ch√≠nh n√≥
                        
                        # Ki·ªÉm tra giao t·∫≠p nh√≥m
                        if groups_a and groups_b and groups_a.intersection(groups_b):
                            answer = "C√≥"
                            confidence = 0.95
                            found_match = True
                            break
                if not found_match:
                    answer = "Kh√¥ng"
                    confidence = 0.9
            else:
                answer = "Kh√¥ng"
                confidence = 0.7
        
        # Fallback: Use reasoning result
        if answer is None:
            answer_text = reasoning_result.answer_text.lower() if reasoning_result else ""
            if any(word in answer_text for word in ['c√≥', 'ƒë√∫ng', 'yes', 'thu·ªôc', 'l√†', 'c√πng']):
                answer = "C√≥"
                confidence = reasoning_result.confidence if reasoning_result else 0.6
            elif any(word in answer_text for word in ['kh√¥ng', 'sai', 'no', 'kh√°c', 'kh√¥ng r√µ']):
                answer = "Kh√¥ng"
                confidence = reasoning_result.confidence if reasoning_result else 0.6
            else:
                # Try LLM as last resort
                if self.llm:
                    try:
                        llm_result = self.llm.evaluate_yes_no(query, formatted_context)
                        answer = llm_result['answer']
                        confidence = llm_result['confidence']
                    except:
                        answer = "Kh√¥ng"
                        confidence = 0.5
                else:
                    answer = "Kh√¥ng"
                    confidence = 0.5
                
        result = {
            "query": query,
            "answer": answer,
            "confidence": confidence,
            "explanation": reasoning_result.explanation if reasoning_result else ""
        }
        
        if return_details:
            result["context"] = context
            result["reasoning"] = reasoning_result
            
        return result
        
    def answer_multiple_choice(
        self,
        query: str,
        choices: List[str],
        return_details: bool = False,
        max_hops_override: int = None
    ) -> Dict:
        """
        Answer a multiple choice question.
        
        Args:
            query: Question
            choices: List of choices
            return_details: Include detailed info
            
        Returns:
            Answer dictionary
        """
        query_lower = query.lower()
        
        # Resolve pronouns BEFORE context retrieval (for MC questions with "nh√≥m ƒë√≥", "nh√≥m n√†y")
        context_pre = self.rag.retrieve_context(query, max_entities=3, max_hops=1)  # Quick initial retrieval
        resolved_query = self._resolve_pronouns(query, context_pre)
        query_to_use = resolved_query if resolved_query != query else query
        query_lower = query_to_use.lower()
        
        # Get context with resolved query
        context = self.rag.retrieve_context(query_to_use, max_entities=5, max_hops=max_hops_override or 3)
        formatted_context = self.rag.format_context_for_llm(context)
        
        # Perform reasoning
        entities = [e['id'] for e in context['entities']]
        reasoning_result = self.reasoner.reason(query, entities, max_hops=max_hops_override or 3)
        
        selected_index = None
        selected_choice = None
        confidence = 0.0
        
        # ============================================
        # SMART ANSWER SELECTION BASED ON QUERY TYPE
        # ============================================
        
        # Pattern 1: "C√¥ng ty n√†o qu·∫£n l√Ω X?" ho·∫∑c "X thu·ªôc h√£ng n√†o?" - find company in choices
        if 'c√¥ng ty' in query_lower or 'company' in query_lower or 'h√£ng n√†o' in query_lower:
            for entity in context['entities']:
                if entity['type'] == 'Group':
                    company = self.kg.get_group_company(entity['id'])
                    if company:
                        # Find matching choice
                        for i, choice in enumerate(choices):
                            if company.lower() in choice.lower() or choice.lower() in company.lower():
                                selected_index = i
                                selected_choice = choices[i]
                                confidence = 1.0
                                break
                    break
                    
        # Pattern 2: "X thu·ªôc nh√≥m n√†o?" - find group in choices
        elif 'nh√≥m n√†o' in query_lower or 'thu·ªôc nh√≥m' in query_lower:
            for entity in context['entities']:
                if entity['type'] == 'Artist':
                    groups = self.kg.get_artist_groups(entity['id'])
                    for group in groups:
                        for i, choice in enumerate(choices):
                            if group.lower() in choice.lower() or choice.lower() in group.lower():
                                selected_index = i
                                selected_choice = choices[i]
                                confidence = 1.0
                                break
                        if selected_index is not None:
                            break
                    break
                    
        # Pattern 3: "Nh√≥m n√†o c√πng c√¥ng ty v·ªõi X?" ho·∫∑c "Nh√≥m n√†o l√† ƒë·ªìng c√¥ng ty v·ªõi X?" ho·∫∑c "Nh√≥m n√†o gi·ªëng X?"
        elif 'c√πng c√¥ng ty' in query_lower or 'ƒë·ªìng c√¥ng ty' in query_lower or 'labelmate' in query_lower or ('gi·ªëng' in query_lower and 'nh√≥m n√†o' in query_lower):
            # Find the reference group/entity
            ref_entity = None
            for entity in context['entities']:
                if entity['type'] == 'Group':
                    ref_entity = entity['id']
                    break
            
            # If no group found but "gi·ªëng X" pattern, try to extract
            if not ref_entity and 'gi·ªëng' in query_lower:
                # Extract entity name before "gi·ªëng"
                import re
                match = re.search(r'gi·ªëng\s+([^?]+)', query_lower)
                if match:
                    entity_name = match.group(1).strip()
                    # Try to find group with this name
                    all_groups = self.kg.get_entities_by_type('Group')
                    for group in all_groups:
                        if entity_name.lower() in group.lower() or group.lower() in entity_name.lower():
                            ref_entity = group
                            break
            
            if ref_entity:
                # Get labelmates (groups v·ªõi c√πng c√¥ng ty)
                labelmates = self.reasoner.get_labelmates(ref_entity)
                labelmate_set = set(labelmates.answer_entities) if hasattr(labelmates, 'answer_entities') else set()
                
                # B·ªï sung: d√πng alias matching tr√™n c√¥ng ty
                ref_companies = self.kg.get_group_companies(ref_entity)
                if ref_companies:
                    all_groups = self.kg.get_entities_by_type('Group')
                    for group in all_groups:
                        if group != ref_entity:
                            group_companies = self.kg.get_group_companies(group)
                            for rc in ref_companies:
                                for gc in group_companies:
                                    if self._company_matches(rc, gc):
                                        labelmate_set.add(group)
                                        break
                
                # Th·ª≠ match tr·ª±c ti·∫øp v·ªõi c√°c l·ª±a ch·ªçn
                for i, choice in enumerate(choices):
                    choice_lower = choice.lower()
                    # N·∫øu labelmate_set ƒë√£ c√≥
                    for lm in labelmate_set:
                        if lm.lower() in choice_lower or choice_lower in lm.lower():
                            selected_index = i
                            selected_choice = choices[i]
                            confidence = 0.9
                            break
                    if selected_index is not None:
                        break
                
                # N·∫øu v·∫´n ch∆∞a match, th·ª≠ so c√¥ng ty gi·ªØa l·ª±a ch·ªçn v√† ref_entity
                if selected_index is None and ref_companies:
                    # t√¨m entity id t·ª´ text choice n·∫øu c√≥
                    all_groups = self.kg.get_entities_by_type('Group')
                    for i, choice in enumerate(choices):
                        for g in all_groups:
                            if g.lower() == choice.lower() or g.lower() in choice_lower or choice_lower in g.lower():
                                g_companies = self.kg.get_group_companies(g)
                                matched = False
                                for rc in ref_companies:
                                    for gc in g_companies:
                                        if self._company_matches(rc, gc):
                                            matched = True
                                            break
                                    if matched:
                                        break
                                if matched:
                                    selected_index = i
                                    selected_choice = choices[i]
                                    confidence = 0.85
                                    break
                        if selected_index is not None:
                            break
        
        # Fallback: Score-based selection using context and reasoning result
        if selected_index is None:
            # Combine context and reasoning for better matching
            search_text = formatted_context.lower()
            if reasoning_result:
                search_text += " " + reasoning_result.answer_text.lower()
                search_text += " " + " ".join(reasoning_result.answer_entities).lower()
            
            scores = []
            for i, choice in enumerate(choices):
                score = 0
                choice_clean = choice.lower().strip()
                
                # Exact match - highest score
                if choice_clean in search_text:
                    score += 10
                    
                # Word matching
                choice_words = [w for w in choice_clean.split() if len(w) > 2]
                for word in choice_words:
                    if word in search_text:
                        score += 2
                        
                # Entity matching
                for entity in context['entities']:
                    if entity['id'].lower() in choice_clean:
                        score += 3
                        
                scores.append(score)
                
            max_score = max(scores) if scores else 0
            if max_score > 0:
                selected_index = scores.index(max_score)
                selected_choice = choices[selected_index]
                confidence = min(max_score / 10, 1.0)
            else:
                # Last resort: try LLM
                if self.llm:
                    try:
                        llm_result = self.llm.evaluate_multiple_choice(query, choices, formatted_context)
                        selected_index = llm_result['selected_index']
                        selected_choice = llm_result['selected_choice']
                        confidence = llm_result['confidence']
                    except:
                        selected_index = 0  # Default to first choice
                        selected_choice = choices[0]
                        confidence = 0.25
                else:
                    selected_index = 0
                    selected_choice = choices[0]
                    confidence = 0.25
                
        result = {
            "query": query,
            "choices": choices,
            "selected_choice": selected_choice,
            "selected_index": selected_index,
            "selected_letter": chr(65 + selected_index) if selected_index is not None else None,
            "confidence": confidence
        }
        
        if return_details:
            result["context"] = context
            result["formatted_context"] = formatted_context
            
        return result
    
    def _extract_album_name_from_query(self, query: str) -> Optional[str]:
        """
        Extract album name from query for album-related questions.
        Returns the album name if found in Knowledge Graph, None otherwise.
        """
        import re
        
        # Pattern ƒë·ªÉ extract t√™n album t·ª´ query
        patterns = [
            r'album\s+["\']([^"\']+)["\']',  # Album "Name" ho·∫∑c Album 'Name'
            r'album\s+"([^"]+)"',  # Album "Name"
            r"album\s+'([^']+)'",  # Album 'Name'
            r'album\s+([A-Z][^?.,]+?)(?:\s+thu·ªôc|\s+c·ªßa|\s+do|\s+l√†)',  # Album Name thu·ªôc/c·ªßa/do/l√†
            r'album\s+(.+?)\s+thu·ªôc',  # Album ... thu·ªôc
        ]
        
        for pattern in patterns:
            match = re.search(pattern, query, re.IGNORECASE)
            if match:
                album_name = match.group(1).strip()
                # Th·ª≠ t√¨m trong KG v·ªõi c√°c bi·∫øn th·ªÉ
                variants = [
                    album_name,
                    f"{album_name} (album)",
                    album_name.replace(":", " -"),
                    album_name.replace(" - ", ": "),
                ]
                for variant in variants:
                    if self.kg.get_entity(variant):
                        return variant
                # Kh√¥ng t√¨m th·∫•y exact match, tr·∫£ v·ªÅ t√™n g·ªëc ƒë·ªÉ b√°o l·ªói
                return None
        
        return None
    
    def _extract_entities_for_membership(self, query: str, expected_labels: Optional[set] = None) -> List[str]:
        """
        Extract entities from query for membership questions.
        Tries to find artist and group names even if GraphRAG didn't find them.
        
        expected_labels: t·∫≠p label ∆∞u ti√™n (Artist, Group, Company, Song, Album, Genre, Occupation)
        N·∫øu provided, ch·ªâ gi·ªØ th·ª±c th·ªÉ c√≥ label trong t·∫≠p n√†y (ƒë·ªÉ gi·∫£m nhi·ªÖu).
        """
        # ƒê·∫£m b·∫£o c√≥ s·∫µn map bi·∫øn th·ªÉ t·ª´ graph
        self._ensure_entity_variant_map()
        variant_map = self._entity_variant_map
        expected_labels = expected_labels or set()
        
        entities = []
        query_lower = query.lower()
        
        # Try to find group/artist/others (case-insensitive, filtered by expected_labels n·∫øu c√≥)
        all_groups = [node for node, data in self.kg.graph.nodes(data=True) 
                     if data.get('label') == 'Group' and (not expected_labels or 'Group' in expected_labels)]
        
        all_artists = [node for node, data in self.kg.graph.nodes(data=True) 
                      if data.get('label') == 'Artist' and (not expected_labels or 'Artist' in expected_labels)]
        
        # Th√™m c√°c lo·∫°i kh√°c n·∫øu c·∫ßn cho intent (song/album/company/genre/occupation)
        all_companies = [node for node, data in self.kg.graph.nodes(data=True)
                        if data.get('label') == 'Company' and (not expected_labels or 'Company' in expected_labels)]
        all_songs = [node for node, data in self.kg.graph.nodes(data=True)
                    if data.get('label') == 'Song' and (not expected_labels or 'Song' in expected_labels)]
        all_albums = [node for node, data in self.kg.graph.nodes(data=True)
                     if data.get('label') == 'Album' and (not expected_labels or 'Album' in expected_labels)]
        all_genres = [node for node, data in self.kg.graph.nodes(data=True)
                     if data.get('label') == 'Genre' and (not expected_labels or 'Genre' in expected_labels)]
        all_occupations = [node for node, data in self.kg.graph.nodes(data=True)
                          if data.get('label') == 'Occupation' and (not expected_labels or 'Occupation' in expected_labels)]

        # Helper: normalize v√† sinh variants cho m·ªôt t√™n node
        def _variants(name: str) -> List[str]:
            base = self._normalize_entity_name(name).lower()
            variants = {
                base,  # Original
                base.replace('-', ' '),  # "go-won" ‚Üí "go won"
                base.replace('-', ''),   # "go-won" ‚Üí "gowon"
                base.replace(' ', ''),   # "go won" ‚Üí "gowon"
                base.replace(' ', '-'),  # "go won" ‚Üí "go-won"
            }
            return list(variants)  # Lo·∫°i b·ªè tr√πng l·∫∑p

        # ===== Graph -> Query: qu√©t n-gram (1-4 words) ƒë·ªÉ b·∫Øt c·∫∑p t√™n li·ªÅn nhau =====
        # QUAN TR·ªåNG: Extract suffix t·ª´ query tr∆∞·ªõc khi strip ƒë·ªÉ ∆∞u ti√™n match
        # V√≠ d·ª•: "F(x) (nh√≥m nh·∫°c)" ‚Üí suffix = "(nh√≥m nh·∫°c)"
        import re
        # Extract c√°c suffix patterns t·ª´ query
        suffix_patterns = re.findall(r'\([^)]+\)', query_lower)
        query_suffixes = set()  # L∆∞u c√°c suffix ƒë√£ t√¨m th·∫•y
        for suffix in suffix_patterns:
            # Normalize suffix: "(nh√≥m nh·∫°c)", "(ca sƒ©)", etc.
            suffix_clean = suffix.strip('()').lower()
            if 'nh√≥m' in suffix_clean or 'group' in suffix_clean:
                query_suffixes.add('(nh√≥m nh·∫°c)')
            elif 'ca sƒ©' in suffix_clean or 'singer' in suffix_clean or 'artist' in suffix_clean:
                query_suffixes.add('(ca sƒ©)')
            else:
                query_suffixes.add(suffix)  # Gi·ªØ nguy√™n c√°c suffix kh√°c
        
        # Strip h·∫≠u t·ªë trong query ƒë·ªÉ t·∫°o tokens
        query_cleaned = re.sub(r'\s*\([^)]+\)\s*', ' ', query_lower)
        query_cleaned = ' '.join(query_cleaned.split())  # Normalize spaces
        
        # QUAN TR·ªåNG: X·ª≠ l√Ω tokens c√≥ dash trong ƒë√≥ (nh∆∞ "won-young")
        # T√°ch tokens, nh∆∞ng c≈©ng t√°ch c√°c token c√≥ dash th√†nh nhi·ªÅu parts
        tokens = query_cleaned.split()
        expanded_tokens = []
        for token in tokens:
            expanded_tokens.append(token)  # Gi·ªØ nguy√™n token g·ªëc
            # N·∫øu token c√≥ dash, th√™m c√°c parts
            if '-' in token:
                parts = token.split('-')
                expanded_tokens.extend(parts)  # "won-young" ‚Üí ["won-young", "won", "young"]
        
        ngrams = []
        for n in [1, 2, 3, 4]:
            # T·∫°o n-grams t·ª´ c·∫£ tokens g·ªëc v√† expanded_tokens
            for token_list in [tokens, expanded_tokens]:
                for i in range(len(token_list) - n + 1):
                    ngram = " ".join(token_list[i:i+n])
                    ngrams.append(ngram)  # Original: "go won", "jang won-young", "jang won young"
                    # th√™m phi√™n b·∫£n kh√¥ng d·∫•u c√°ch ƒë·ªÉ b·∫Øt "go won" vs "gowon"
                    ngrams.append(ngram.replace(" ", ""))
                    # th√™m phi√™n b·∫£n thay space b·∫±ng g·∫°ch ƒë·ªÉ b·∫Øt "jang won young" vs "jang-won-young"
                    ngrams.append(ngram.replace(" ", "-"))
                    # QUAN TR·ªåNG: X·ª≠ l√Ω t√™n c√≥ d·∫•u g·∫°ch ngang trong query
                    # N·∫øu ngram c√≥ d·∫•u g·∫°ch ngang, t·∫°o th√™m variant v·ªõi space
                    if '-' in ngram:
                        ngrams.append(ngram.replace("-", " "))  # "won-young" ‚Üí "won young", "jang won-young" ‚Üí "jang won young"
                        ngrams.append(ngram.replace("-", ""))   # "won-young" ‚Üí "wonyoung"
        
        # Lo·∫°i b·ªè tr√πng l·∫∑p
        ngrams = list(dict.fromkeys(ngrams))

        # QUAN TR·ªåNG: ƒê·ªãnh nghƒ©a query_words_list TR∆Ø·ªöC khi s·ª≠ d·ª•ng
        # S·ª≠ d·ª•ng query_cleaned (ƒë√£ strip h·∫≠u t·ªë) thay v√¨ query_lower ƒë·ªÉ match t·ªët h∆°n
        query_words_list = query_cleaned.split()  # List ƒë·ªÉ gi·ªØ th·ª© t·ª±
        query_words_list_original = query_lower.split()  # Gi·ªØ b·∫£n g·ªëc ƒë·ªÉ fallback

        matched_from_graph = []
        candidate_scores = []  # list of (name, score, label)
        token_set = set(tokens)  # T·ª´ query_cleaned (ƒë√£ strip h·∫≠u t·ªë)
        token_set_original = set(query_words_list_original)  # T·ª´ query g·ªëc (fallback)

        # Track normalized names ƒë·ªÉ tr√°nh duplicate (v√≠ d·ª•: "Ros√©" v√† "Ros√© (ca sƒ©)" ‚Üí ch·ªâ gi·ªØ 1)
        normalized_seen = set()
        # Track c√°c t·ª´ ƒë√£ ƒë∆∞·ª£c match trong t√™n ƒë·∫ßy ƒë·ªß ƒë·ªÉ tr√°nh match single word khi ƒë√£ c√≥ match ƒë·∫ßy ƒë·ªß
        # V√≠ d·ª•: n·∫øu ƒë√£ match "Yoo Jeong-yeon", th√¨ kh√¥ng match "Yoo" n·ªØa
        words_in_matched_full_names = set()
        
        # QUAN TR·ªåNG: Kh·ªüi t·∫°o seen_entities TR∆Ø·ªöC khi s·ª≠ d·ª•ng
        seen_entities = set()

        # ============================================
        # B∆Ø·ªöC 0: T·ª∞ ƒê·ªòNG T√åM ENTITY V·ªöI SUFFIX (ca sƒ©), (nh√≥m nh·∫°c), etc.
        # ============================================
        # Logic: Khi query c√≥ t√™n ng·∫Øn nh∆∞ "Kai", "IU", t·ª± ƒë·ªông t√¨m entity ƒë·∫ßy ƒë·ªß
        # nh∆∞ "Kai (ca sƒ©)", "IU (ca sƒ©)" trong KG
        
        # Danh s√°ch c√°c suffix ph·ªï bi·∫øn theo th·ª© t·ª± ∆∞u ti√™n
        artist_suffixes = ["(ca sƒ©)", "(rapper)", "(ca sƒ© H√†n Qu·ªëc)"]
        group_suffixes = ["(nh√≥m nh·∫°c)", "(nh√≥m nh·∫°c H√†n Qu·ªëc)", "(ban nh·∫°c)"]
        album_suffixes = ["(EP)", "(album)"]  # Album suffixes c∆° b·∫£n
        song_suffixes = ["(b√†i h√°t)"]
        
        # X√°c ƒë·ªãnh context ƒë·ªÉ ∆∞u ti√™n suffix ph√π h·ª£p
        is_artist_context = any(kw in query_lower for kw in ['ca sƒ©', 'ngh·ªá sƒ©', 'artist', 'h√°t', 'th·ªÉ hi·ªán'])
        is_group_context = any(kw in query_lower for kw in ['nh√≥m', 'group', 'band', 'th√†nh vi√™n'])
        is_album_context = any(kw in query_lower for kw in ['album', 'ep', 'ƒëƒ©a'])
        is_song_context = any(kw in query_lower for kw in ['b√†i h√°t', 'ca kh√∫c', 'song', 'track'])
        
        # ∆Øu ti√™n suffix theo context
        if is_album_context:
            preferred_suffixes = album_suffixes  # S·∫Ω x·ª≠ l√Ω ƒë·∫∑c bi·ªát cho album
        elif is_song_context:
            preferred_suffixes = song_suffixes + artist_suffixes
        elif is_group_context:
            preferred_suffixes = group_suffixes + artist_suffixes
        else:
            preferred_suffixes = artist_suffixes + group_suffixes
        
        preferred_entities_found = []
        
        # T√¨m c√°c t·ª´ c√≥ th·ªÉ l√† t√™n entity trong query
        import re
        # T√°ch query th√†nh c√°c tokens (words)
        query_tokens = re.findall(r'\b[A-Za-z\u3131-\uD79D]+(?:[-\'][A-Za-z\u3131-\uD79D]+)*\b', query_lower)
        
        # T·∫°o n-grams t·ª´ tokens (1-3 words) ƒë·ªÉ match t√™n c√≥ nhi·ªÅu t·ª´ nh∆∞ "Rose", "J-Hope"
        potential_names = set()
        for i in range(len(query_tokens)):
            for n in range(1, min(4, len(query_tokens) - i + 1)):
                ngram = " ".join(query_tokens[i:i+n])
                if len(ngram) >= 2:  # T·ªëi thi·ªÉu 2 k√Ω t·ª±
                    potential_names.add(ngram)
                    # Th√™m variant v·ªõi dash
                    potential_names.add(ngram.replace(" ", "-"))
                    potential_names.add(ngram.replace("-", " "))
        
        for potential_name in potential_names:
            # B∆∞·ªõc 1: Ki·ªÉm tra n·∫øu entity t·ªìn t·∫°i v·ªõi suffix
            found_with_suffix = False
            
            # B∆∞·ªõc 1a: N·∫øu l√† album context, t√¨m v·ªõi pattern "(album c·ªßa X)" ho·∫∑c "(EP)"
            if is_album_context:
                # T√¨m t·∫•t c·∫£ albums trong KG c√≥ t√™n b·∫Øt ƒë·∫ßu b·∫±ng potential_name
                album_candidates = []
                for node, data in self.kg.graph.nodes(data=True):
                    if data.get('label') == 'Album':
                        node_lower = node.lower()
                        name_lower = potential_name.lower()
                        # Match: "Alive (album c·ªßa Big Bang)" v·ªõi "alive"
                        if node_lower.startswith(name_lower + " (") or node_lower == name_lower:
                            album_candidates.append((node, data))
                
                # ∆Øu ti√™n album c√≥ infobox ƒë·∫ßy ƒë·ªß
                album_candidates.sort(key=lambda x: len(x[1].get('infobox', {})), reverse=True)
                
                for album_name, album_data in album_candidates:
                    if album_name not in seen_entities:
                        seen_entities.add(album_name)
                        normalized_seen.add(self._normalize_entity_name(album_name).lower())
                        score = 3.5  # Score cao cho album match
                        if album_data.get('infobox') and len(album_data.get('infobox', {})) > 0:
                            score += 0.5
                        candidate_scores.append((album_name, score, 'Album'))
                        matched_from_graph.append({"name": album_name, "score": score})
                        preferred_entities_found.append(album_name)
                        found_with_suffix = True
                        break
            
            # B∆∞·ªõc 1b: T√¨m v·ªõi suffix th√¥ng th∆∞·ªùng (ca sƒ©, nh√≥m nh·∫°c, etc.)
            if not found_with_suffix:
                for suffix in preferred_suffixes:
                    full_name = f"{potential_name.title()} {suffix}"
                    entity_data = self.kg.get_entity(full_name)
                    if entity_data:
                        # Ki·ªÉm tra label ph√π h·ª£p v·ªõi expected_labels
                        label = entity_data.get('label', 'Unknown')
                        if not expected_labels or label in expected_labels:
                            if full_name not in seen_entities:
                                seen_entities.add(full_name)
                                normalized_seen.add(self._normalize_entity_name(full_name).lower())
                                # Score cao cho entity c√≥ suffix v√† infobox ƒë·∫ßy ƒë·ªß
                                score = 3.0
                                if entity_data.get('infobox') and len(entity_data.get('infobox', {})) > 0:
                                    score += 0.5
                                candidate_scores.append((full_name, score, label))
                                matched_from_graph.append({"name": full_name, "score": score})
                                preferred_entities_found.append(full_name)
                                found_with_suffix = True
                                break
            
            # B∆∞·ªõc 2: N·∫øu kh√¥ng t√¨m th·∫•y v·ªõi suffix, th·ª≠ t√¨m exact match
            if not found_with_suffix:
                # Th·ª≠ v·ªõi Title Case
                for name_variant in [potential_name.title(), potential_name.upper(), potential_name]:
                    entity_data = self.kg.get_entity(name_variant)
                    if entity_data:
                        label = entity_data.get('label', 'Unknown')
                        if not expected_labels or label in expected_labels:
                            if name_variant not in seen_entities:
                                seen_entities.add(name_variant)
                                normalized_seen.add(self._normalize_entity_name(name_variant).lower())
                                # Score th·∫•p h∆°n cho entity kh√¥ng c√≥ suffix
                                score = 2.5
                                if entity_data.get('infobox') and len(entity_data.get('infobox', {})) > 0:
                                    score += 0.5
                                candidate_scores.append((name_variant, score, label))
                                matched_from_graph.append({"name": name_variant, "score": score})
                                preferred_entities_found.append(name_variant)
                                break
        
        # ============================================
        # B∆Ø·ªöC 1: LOOKUP T·ª™ VARIANT_MAP (∆ØU TI√äN - NHANH V√Ä CH√çNH X√ÅC)
        # ============================================
        # QUAN TR·ªåNG: Variant map ƒë√£ ƒë∆∞·ª£c build v·ªõi t·∫•t c·∫£ bi·∫øn th·ªÉ t·ª´ graph
        # ∆Øu ti√™n lookup t·ª´ variant_map tr∆∞·ªõc v√¨ ƒë√£ ƒë∆∞·ª£c index s·∫µn v√† c√≥ scoring ch√≠nh x√°c
        
        # T·∫°o th√™m c√°c bi·∫øn th·ªÉ n-gram t·ª´ query_cleaned (ƒë√£ strip h·∫≠u t·ªë)
        cleaned_ngrams = []
        cleaned_tokens = query_cleaned.split()
        for n in [1, 2, 3, 4]:
            for i in range(len(cleaned_tokens) - n + 1):
                ngram = " ".join(cleaned_tokens[i:i+n])
                cleaned_ngrams.append(ngram)
                cleaned_ngrams.append(ngram.replace(" ", ""))
                cleaned_ngrams.append(ngram.replace(" ", "-"))
                if '-' in ngram:
                    cleaned_ngrams.append(ngram.replace("-", " "))
                    cleaned_ngrams.append(ngram.replace("-", ""))
        
        # K·∫øt h·ª£p c·∫£ ngrams t·ª´ query g·ªëc v√† query ƒë√£ cleaned
        all_ngrams = list(dict.fromkeys(ngrams + cleaned_ngrams))
        
        seen_entities = set()  # Tr√°nh tr√πng l·∫∑p
        
        for ng in all_ngrams:
            if len(ng) < 2:
                continue
            # Normalize n-gram (lo·∫°i b·ªè spaces th·ª´a, k√Ω t·ª± ƒë·∫∑c bi·ªát)
            ng_normalized = " ".join(ng.split())
            # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát nh∆∞ *, (), [] nh∆∞ng gi·ªØ l·∫°i dash v√† space
            import re
            ng_clean = re.sub(r'[^\w\s-]', '', ng_normalized)
            # T·∫°o c√°c lookup keys: original, normalized, lowercase, cleaned
            # QUAN TR·ªåNG: Th·ª≠ nhi·ªÅu bi·∫øn th·ªÉ c·ªßa n-gram ƒë·ªÉ match t·ªët h∆°n
            lookup_keys = [
                ng, 
                ng_normalized, 
                ng.lower(), 
                ng_normalized.lower(), 
                ng_clean.lower(),
                ng_clean,  # Th√™m c·∫£ cleaned kh√¥ng lowercase
                ng.replace(' ', '-').lower(),  # Th√™m variant v·ªõi dash
                ng.replace('-', ' ').lower(),  # Th√™m variant v·ªõi space
            ]
            # Lo·∫°i b·ªè tr√πng l·∫∑p
            lookup_keys = list(dict.fromkeys(lookup_keys))
            
            for lookup_key in lookup_keys:
                if lookup_key in variant_map:
                    # Variant map ƒë√£ ƒë∆∞·ª£c sort theo score (highest first)
                    # ∆Øu ti√™n l·∫•y entity c√≥ score cao nh·∫•t (exact match)
                    # QUAN TR·ªåNG: ∆Øu ti√™n entities c√≥ suffix kh·ªõp v·ªõi query
                    entities_with_suffix = []  # Entities c√≥ suffix kh·ªõp
                    entities_without_suffix = []  # Entities kh√¥ng c√≥ suffix ho·∫∑c kh√¥ng kh·ªõp
                    
                    for ent in variant_map[lookup_key]:
                        entity_name = ent["name"]
                        normalized = self._normalize_entity_name(entity_name).lower()
                        label = ent.get("label", "Unknown")
                        
                        # Filter theo expected_labels n·∫øu c√≥
                        if expected_labels and label not in expected_labels:
                            continue
                        
                        # Check n·∫øu entity c√≥ suffix kh·ªõp v·ªõi query
                        has_matching_suffix = False
                        if query_suffixes:
                            entity_suffixes = re.findall(r'\([^)]+\)', entity_name.lower())
                            for entity_suffix in entity_suffixes:
                                entity_suffix_clean = entity_suffix.strip('()').lower()
                                for query_suffix in query_suffixes:
                                    query_suffix_clean = query_suffix.strip('()').lower()
                                    if query_suffix_clean in entity_suffix_clean or entity_suffix_clean in query_suffix_clean:
                                        has_matching_suffix = True
                                        break
                                if has_matching_suffix:
                                    break
                        
                        # Ph√¢n lo·∫°i entities theo suffix match
                        if has_matching_suffix:
                            entities_with_suffix.append((ent, entity_name, normalized, label))
                        else:
                            entities_without_suffix.append((ent, entity_name, normalized, label))
                    
                    # X·ª≠ l√Ω entities c√≥ suffix kh·ªõp TR∆Ø·ªöC (∆∞u ti√™n cao h∆°n)
                    for ent, entity_name, normalized, label in entities_with_suffix:
                        if normalized not in normalized_seen:
                            normalized_seen.add(normalized)
                            seen_entities.add(entity_name)
                            entity_score = ent.get("score", 1.5)
                            # Bonus l·ªõn cho suffix match (∆∞u ti√™n cao nh·∫•t)
                            entity_score += 1.0
                            if lookup_key == normalized:
                                entity_score += 0.5
                            candidate_scores.append((entity_name, entity_score, label))
                            matched_from_graph.append({"name": entity_name, "score": entity_score})
                    
                    # Sau ƒë√≥ m·ªõi x·ª≠ l√Ω entities kh√¥ng c√≥ suffix match
                    # QUAN TR·ªåNG: ∆Øu ti√™n entity c√≥ th√¥ng tin (infobox kh√¥ng tr·ªëng) h∆°n entity tr·ªëng
                    entities_with_info = []
                    entities_without_info = []
                    
                    for item in entities_without_suffix:
                        ent, entity_name, normalized, label = item
                        # Ki·ªÉm tra entity c√≥ infobox kh√¥ng tr·ªëng
                        entity_data = self.kg.get_entity(entity_name)
                        has_info = entity_data and entity_data.get('infobox') and len(entity_data.get('infobox', {})) > 0
                        if has_info:
                            entities_with_info.append(item)
                        else:
                            entities_without_info.append(item)
                    
                    # X·ª≠ l√Ω entities c√≥ th√¥ng tin TR∆Ø·ªöC
                    for ent, entity_name, normalized, label in entities_with_info:
                        if normalized not in normalized_seen:
                            normalized_seen.add(normalized)
                            seen_entities.add(entity_name)
                            entity_score = ent.get("score", 1.5)
                            if lookup_key == normalized:
                                entity_score += 0.5
                            # Bonus cho entity c√≥ th√¥ng tin
                            entity_score += 0.3
                            candidate_scores.append((entity_name, entity_score, label))
                            matched_from_graph.append({"name": entity_name, "score": entity_score})
                    
                    # Cu·ªëi c√πng m·ªõi x·ª≠ l√Ω entities kh√¥ng c√≥ th√¥ng tin
                    for ent, entity_name, normalized, label in entities_without_info:
                        if normalized not in normalized_seen:
                            normalized_seen.add(normalized)
                            seen_entities.add(entity_name)
                            entity_score = ent.get("score", 1.5)
                            if lookup_key == normalized:
                                entity_score += 0.5
                            # Penalty cho entity kh√¥ng c√≥ th√¥ng tin
                            entity_score -= 0.5
                            candidate_scores.append((entity_name, entity_score, label))
                            matched_from_graph.append({"name": entity_name, "score": entity_score})

        # ============================================
        # B∆Ø·ªöC 2: FALLBACK - MATCH TR·ª∞C TI·∫æP CHO C√ÅC ENTITY CH∆ØA T√åM TH·∫§Y
        # ============================================
        # Ch·ªâ match c√°c entity ch∆∞a ƒë∆∞·ª£c t√¨m th·∫•y qua variant_map
        # ∆Øu ti√™n match ƒë·∫ßy ƒë·ªß t√™n (n-gram) tr∆∞·ªõc single word
        
        def _match_list_fallback(nodes: List[str], score_val: float, label: str):
            """Match tr·ª±c ti·∫øp cho c√°c entity ch∆∞a c√≥ trong variant_map."""
            # T·∫°o n-grams t·ª´ query_cleaned (ƒë√£ strip h·∫≠u t·ªë) v√† query g·ªëc ƒë·ªÉ match t·ªët h∆°n
            query_ngrams_for_match = []
            # S·ª≠ d·ª•ng query_cleaned (ƒë√£ strip h·∫≠u t·ªë) ƒë·ªÉ match t·ªët h∆°n
            for n in [2, 3, 4]:
                # T·ª´ query_cleaned
                for i in range(len(query_words_list) - n + 1):
                    ngram = " ".join(query_words_list[i:i+n])
                    query_ngrams_for_match.append(ngram)
                    query_ngrams_for_match.append(ngram.replace(" ", ""))
                    query_ngrams_for_match.append(ngram.replace(" ", "-"))
                    if '-' in ngram:
                        query_ngrams_for_match.append(ngram.replace("-", " "))
                        query_ngrams_for_match.append(ngram.replace("-", ""))
                # T·ª´ query g·ªëc (fallback)
                for i in range(len(query_words_list_original) - n + 1):
                    ngram = " ".join(query_words_list_original[i:i+n])
                    query_ngrams_for_match.append(ngram)
                    query_ngrams_for_match.append(ngram.replace(" ", ""))
                    query_ngrams_for_match.append(ngram.replace(" ", "-"))
                    if '-' in ngram:
                        query_ngrams_for_match.append(ngram.replace("-", " "))
                        query_ngrams_for_match.append(ngram.replace("-", ""))
            query_ngrams_for_match = list(dict.fromkeys(query_ngrams_for_match))
            
            for node in nodes:
                normalized = self._normalize_entity_name(node).lower()
                # Check duplicate b·∫±ng normalized name (ƒë√£ match qua variant_map)
                if normalized in normalized_seen:
                    continue
                
                # Check n·∫øu entity c√≥ suffix kh·ªõp v·ªõi query (∆∞u ti√™n cao h∆°n)
                has_matching_suffix = False
                if query_suffixes:
                    entity_suffixes = re.findall(r'\([^)]+\)', node.lower())
                    for entity_suffix in entity_suffixes:
                        entity_suffix_clean = entity_suffix.strip('()').lower()
                        for query_suffix in query_suffixes:
                            query_suffix_clean = query_suffix.strip('()').lower()
                            if query_suffix_clean in entity_suffix_clean or entity_suffix_clean in query_suffix_clean:
                                has_matching_suffix = True
                                break
                        if has_matching_suffix:
                            break
                
                variants = _variants(node)
                hit = False
                base_name_word_count = len(normalized.split())
                
                # Method 1: Check n-gram matching (∆∞u ti√™n match ƒë·∫ßy ƒë·ªß t√™n tr∆∞·ªõc)
                # Ch·ªâ check n·∫øu base_name c√≥ nhi·ªÅu t·ª´ (‚â•2) ƒë·ªÉ ∆∞u ti√™n match ƒë·∫ßy ƒë·ªß
                if base_name_word_count >= 2:
                    for ngram in query_ngrams_for_match:
                        if len(ngram) < 3:
                            continue
                        for variant in variants:
                            if len(variant) < 3:
                                continue
                            # Exact match ho·∫∑c substring match
                            if variant == ngram or variant in ngram or ngram in variant:
                                base_score = score_val + 0.5  # Bonus cho n-gram match
                                if variant in token_set or variant in token_set_original:
                                    base_score += 0.4  # ∆∞u ti√™n match ƒë√∫ng token
                                # QUAN TR·ªåNG: Bonus l·ªõn cho suffix match (∆∞u ti√™n cao nh·∫•t)
                                if has_matching_suffix:
                                    base_score += 1.0
                                candidate_scores.append((node, base_score, label))
                                hit = True
                                break
                        if hit:
                            break
                
                # Method 2: Check single word matching (ch·ªâ cho single word names ho·∫∑c fallback)
                if not hit:
                    for variant in variants:
                        if len(variant) < 3:
                            continue
                        # Ch·ªâ match single word n·∫øu base_name ch·ªâ c√≥ 1 t·ª´
                        if base_name_word_count == 1:
                            # Th·ª≠ c·∫£ query_cleaned v√† query_lower
                            if variant in query_cleaned or variant in query_lower:
                                base_score = score_val
                                if variant in token_set or variant in token_set_original:
                                    base_score += 0.4  # ∆∞u ti√™n match ƒë√∫ng token
                                # QUAN TR·ªåNG: Bonus l·ªõn cho suffix match (∆∞u ti√™n cao nh·∫•t)
                                if has_matching_suffix:
                                    base_score += 1.0
                                candidate_scores.append((node, base_score, label))
                                hit = True
                                break
                        # N·∫øu base_name c√≥ nhi·ªÅu t·ª´, ch·ªâ match n·∫øu t·∫•t c·∫£ c√°c t·ª´ ƒë·ªÅu c√≥ trong query
                        elif base_name_word_count > 1:
                            variant_words = set(variant.split())
                            query_words_set = set(query_words_list)
                            query_words_set_original = set(query_words_list_original)
                            # Ki·ªÉm tra c·∫£ query_cleaned v√† query g·ªëc
                            if variant_words.issubset(query_words_set) or variant_words.issubset(query_words_set_original):
                                base_score = score_val
                                if variant in token_set or variant in token_set_original:
                                    base_score += 0.4
                                # QUAN TR·ªåNG: Bonus l·ªõn cho suffix match (∆∞u ti√™n cao nh·∫•t)
                                if has_matching_suffix:
                                    base_score += 1.0
                                candidate_scores.append((node, base_score, label))
                                hit = True
                                break
                
                if hit:
                    entities.append(node)
                    normalized_seen.add(normalized)
                    # kh√¥ng break ƒë·ªÉ c√≥ th·ªÉ th√™m nhi·ªÅu th·ª±c th·ªÉ, nh∆∞ng tr√°nh tr√πng l·∫∑p
        
        # Match c√°c entity types ch∆∞a ƒë∆∞·ª£c cover trong variant_map (Company, Song, Album, Genre, Occupation)
        # Artists v√† Groups ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω qua variant_map v√† logic ri√™ng ·ªü tr√™n
        _match_list_fallback(all_companies, 1.3, 'Company')
        _match_list_fallback(all_songs, 1.2, 'Song')
        _match_list_fallback(all_albums, 1.2, 'Album')
        _match_list_fallback(all_genres, 1.1, 'Genre')
        _match_list_fallback(all_occupations, 1.0, 'Occupation')
        
        # ============================================
        # KEY STRATEGY: Match by length (longest first)
        # ============================================
        # Sort ALL artists by name length (longest first)
        # This ensures "Yoo Jeong-yeon" is checked before "Yoo", "Jeongyeon", "Ye-on"
        all_artists_sorted = sorted(
            all_artists,
            key=lambda x: len(self._normalize_entity_name(x).lower().replace('-', ' ')),
            reverse=True
        )
        
        # Track which parts of query have been "consumed" by matched entities
        # This prevents matching "Yoo" after matching "Yoo Jeong-yeon"
        matched_query_spans = []  # List of (start_idx, end_idx) in query_words_list
        
        # Create n-grams from query (for matching multi-word names)
        query_ngrams_with_positions = []
        for n in [4, 3, 2]:  # Longest first
            for i in range(len(query_words_list) - n + 1):
                ngram = " ".join(query_words_list[i:i+n])
                query_ngrams_with_positions.append({
                    'text': ngram,
                    'start': i,
                    'end': i + n,
                    'variants': [
                        v for v in [
                            ngram,
                            ngram.replace(" ", ""),
                            ngram.replace(" ", "-"),
                            ngram.replace("-", " ") if '-' in ngram else None,
                            ngram.replace("-", "") if '-' in ngram else None,
                        ] if v is not None
                    ]
                })
        
        # ============================================
        # MATCH ARTISTS (longest to shortest)
        # ============================================
        found_artists = []
        
        for artist in all_artists_sorted:
            base_name = self._normalize_entity_name(artist).lower()
            
            if base_name in normalized_seen:
                continue
            
            base_words = base_name.replace('-', ' ').split()
            base_word_count = len(base_words)
            
            # Generate variants for this artist
            artist_variants = self._generate_variants(base_name)
            
            matched = False
            match_start = -1
            match_end = -1
            
            # ============================================
            # CASE 1: Multi-word names (‚â•2 words)
            # ============================================
            if base_word_count >= 2:
                # Try to match with n-grams
                for ngram_info in query_ngrams_with_positions:
                    # Skip if this span was already matched
                    span_start = ngram_info['start']
                    span_end = ngram_info['end']
                    
                    # Check if this span overlaps with any matched span
                    is_overlapping = any(
                        not (span_end <= ms or span_start >= me)
                        for ms, me in matched_query_spans
                    )
                    if is_overlapping:
                        continue
                    
                    # Try to match variants
                    for variant in artist_variants:
                        if any(v == variant for v in ngram_info['variants'] if v):
                            # MATCH FOUND!
                            found_artists.append(artist)
                            normalized_seen.add(base_name)
                            candidate_scores.append((artist, 1.6, 'Artist'))
                            matched = True
                            match_start = span_start
                            match_end = span_end
                            break
                        
                        # Partial match: if ‚â•2 words overlap
                        if not matched:
                            ngram_text = ngram_info['text']
                            variant_words = set(variant.replace('-', ' ').split())
                            ngram_words = set(ngram_text.replace('-', ' ').split())
                            if len(variant_words.intersection(ngram_words)) >= 2:
                                found_artists.append(artist)
                                normalized_seen.add(base_name)
                                candidate_scores.append((artist, 1.5, 'Artist'))
                                matched = True
                                match_start = span_start
                                match_end = span_end
                                break
                    
                    if matched:
                        break
            
            # ============================================
            # CASE 2: Single-word names (1 word)
            # ============================================
            else:  # base_word_count == 1
                # Check each word in query
                for idx, word in enumerate(query_words_list):
                    # Skip if this position was already matched
                    is_overlapping = any(
                        ms <= idx < me
                        for ms, me in matched_query_spans
                    )
                    if is_overlapping:
                        continue
                    
                    # Check if word matches any variant
                    for variant in artist_variants:
                        if word == variant:
                            # MATCH FOUND!
                            found_artists.append(artist)
                            normalized_seen.add(base_name)
                            candidate_scores.append((artist, 1.4, 'Artist'))
                            matched = True
                            match_start = idx
                            match_end = idx + 1
                            break
                    
                    if matched:
                        break
            
            # Record matched span to prevent overlapping matches
            if matched and match_start >= 0:
                matched_query_spans.append((match_start, match_end))
        
        # Th√™m t·∫•t c·∫£ artists t√¨m ƒë∆∞·ª£c (kh√¥ng ch·ªâ 1)
        entities.extend(found_artists)
        
        # ============================================
        # TH√äM ENTITIES T·ª™ VARIANT_MAP V√ÄO K·∫æT QU·∫¢
        # ============================================
        # ƒê·∫£m b·∫£o t·∫•t c·∫£ entities t·ª´ variant_map ƒë∆∞·ª£c th√™m v√†o
        if matched_from_graph:
            for m in matched_from_graph:
                if m['name'] not in entities:
                    entities.append(m['name'])
        
        # ============================================
        # SORT AND RETURN
        # ============================================
        # QUAN TR·ªåNG: ∆Øu ti√™n score cao nh·∫•t (exact match) tr∆∞·ªõc, sau ƒë√≥ m·ªõi ƒë·∫øn label priority
        if candidate_scores:
            label_priority = {'Group': 7, 'Artist': 6, 'Company': 5, 'Song': 4, 'Album': 3, 'Genre': 2, 'Occupation': 1}
            ordered = []
            seen = set()
            # Sort theo: score (cao nh·∫•t), label priority, ƒë·ªô d√†i t√™n (d√†i h∆°n ∆∞u ti√™n h∆°n)
            for item in sorted(
                candidate_scores,
                key=lambda x: (x[1], label_priority.get(x[2] if len(x) > 2 else None, 0), len(x[0])),
                reverse=True
            ):
                name = item[0]
                if name not in seen:
                    ordered.append(name)
                    seen.add(name)
            entities = ordered[:10]
        
        # ============================================
        # FINAL FILTER: Remove shorter entities that are parts of longer matched entities
        # ============================================
        # Build blacklist from matched multi-word entities
        blacklist_words = set()
        multi_word_entities = []
        for entity in entities:
            base_name = self._normalize_entity_name(entity).lower()
            base_words = base_name.replace('-', ' ').split()
            if len(base_words) >= 2:
                multi_word_entities.append((entity, base_name, base_words))
                # Add individual words to blacklist
                for word in base_words:
                    if len(word) >= 2:
                        blacklist_words.add(word)
                # Add normalized name without dashes/spaces
                blacklist_words.add(base_name.replace('-', '').replace(' ', ''))
        
        # Filter entities: remove single-word entities that are in blacklist
        filtered_entities = []
        for entity in entities:
            base_name = self._normalize_entity_name(entity).lower()
            base_words = base_name.replace('-', ' ').split()
            if len(base_words) == 1:
                # Single-word entity: check if it's in blacklist
                base_no_dash = base_name.replace('-', '').replace(' ', '')
                if base_name in blacklist_words or base_no_dash in blacklist_words:
                    continue  # Skip this entity
                # Also check if it's a substring of any multi-word entity
                should_skip = False
                for _, multi_base, multi_words in multi_word_entities:
                    multi_no_dash = multi_base.replace('-', '').replace(' ', '')
                    if base_name in multi_words or base_no_dash in multi_no_dash:
                        should_skip = True
                        break
                if should_skip:
                    continue
            filtered_entities.append(entity)
        
        return filtered_entities[:10] if filtered_entities else []
    
    def _normalize_entity_name(self, entity_name: str) -> str:
        """
        Normalize entity name b·∫±ng c√°ch remove suffixes trong parentheses.
        
        V√≠ d·ª•:
        - "Lisa (ca sƒ©)" ‚Üí "Lisa"
        - "BLACKPINK (nh√≥m nh·∫°c)" ‚Üí "BLACKPINK"
        - "BTS (rapper)" ‚Üí "BTS"
        
        Args:
            entity_name: Entity name c√≥ th·ªÉ c√≥ ƒëu√¥i
            
        Returns:
            Base name (kh√¥ng c√≥ ƒëu√¥i)
        """
        import re
        # Remove suffixes trong parentheses: (ca sƒ©), (nh√≥m nh·∫°c), (rapper), etc.
        normalized = re.sub(r'\s*\([^)]+\)\s*$', '', entity_name)
        return normalized.strip()
    
    def _generate_variants(self, name: str) -> List[str]:
        """Sinh c√°c bi·∫øn th·ªÉ ƒë∆°n gi·∫£n c·ªßa m·ªôt t√™n entity."""
        base = self._normalize_entity_name(name).lower()
        variants = {
            base,  # Original: "jang won-young"
            base.replace('-', ' '),  # "jang won-young" ‚Üí "jang won young", "go-won" ‚Üí "go won"
            base.replace('-', ''),   # "jang won-young" ‚Üí "jangwonyoung", "go-won" ‚Üí "gowon"
            base.replace(' ', ''),   # "jang won-young" ‚Üí "jangwon-young", "go won" ‚Üí "gowon"
            base.replace(' ', '-'),  # "jang won-young" ‚Üí "jang-won-young", "go won" ‚Üí "go-won"
        }
        
        # QUAN TR·ªåNG: X·ª≠ l√Ω t√™n c√≥ C·∫¢ dash V√Ä space nh∆∞ "jang won-young"
        # T√°ch th√†nh c√°c parts (c·∫£ dash v√† space ƒë·ªÅu l√† separator)
        # "jang won-young" ‚Üí ["jang", "won", "young"]
        all_parts = []
        # T√°ch theo dash tr∆∞·ªõc
        for part in base.split('-'):
            # M·ªói part c√≥ th·ªÉ c√≥ space, t√°ch ti·∫øp
            all_parts.extend(part.split())
        # Lo·∫°i b·ªè empty parts
        all_parts = [p for p in all_parts if p]
        
        if len(all_parts) >= 2:
            # T·∫°o variants v·ªõi t·∫•t c·∫£ c√°c combinations
            # "jang won-young" ‚Üí ["jang", "won", "young"]
            variants.add(" ".join(all_parts))  # "jang won young"
            variants.add("-".join(all_parts))  # "jang-won-young"
            variants.add("".join(all_parts))   # "jangwonyoung"
            
            # T·∫°o c√°c combinations: m·ªôt s·ªë parts c√≥ dash, m·ªôt s·ªë c√≥ space
            # "jang won-young" ‚Üí "jang won-young", "jang-won young", etc.
            if len(all_parts) == 3:
                # 3 parts: c√≥ th·ªÉ c√≥ 2 dash positions
                variants.add(f"{all_parts[0]} {all_parts[1]}-{all_parts[2]}")  # "jang won-young"
                variants.add(f"{all_parts[0]}-{all_parts[1]} {all_parts[2]}")  # "jang-won young"
                variants.add(f"{all_parts[0]}-{all_parts[1]}-{all_parts[2]}")  # "jang-won-young"
                variants.add(f"{all_parts[0]} {all_parts[1]} {all_parts[2]}")  # "jang won young"
        
        # N·∫øu c√≥ g·∫°ch, th√™m b·∫£n t√°ch g·∫°ch v·ªõi nhi·ªÅu space v√† combinations
        if '-' in base:
            parts = base.split('-')
            # "yoo-jeong-yeon" ‚Üí ["yoo", "jeong", "yeon"]
            variants.add(" ".join(parts))  # "yoo jeong yeon"
            variants.add("".join(parts))   # "yoojeongyeon"
            # Th√™m c√°c combinations: "yoo jeong-yeon", "yoo-jeong yeon", etc.
            for i in range(len(parts)):
                # T·∫°o variant v·ªõi m·ªôt s·ªë ph·∫ßn c√≥ g·∫°ch, m·ªôt s·ªë c√≥ space
                if i < len(parts) - 1:
                    variant_parts = parts.copy()
                    variant_parts[i] = variant_parts[i] + "-" + variant_parts[i+1]
                    variant_parts.pop(i+1)
                    variants.add(" ".join(variant_parts))
        # N·∫øu c√≥ space, th√™m variant v·ªõi g·∫°ch v√† c√°c combinations
        if ' ' in base:
            parts = base.split(' ')
            # "go won" ‚Üí ["go", "won"]
            variants.add("-".join(parts))  # "go-won"
            variants.add("".join(parts))   # "gowon"
            # V·ªõi t√™n d√†i h∆°n: "jang won young" ‚Üí "jang-won-young", "jangwonyoung"
            if len(parts) > 2:
                variants.add("-".join(parts))  # "jang-won-young"
                variants.add("".join(parts))   # "jangwonyoung"
        return list(variants)
    
    def _ensure_entity_variant_map(self):
        """
        Build m·ªôt map variant -> [entity] ƒë·ªÉ tra c·ª©u nhanh (graph -> query).
        Ch·ªâ gi·ªØ label Artist/Group; th√™m alias th·ªß c√¥ng cho m·ªôt s·ªë case d·ªÖ nh·∫ßm.
        ∆ØU TI√äN: T·∫°o nhi·ªÅu bi·∫øn th·ªÉ ƒë·ªÉ ƒë·∫£m b·∫£o matching ch√≠nh x√°c t·ª´ graph ‚Üí query.
        """
        if hasattr(self, "_entity_variant_map") and self._entity_variant_map is not None:
            return
        
        import re
        
        alias_map = {
            # LOONA / LOOŒ†Œî
            "loona": ["loona", "looœÄŒ¥", "loonŒ±", "loona-loona"],
            "vi vi": ["vivi", "vi-vi", "vi vi"],
            "vivi": ["vivi", "vi-vi", "vi vi"],
            "go won": ["go won", "gowon", "go-won"],
            "gowon": ["go won", "gowon", "go-won"],
            # BLACKPINK
            "blackpink": ["blackpink", "black pink", "black-pink", "bp"],
        }
        
        variant_map: Dict[str, List[Dict[str, Any]]] = {}
        # QUAN TR·ªåNG: Build variant map cho T·∫§T C·∫¢ entity types, kh√¥ng ch·ªâ Artist/Group
        # ∆Øu ti√™n Artist v√† Group v√¨ ch√∫ng quan tr·ªçng nh·∫•t, nh∆∞ng c≈©ng index c·∫£ Company, Song, Album, etc.
        entity_type_priority = ['Artist', 'Group', 'Company', 'Song', 'Album', 'Genre', 'Occupation']
        
        for node, data in self.kg.graph.nodes(data=True):
            label = data.get('label')
            # Ch·ªâ index c√°c entity types c√≥ trong priority list (ƒë·ªÉ tr√°nh nhi·ªÖu)
            if label not in entity_type_priority:
                continue
            
            base_name = self._normalize_entity_name(node)
            base_variants = self._generate_variants(node)
            
            # Th√™m alias th·ªß c√¥ng n·∫øu kh·ªõp base name
            extra_alias = []
            base_lower = base_name.lower()
            if base_lower in alias_map:
                extra_alias = alias_map[base_lower]
            
            # QUAN TR·ªåNG: T·∫°o th√™m variants t·ª´ base_name (kh√¥ng ch·ªâ t·ª´ node)
            # ƒê·∫£m b·∫£o cover ƒë∆∞·ª£c c·∫£ base_name variants
            base_name_variants = self._generate_variants(base_name)
            
            all_variants = set(base_variants + base_name_variants + extra_alias)
            
            # Th√™m c·∫£ full node name (c√≥ th·ªÉ c√≥ ƒëu√¥i) v√† base name
            all_variants.add(node.lower())
            all_variants.add(base_name.lower())
            
            # QUAN TR·ªåNG: T·∫°o th√™m c√°c bi·∫øn th·ªÉ t·ª´ node name (c√≥ th·ªÉ c√≥ h·∫≠u t·ªë)
            # V√≠ d·ª•: "Luna (ca sƒ©)" ‚Üí t·∫°o variants cho c·∫£ "Luna (ca sƒ©)" v√† "Luna"
            node_lower = node.lower()
            main_name = None
            if '(' in node_lower:
                # T√°ch ph·∫ßn t√™n v√† h·∫≠u t·ªë
                parts = re.split(r'\s*\([^)]+\)\s*', node_lower)
                main_name = parts[0].strip()
                if main_name:
                    all_variants.add(main_name)
                    # T·∫°o variants t·ª´ main_name
                    main_variants = self._generate_variants(main_name)
                    all_variants.update(main_variants)
            
            # QUAN TR·ªåNG: T·∫°o n-grams t·ª´ t√™n entity ƒë·ªÉ match t·ªët h∆°n
            # V√≠ d·ª•: "Jang Won-young" ‚Üí ["jang", "won", "young", "jang won", "won young", "jang won young"]
            base_words = base_name.lower().replace('-', ' ').split()
            if len(base_words) > 1:
                # T·∫°o c√°c n-grams (1-word, 2-word, 3-word, etc.)
                for n in range(1, min(len(base_words) + 1, 5)):  # T·ªëi ƒëa 4 words
                    for i in range(len(base_words) - n + 1):
                        ngram = " ".join(base_words[i:i+n])
                        all_variants.add(ngram)
                        # Th√™m variants c·ªßa ngram
                        ngram_variants = self._generate_variants(ngram)
                        all_variants.update(ngram_variants)
            
            # QUAN TR·ªåNG: X·ª≠ l√Ω k√Ω t·ª± ƒë·∫∑c bi·ªát v√† s·ªë
            # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát nh∆∞ *, (), [] nh∆∞ng gi·ªØ l·∫°i dash v√† space
            base_clean = re.sub(r'[^\w\s-]', '', base_name.lower())
            if base_clean != base_name.lower():
                all_variants.add(base_clean)
                base_clean_variants = self._generate_variants(base_clean)
                all_variants.update(base_clean_variants)
            
            # QUAN TR·ªåNG: T·∫°o variants kh√¥ng c√≥ s·ªë (n·∫øu c√≥)
            base_no_numbers = re.sub(r'\d+', '', base_name.lower())
            if base_no_numbers != base_name.lower():
                base_no_numbers = " ".join(base_no_numbers.split())
                if base_no_numbers:
                    all_variants.add(base_no_numbers)
                    base_no_numbers_variants = self._generate_variants(base_no_numbers)
                    all_variants.update(base_no_numbers_variants)
            
            for v in all_variants:
                if len(v) < 2:
                    continue
                # Normalize: lo·∫°i b·ªè spaces th·ª´a
                v_normalized = " ".join(v.split())
                if len(v_normalized) < 2:
                    continue
                
                # Th√™m c·∫£ normalized v√† original v√†o map
                for variant_key in [v, v_normalized]:
                    if len(variant_key) < 2:
                        continue
                    
                    if variant_key not in variant_map:
                        variant_map[variant_key] = []
                    
                    # Score: ∆Øu ti√™n exact match v√† alias
                    # Exact match (base_name ho·∫∑c node) c√≥ score cao nh·∫•t
                    if variant_key == base_name.lower() or variant_key == node.lower():
                        score = 3.0  # Highest priority
                    elif variant_key in extra_alias:
                        score = 2.5  # High priority for aliases
                    elif variant_key in base_name_variants:
                        score = 2.0  # High priority for base name variants
                    elif main_name and variant_key == main_name:
                        score = 1.8  # High priority for main name (without suffix)
                    else:
                        # Default score - c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh theo label
                        if label in ['Artist', 'Group']:
                            score = 1.5  # High priority cho Artist/Group
                        elif label == 'Company':
                            score = 1.4
                        elif label in ['Song', 'Album']:
                            score = 1.3
                        else:
                            score = 1.2  # Lower priority cho c√°c types kh√°c
                    
                    # Tr√°nh duplicate entries
                    existing = [e for e in variant_map[variant_key] if e["name"] == node]
                    if not existing:
                        variant_map[variant_key].append({
                            "name": node,
                            "label": label,
                            "score": score
                        })
        
        # Sort entries by score (highest first) ƒë·ªÉ ∆∞u ti√™n exact match
        for key in variant_map:
            variant_map[key].sort(key=lambda x: x["score"], reverse=True)
        
        self._entity_variant_map = variant_map
        
    # =========== Specialized Query Methods ===========
    
    def get_group_members(self, group_name: str) -> Dict:
        """Get members of a K-pop group."""
        result = self.reasoner.get_group_members(group_name)
        return {
            "group": group_name,
            "members": result.answer_entities,
            "member_count": len(result.answer_entities),
            "answer": result.answer_text
        }
        
    def get_group_company(self, group_name: str) -> Dict:
        """Get company managing a group."""
        result = self.reasoner.get_company_of_group(group_name)
        return {
            "group": group_name,
            "company": result.answer_entities[0] if result.answer_entities else None,
            "answer": result.answer_text
        }
        
    def check_same_company(self, entity1: str, entity2: str) -> Dict:
        """Check if two entities are under the same company."""
        result = self.reasoner.check_same_company(entity1, entity2)
        return {
            "entity1": entity1,
            "entity2": entity2,
            "same_company": len(result.answer_entities) > 0,
            "common_company": result.answer_entities[0] if result.answer_entities else None,
            "answer": result.answer_text
        }
        
    def get_labelmates(self, entity: str) -> Dict:
        """Get all groups/artists under same company."""
        result = self.reasoner.get_labelmates(entity)
        return {
            "entity": entity,
            "labelmates": result.answer_entities,
            "count": len(result.answer_entities),
            "answer": result.answer_text
        }
        
    def find_path(self, source: str, target: str) -> Dict:
        """Find relationship path between two entities."""
        path = self.kg.find_path(source, target)
        
        if path:
            details = self.kg.get_path_details(path)
            path_str = " ‚Üí ".join([
                f"{d['entity']}({d['type']})" for d in details
            ])
            return {
                "source": source,
                "target": target,
                "path_found": True,
                "path": path,
                "hops": len(path) - 1,
                "description": path_str
            }
        else:
            return {
                "source": source,
                "target": target,
                "path_found": False,
                "path": [],
                "hops": -1,
                "description": f"Kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng ƒëi t·ª´ {source} ƒë·∫øn {target}"
            }
            
    def get_statistics(self) -> Dict:
        """Get chatbot and knowledge graph statistics."""
        kg_stats = self.kg.get_statistics()
        return {
            "knowledge_graph": kg_stats,
            "active_sessions": len(self.sessions),
            "llm_available": self.llm is not None,
            "embeddings_available": self.rag.embedder is not None
        }


def main():
    """Test the chatbot."""
    print("="*60)
    print("üé§ K-pop Knowledge Graph Chatbot Demo")
    print("="*60)
    
    # Initialize chatbot
    chatbot = KpopChatbot(
        llm_model="qwen2-0.5b",
        verbose=True
    )
    
    # Print statistics
    print("\nüìä Statistics:")
    stats = chatbot.get_statistics()
    print(f"  Nodes: {stats['knowledge_graph']['total_nodes']}")
    print(f"  Edges: {stats['knowledge_graph']['total_edges']}")
    print(f"  LLM: {'‚úÖ' if stats['llm_available'] else '‚ùå'}")
    print(f"  Embeddings: {'‚úÖ' if stats['embeddings_available'] else '‚ùå'}")
    
    # Test queries
    test_queries = [
        "BTS c√≥ bao nhi√™u th√†nh vi√™n?",
        "C√¥ng ty n√†o qu·∫£n l√Ω BLACKPINK?",
        "BTS v√† SEVENTEEN c√≥ c√πng c√¥ng ty kh√¥ng?",
    ]
    
    print("\n" + "="*60)
    print("üß™ Running Test Queries")
    print("="*60)
    
    session_id = chatbot.create_session()
    
    for query in test_queries:
        print(f"\n‚ùì Query: {query}")
        result = chatbot.chat(query, session_id, return_details=True)
        print(f"ü§ñ Response: {result['response']}")
        print(f"üìç Entities: {result['entities_found']}, Hops: {result['reasoning_hops']}")
        
    # Test specialized queries
    print("\n" + "="*60)
    print("üß™ Specialized Queries")
    print("="*60)
    
    print("\nüë• BTS Members:")
    result = chatbot.get_group_members("BTS")
    print(f"  {result['answer']}")
    
    print("\nüè¢ BTS Company:")
    result = chatbot.get_group_company("BTS")
    print(f"  {result['answer']}")
    
    print("\nüîç Same Company Check (BTS vs SEVENTEEN):")
    result = chatbot.check_same_company("BTS", "SEVENTEEN")
    print(f"  {result['answer']}")


if __name__ == "__main__":
    main()

