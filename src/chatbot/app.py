"""
Gradio Web Interface for K-pop Knowledge Graph Chatbot

A beautiful, interactive web interface for the K-pop chatbot
with support for:
- Multi-turn conversations
- Multi-hop reasoning visualization
- Knowledge graph exploration
- Evaluation mode
"""

import json
import os
from typing import List, Tuple, Optional
from datetime import datetime

try:
    import gradio as gr
    GRADIO_AVAILABLE = True
except ImportError:
    GRADIO_AVAILABLE = False
    print("‚ö†Ô∏è Gradio not installed. Run: pip install gradio")

from .chatbot import KpopChatbot
from .evaluation import EvaluationDatasetGenerator


# Global chatbot instance
chatbot = None


def initialize_chatbot(skip_llm: bool = False):
    """
    Initialize the chatbot.
    
    Args:
        skip_llm: If True, skip loading LLM (faster startup, graph-only mode)
    """
    global chatbot
    if chatbot is None:
        try:
            print("üîÑ Initializing K-pop Chatbot...")
            print("   (L·∫ßn ƒë·∫ßu kh·ªüi t·∫°o c√≥ th·ªÉ m·∫•t 30-60 gi√¢y...)")
            
            # Initialize without LLM first for fast startup
            chatbot = KpopChatbot(
                verbose=True,
                llm_model="qwen2-0.5b" if not skip_llm else None
            )
            print("‚úÖ Chatbot initialized successfully!")
            
        except Exception as e:
            print(f"‚ùå Failed to initialize chatbot: {e}")
            import traceback
            traceback.print_exc()
            
            # Try fallback without LLM
            try:
                print("üîÑ Retrying without LLM...")
                chatbot = KpopChatbot(verbose=True, llm_model=None)
                print("‚úÖ Chatbot initialized (graph-only mode)")
            except Exception as e2:
                print(f"‚ùå Fallback also failed: {e2}")
                raise
    return chatbot


def chat_response(
    message: str,
    history: List[List[str]],
    use_multihop: bool,
    max_hops: int
) -> Tuple[str, List[List[str]]]:
    """
    Process chat message and return response.
    
    Args:
        message: User's message
        history: Chat history
        use_multihop: Enable multi-hop reasoning
        max_hops: Maximum reasoning hops
        
    Returns:
        Tuple of (response, updated_history)
    """
    if not message.strip():
        return "", history
        
    try:
        bot = initialize_chatbot()
        
        # ‚úÖ Y√äU C·∫¶U B√ÄI T·∫¨P: Ph·∫£i d√πng Small LLM d·ª±a tr√™n ƒë·ªì th·ªã tri th·ª©c
        # LLM s·∫Ω s·ª≠ d·ª•ng context t·ª´ Knowledge Graph (GraphRAG) ƒë·ªÉ tr·∫£ l·ªùi
        use_llm = True  # Lu√¥n d√πng LLM ƒë·ªÉ ƒë√°p ·ª©ng y√™u c·∫ßu
        
        # Get response using Small LLM with Knowledge Graph context
        # Note: This may take 10-30 seconds, but UI will wait
        result = bot.chat(
            message,
            use_multi_hop=use_multihop,
            max_hops=max_hops,
            return_details=True,
            use_llm=use_llm  # D√πng Small LLM v·ªõi context t·ª´ Knowledge Graph
        )
        
        response = result['response']
        
        # Add reasoning info if available
        if result.get('reasoning', {}).get('steps'):
            steps = result['reasoning']['steps']
            response += f"\n\nüìä *Suy lu·∫≠n {len(steps)}-hop*"
            
        # Update history
        history.append([message, response])
        
    except Exception as e:
        # Handle errors gracefully
        error_msg = f"‚ùå L·ªói: {str(e)}\n\nüí° Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c ki·ªÉm tra console ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt."
        history.append([message, error_msg])
        print(f"‚ùå Error in chat_response: {e}")
        import traceback
        traceback.print_exc()
    
    return "", history


def answer_question(
    question: str,
    question_type: str,
    choices: str
) -> str:
    """
    Answer a specific question.
    
    Args:
        question: The question
        question_type: Type of question
        choices: Comma-separated choices (for MC)
        
    Returns:
        Formatted answer
    """
    if not question.strip():
        return "Vui l√≤ng nh·∫≠p c√¢u h·ªèi."
        
    try:
        bot = initialize_chatbot()
        
        if question_type == "ƒê√∫ng/Sai" or question_type == "C√≥/Kh√¥ng":
            result = bot.answer_yes_no(question, return_details=True)
            answer = f"""
### K·∫øt qu·∫£:
- **C√¢u tr·∫£ l·ªùi**: {result['answer']}
- **ƒê·ªô tin c·∫≠y**: {result['confidence']:.1%}
- **Gi·∫£i th√≠ch**: {result.get('explanation', 'N/A')}
"""
        else:
            choice_list = [c.strip() for c in choices.split(',')]
            if len(choice_list) < 2:
                return "Vui l√≤ng nh·∫≠p √≠t nh·∫•t 2 ƒë√°p √°n, c√°ch nhau b·ªüi d·∫•u ph·∫©y."
                
            result = bot.answer_multiple_choice(question, choice_list, return_details=True)
            answer = f"""
### K·∫øt qu·∫£:
- **ƒê√°p √°n**: {result['selected_letter']}. {result['selected_choice']}
- **ƒê·ªô tin c·∫≠y**: {result['confidence']:.1%}
"""
            
        return answer
    except Exception as e:
        error_msg = f"‚ùå L·ªói: {str(e)}\n\nüí° Vui l√≤ng ki·ªÉm tra console ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt."
        print(f"‚ùå Error in answer_question: {e}")
        import traceback
        traceback.print_exc()
        return error_msg


def search_entity(entity_name: str) -> str:
    """Search for an entity in the knowledge graph."""
    if not entity_name.strip():
        return "Vui l√≤ng nh·∫≠p t√™n th·ª±c th·ªÉ."
        
    try:
        bot = initialize_chatbot()
        
        results = bot.kg.search_entities(entity_name, limit=5)
        
        if not results:
            return f"Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ cho '{entity_name}'"
            
        output = f"### K·∫øt qu·∫£ t√¨m ki·∫øm cho '{entity_name}':\n\n"
        
        for r in results:
            entity_data = bot.kg.get_entity(r['id'])
            infobox = entity_data.get('infobox', {}) if entity_data else {}
            
            output += f"**{r['id']}** ({r['type']})\n"
            for key, value in list(infobox.items())[:3]:
                if value:
                    output += f"- {key}: {value}\n"
            output += "\n"
            
        return output
    except Exception as e:
        error_msg = f"‚ùå L·ªói: {str(e)}"
        print(f"‚ùå Error in search_entity: {e}")
        import traceback
        traceback.print_exc()
        return error_msg


def get_group_info(group_name: str) -> str:
    """Get detailed information about a K-pop group."""
    if not group_name.strip():
        return "Vui l√≤ng nh·∫≠p t√™n nh√≥m nh·∫°c."
        
    try:
        bot = initialize_chatbot()
        
        # Get group data
        group_data = bot.kg.get_entity(group_name)
        if not group_data:
            return f"Kh√¥ng t√¨m th·∫•y nh√≥m '{group_name}'"
            
        # Get members
        members = bot.kg.get_group_members(group_name)
        
        # Get company
        company = bot.kg.get_group_company(group_name)
        
        # Get songs
        songs = bot.kg.get_group_songs(group_name)
        
        infobox = group_data.get('infobox', {})
        
        output = f"""
### {group_name}

**Lo·∫°i**: {group_data.get('label', 'N/A')}

**Th√¥ng tin c∆° b·∫£n**:
- NƒÉm ho·∫°t ƒë·ªông: {infobox.get('NƒÉm ho·∫°t ƒë·ªông', 'N/A')}
- Th·ªÉ lo·∫°i: {infobox.get('Th·ªÉ lo·∫°i', 'N/A')}
- C√¥ng ty: {company or infobox.get('H√£ng ƒëƒ©a', 'N/A')}

**Th√†nh vi√™n** ({len(members)}):
{', '.join(members) if members else 'N/A'}

**B√†i h√°t** ({len(songs)}):
{', '.join(songs[:10]) if songs else 'N/A'}{'...' if len(songs) > 10 else ''}
"""
        
        return output
    except Exception as e:
        error_msg = f"‚ùå L·ªói: {str(e)}"
        print(f"‚ùå Error in get_group_info: {e}")
        import traceback
        traceback.print_exc()
        return error_msg


def find_relationship(entity1: str, entity2: str) -> str:
    """Find relationship path between two entities."""
    if not entity1.strip() or not entity2.strip():
        return "Vui l√≤ng nh·∫≠p c·∫£ hai th·ª±c th·ªÉ."
        
    try:
        bot = initialize_chatbot()
        
        result = bot.find_path(entity1, entity2)
        
        if result['path_found']:
            output = f"""
### ƒê∆∞·ªùng ƒëi t·ª´ {entity1} ƒë·∫øn {entity2}:

**S·ªë b∆∞·ªõc**: {result['hops']} hop(s)

**ƒê∆∞·ªùng ƒëi**: {result['description']}
"""
        else:
            output = f"Kh√¥ng t√¨m th·∫•y ƒë∆∞·ªùng ƒëi t·ª´ '{entity1}' ƒë·∫øn '{entity2}'."
            
        return output
    except Exception as e:
        error_msg = f"‚ùå L·ªói: {str(e)}"
        print(f"‚ùå Error in find_relationship: {e}")
        import traceback
        traceback.print_exc()
        return error_msg


def get_statistics() -> str:
    """Get knowledge graph statistics."""
    try:
        bot = initialize_chatbot()
        stats = bot.get_statistics()
        
        kg_stats = stats['knowledge_graph']
        
        output = f"""
### üìä Th·ªëng k√™ ƒê·ªì th·ªã Tri th·ª©c

**T·ªïng quan**:
- T·ªïng s·ªë nodes: {kg_stats['total_nodes']:,}
- T·ªïng s·ªë edges: {kg_stats['total_edges']:,}
- M·∫≠t ƒë·ªô ƒë·ªì th·ªã: {kg_stats['density']:.4f}
- B·∫≠c trung b√¨nh: {kg_stats['average_degree']:.2f}

**Ph√¢n b·ªë theo lo·∫°i th·ª±c th·ªÉ**:
"""
        
        for entity_type, count in kg_stats['entity_types'].items():
            output += f"- {entity_type}: {count:,}\n"
            
        output += "\n**Ph√¢n b·ªë theo lo·∫°i quan h·ªá**:\n"
        
        for rel_type, count in list(kg_stats['relationship_types'].items())[:10]:
            output += f"- {rel_type}: {count:,}\n"
            
        output += f"""
**Tr·∫°ng th√°i h·ªá th·ªëng**:
- LLM: {'‚úÖ Ho·∫°t ƒë·ªông' if stats['llm_available'] else '‚ùå Kh√¥ng kh·∫£ d·ª•ng'}
- Embeddings: {'‚úÖ Ho·∫°t ƒë·ªông' if stats['embeddings_available'] else '‚ùå Kh√¥ng kh·∫£ d·ª•ng'}
- Sessions ho·∫°t ƒë·ªông: {stats['active_sessions']}
"""
        
        return output
    except Exception as e:
        error_msg = f"‚ùå L·ªói: {str(e)}"
        print(f"‚ùå Error in get_statistics: {e}")
        import traceback
        traceback.print_exc()
        return error_msg


def generate_evaluation_dataset(num_questions: int) -> str:
    """Generate evaluation dataset."""
    try:
        generator = EvaluationDatasetGenerator()
        stats = generator.generate_full_dataset(
            target_count=num_questions,
            output_path="data/evaluation_dataset.json"
        )
        
        return f"""
### ‚úÖ Dataset ƒë√£ ƒë∆∞·ª£c t·∫°o!

- **T·ªïng s·ªë c√¢u h·ªèi**: {stats['total_questions']}
- **Theo s·ªë hop**: {stats['by_hops']}
- **Theo lo·∫°i c√¢u h·ªèi**: {stats['by_type']}
- **L∆∞u t·∫°i**: data/evaluation_dataset.json
"""
    except Exception as e:
        return f"‚ùå L·ªói: {str(e)}"


def create_ui():
    """Create Gradio UI."""
    if not GRADIO_AVAILABLE:
        print("‚ùå Gradio not available. Please install: pip install gradio")
        return None
        
    # Use minimal parameters for maximum compatibility with different Gradio versions
    # Create Blocks with no parameters (most compatible)
    with gr.Blocks() as app:
        gr.Markdown("""
        # üé§ K-pop Knowledge Graph Chatbot
        
        Chatbot th√¥ng minh v·ªÅ K-pop s·ª≠ d·ª•ng **ƒë·ªì th·ªã tri th·ª©c** v√† **suy lu·∫≠n multi-hop**.
        
        > üí° *Powered by GraphRAG + Small LLM (Qwen2-0.5B)*
        > 
        > ‚è≥ **L∆∞u √Ω:** C√°c c√¢u h·ªèi c√≥ th·ªÉ m·∫•t 10-30 gi√¢y ƒë·ªÉ x·ª≠ l√Ω. Vui l√≤ng ki√™n nh·∫´n ƒë·ª£i, ch∆∞∆°ng tr√¨nh s·∫Ω kh√¥ng b·ªã d·ª´ng!
        """)
        
        with gr.Tabs():
            # Tab 1: Chat
            with gr.Tab("üí¨ Tr√≤ chuy·ªán"):
                chatbot_ui = gr.Chatbot(
                    label="Chat",
                    height=400
                )
                
                with gr.Row():
                    msg = gr.Textbox(
                        placeholder="H·ªèi v·ªÅ K-pop... (VD: BTS c√≥ bao nhi√™u th√†nh vi√™n?)",
                        label="C√¢u h·ªèi"
                    )
                    submit_btn = gr.Button("G·ª≠i üöÄ")
                    
                with gr.Row():
                    use_multihop = gr.Checkbox(
                        label="Suy lu·∫≠n Multi-hop",
                        value=True
                    )
                    max_hops = gr.Slider(
                        minimum=1,
                        maximum=5,
                        value=3,
                        step=1,
                        label="Max hops"
                    )
                    clear_btn = gr.Button("X√≥a üóëÔ∏è")
                    
                gr.Markdown("""
                > üí° **G·ª£i √Ω:** 
                > - Chatbot s·ª≠ d·ª•ng ch·∫ø ƒë·ªô nhanh (graph-only) tr∆∞·ªõc, sau ƒë√≥ m·ªõi d√πng LLM n·∫øu c·∫ßn.
                > - ƒê·ªÉ c√≥ c√¢u tr·∫£ l·ªùi nhanh nh·∫•t, h·ªèi v·ªÅ: th√†nh vi√™n, c√¥ng ty, c√πng c√¥ng ty, nh√≥m nh·∫°c...
                > - ‚è≥ **L∆∞u √Ω:** C√¢u h·ªèi c√≥ th·ªÉ m·∫•t 10-30 gi√¢y ƒë·ªÉ x·ª≠ l√Ω. Vui l√≤ng ƒë·ª£i, UI s·∫Ω kh√¥ng b·ªã d·ª´ng!
                """)
                    
                # Event handlers - queue parameter may not be available in older Gradio versions
                # If queue is not supported, Gradio will still process requests, just without queuing
                try:
                    submit_btn.click(
                        chat_response,
                        inputs=[msg, chatbot_ui, use_multihop, max_hops],
                        outputs=[msg, chatbot_ui],
                        queue=True  # Enable queue for long-running tasks (if supported)
                    )
                    msg.submit(
                        chat_response,
                        inputs=[msg, chatbot_ui, use_multihop, max_hops],
                        outputs=[msg, chatbot_ui],
                        queue=True  # Enable queue for long-running tasks (if supported)
                    )
                except TypeError:
                    # Fallback for older Gradio versions without queue parameter
                    submit_btn.click(
                        chat_response,
                        inputs=[msg, chatbot_ui, use_multihop, max_hops],
                        outputs=[msg, chatbot_ui]
                    )
                    msg.submit(
                        chat_response,
                        inputs=[msg, chatbot_ui, use_multihop, max_hops],
                        outputs=[msg, chatbot_ui]
                    )
                clear_btn.click(lambda: (None, []), outputs=[msg, chatbot_ui])
                
            # Tab 2: Question Answering
            with gr.Tab("‚ùì H·ªèi ƒë√°p"):
                gr.Markdown("### Tr·∫£ l·ªùi c√¢u h·ªèi ƒê√∫ng/Sai, C√≥/Kh√¥ng, ho·∫∑c Tr·∫Øc nghi·ªám")
                
                question_input = gr.Textbox(
                    label="C√¢u h·ªèi",
                    placeholder="VD: BTS thu·ªôc c√¥ng ty HYBE ƒë√∫ng kh√¥ng?"
                )
                
                question_type = gr.Radio(
                    choices=["ƒê√∫ng/Sai", "C√≥/Kh√¥ng", "Tr·∫Øc nghi·ªám"],
                    label="Lo·∫°i c√¢u h·ªèi",
                    value="C√≥/Kh√¥ng"
                )
                
                choices_input = gr.Textbox(
                    label="ƒê√°p √°n (cho tr·∫Øc nghi·ªám, c√°ch nhau b·ªüi d·∫•u ph·∫©y)",
                    placeholder="HYBE, SM Entertainment, JYP Entertainment, YG Entertainment",
                    visible=True
                )
                
                answer_btn = gr.Button("Tr·∫£ l·ªùi")
                answer_output = gr.Markdown(label="K·∫øt qu·∫£")
                
                answer_btn.click(
                    answer_question,
                    inputs=[question_input, question_type, choices_input],
                    outputs=answer_output
                )
                
            # Tab 3: Knowledge Graph Explorer
            with gr.Tab("üîç Kh√°m ph√°"):
                gr.Markdown("### Kh√°m ph√° ƒê·ªì th·ªã Tri th·ª©c K-pop")
                
                with gr.Row():
                    with gr.Column():
                        search_input = gr.Textbox(
                            label="T√¨m th·ª±c th·ªÉ",
                            placeholder="VD: BTS, BLACKPINK, Jungkook..."
                        )
                        search_btn = gr.Button("T√¨m ki·∫øm üîç")
                        search_output = gr.Markdown()
                        
                    with gr.Column():
                        group_input = gr.Textbox(
                            label="Th√¥ng tin nh√≥m nh·∫°c",
                            placeholder="VD: BTS"
                        )
                        group_btn = gr.Button("Xem chi ti·∫øt üìã")
                        group_output = gr.Markdown()
                        
                search_btn.click(search_entity, inputs=search_input, outputs=search_output)
                group_btn.click(get_group_info, inputs=group_input, outputs=group_output)
                
                gr.Markdown("### T√¨m m·ªëi quan h·ªá")
                
                with gr.Row():
                    entity1_input = gr.Textbox(label="Th·ª±c th·ªÉ 1", placeholder="VD: Jungkook")
                    entity2_input = gr.Textbox(label="Th·ª±c th·ªÉ 2", placeholder="VD: HYBE")
                    
                path_btn = gr.Button("T√¨m ƒë∆∞·ªùng ƒëi üîó")
                path_output = gr.Markdown()
                
                path_btn.click(
                    find_relationship,
                    inputs=[entity1_input, entity2_input],
                    outputs=path_output
                )
                
            # Tab 4: Statistics
            with gr.Tab("üìä Th·ªëng k√™"):
                stats_btn = gr.Button("C·∫≠p nh·∫≠t th·ªëng k√™ üìà")
                stats_output = gr.Markdown()
                
                stats_btn.click(get_statistics, outputs=stats_output)
                
            # Tab 5: Evaluation
            with gr.Tab("üìù ƒê√°nh gi√°"):
                gr.Markdown("""
                ### T·∫°o Dataset ƒê√°nh gi√°
                
                T·∫°o t·∫≠p d·ªØ li·ªáu c√¢u h·ªèi ƒë·ªÉ ƒë√°nh gi√° chatbot v·ªõi c√°c lo·∫°i:
                - C√¢u h·ªèi ƒê√∫ng/Sai
                - C√¢u h·ªèi C√≥/Kh√¥ng
                - C√¢u h·ªèi Tr·∫Øc nghi·ªám
                - Suy lu·∫≠n 1-hop, 2-hop, 3-hop
                """)
                
                num_questions = gr.Slider(
                    minimum=100,
                    maximum=5000,
                    value=2000,
                    step=100,
                    label="S·ªë l∆∞·ª£ng c√¢u h·ªèi"
                )
                
                generate_btn = gr.Button("T·∫°o Dataset üìù")
                generate_output = gr.Markdown()
                
                generate_btn.click(
                    generate_evaluation_dataset,
                    inputs=num_questions,
                    outputs=generate_output
                )
                
        gr.Markdown("""
        ---
        *Made with ‚ù§Ô∏è for K-pop fans | Using GraphRAG + Multi-hop Reasoning*
        """)
        
    return app


def main():
    """Run the Gradio app."""
    if not GRADIO_AVAILABLE:
        print("‚ùå Gradio not available. Please install: pip install gradio")
        return
        
    # Pre-initialize chatbot
    initialize_chatbot()
    
    # Create and launch app
    app = create_ui()
    
    if app:
        print("\nüöÄ Launching K-pop Chatbot UI...")
        print("üí° L∆∞u √Ω: C√°c c√¢u h·ªèi c√≥ th·ªÉ m·∫•t 10-30 gi√¢y ƒë·ªÉ x·ª≠ l√Ω.")
        print("   UI s·∫Ω hi·ªÉn th·ªã 'ƒêang x·ª≠ l√Ω...' trong l√∫c ch·ªù.\n")
        
        # Try with max_threads, fallback if not supported
        try:
            app.launch(
                server_name="0.0.0.0",
                server_port=7860,
                share=False,
                show_error=True,
                max_threads=10  # Allow multiple concurrent requests
            )
        except TypeError:
            # Fallback for older Gradio versions
            app.launch(
                server_name="0.0.0.0",
                server_port=7860,
                share=False
            )


if __name__ == "__main__":
    main()

