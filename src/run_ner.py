# -*- coding: utf-8 -*-
"""
MÃ” HÃŒNH NHáº¬N Dáº NG THá»°C THá»‚ K-POP (TÃCH Há»¢P Bá»˜ Lá»ŒC)
===================================================
1. Nháº­n dáº¡ng entities tá»« vÄƒn báº£n Wikipedia
2. Lá»c theo context K-pop
3. Loáº¡i bá» entities khÃ´ng há»£p lá»‡
"""
import sys
import io
import json
import re
import argparse
from collections import defaultdict
from datetime import datetime
from typing import Dict, Set

# Parse command line arguments
parser = argparse.ArgumentParser(description='K-pop NER: Rule-based vÃ  ML-based')
parser.add_argument('--rule-only', '--no-ml', action='store_true',
                    help='Chá»‰ cháº¡y rule-based NER, khÃ´ng dÃ¹ng ML-based')
args = parser.parse_args()

# Import ML-based NER module
if args.rule_only:
    ML_NER_AVAILABLE = False
    print("âš ï¸  Cháº¿ Ä‘á»™ --rule-only: Chá»‰ sá»­ dá»¥ng rule-based NER")
else:
    try:
        from ml_ner import extract_ml_entities, get_ner_model
        ML_NER_AVAILABLE = True
    except ImportError:
        ML_NER_AVAILABLE = False
        print("âš ï¸  ml_ner module khÃ´ng kháº£ dá»¥ng. Chá»‰ sá»­ dá»¥ng rule-based NER.")

if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

print("=" * 70)
if args.rule_only:
    print("MÃ” HÃŒNH NHáº¬N Dáº NG THá»°C THá»‚ K-POP (RULE-BASED ONLY)")
else:
    print("MÃ” HÃŒNH NHáº¬N Dáº NG THá»°C THá»‚ K-POP (HYBRID: RULE-BASED + ML)")
print("=" * 70)

# Khá»Ÿi táº¡o ML model náº¿u cÃ³
if ML_NER_AVAILABLE:
    print("\nğŸ¤– Äang khá»Ÿi táº¡o ML-based NER model...")
    try:
        ml_model = get_ner_model()
        if ml_model and ml_model.available:
            print("  âœ“ ML model Ä‘Ã£ sáºµn sÃ ng")
        else:
            print("  âš ï¸  ML model khÃ´ng kháº£ dá»¥ng, chá»‰ sá»­ dá»¥ng rule-based")
    except Exception as e:
        print(f"  âš ï¸  Lá»—i khá»Ÿi táº¡o ML model: {e}")
        print("  â†’ Chá»‰ sá»­ dá»¥ng rule-based NER")
else:
    print("\nâš ï¸  ML-based NER khÃ´ng kháº£ dá»¥ng, chá»‰ sá»­ dá»¥ng rule-based")

# =====================================================
# Tá»ª KHÃ“A K-POP (Ä‘á»ƒ kiá»ƒm tra context)
# =====================================================
KPOP_KEYWORDS = {
    # Thuáº­t ngá»¯ K-pop
    'k-pop', 'kpop', 'k pop', 'idol', 'idols', 'tháº§n tÆ°á»£ng',
    'debut', 'ra máº¯t', 'comeback', 'trá»Ÿ láº¡i', 'fandom', 'fan',
    'trainee', 'thá»±c táº­p sinh', 'agency', 'entertainment',
    'mv', 'music video', 'teaser', 'concept', 'mini album', 'ep',
    'title track', 'ca khÃºc chá»§ Ä‘á»', 'báº£ng xáº¿p háº¡ng', 'chart',
    'melon', 'gaon', 'billboard', 'inkigayo', 'music bank', 'm countdown',
    'daesang', 'bonsang', 'rookie', 'tÃ¢n binh', 'world tour',
    # Quá»‘c gia
    'hÃ n quá»‘c', 'korea', 'korean', 'seoul', 'nam hÃ n',
    # Vai trÃ²
    'nhÃ³m nháº¡c', 'ca sÄ©', 'rapper', 'dancer', 'vocal', 'main vocal',
    'lead vocal', 'sub vocal', 'main dancer', 'lead dancer',
    'main rapper', 'leader', 'trÆ°á»Ÿng nhÃ³m', 'maknae', 'visual', 'center',
    # CÃ´ng ty
    'sm entertainment', 'jyp entertainment', 'yg entertainment', 'hybe',
    'cube entertainment', 'starship', 'pledis', 'fnc', 'woollim',
    'rbw', 'wm entertainment', 'dsp media', 'mbk', 'jellyfish',
    'big hit', 'source music', 'kq entertainment', 'ist entertainment',
    # NhÃ³m nháº¡c ná»•i tiáº¿ng
    'bts', 'blackpink', 'twice', 'exo', 'nct', 'aespa', 'ive', 'newjeans',
    'stray kids', 'seventeen', 'txt', 'enhypen', 'le sserafim', 'itzy',
    'red velvet', 'girls generation', 'snsd', 'super junior', 'shinee',
    'got7', 'monsta x', 'ateez', 'the boyz', 'treasure', 'bigbang',
    '2ne1', 'wonder girls', 'f(x)', 'mamamoo', 'gfriend', 'apink',
    'oh my girl', 'loona', 'fromis_9', 'wjsn', 'everglow', 'dreamcatcher',
}

# =====================================================
# Tá»ª KHÃ”NG Há»¢P Lá»† (CHUNG CHUNG, KHÃ”NG PHáº¢I TÃŠN RIÃŠNG)
# =====================================================
INVALID_WORDS = {
    # Tiáº¿ng Anh chung
    'the', 'a', 'an', 'and', 'or', 'but', 'is', 'was', 'are', 'were',
    'has', 'have', 'had', 'been', 'to', 'for', 'of', 'in', 'on', 'at',
    'by', 'with', 'about', 'as', 'this', 'that', 'these', 'those',
    'my', 'your', 'his', 'her', 'its', 'our', 'their', 'it', 'he', 'she',
    
    # Tiáº¿ng Viá»‡t chung
    'cá»§a', 'lÃ ', 'vÃ ', 'vá»›i', 'trong', 'cÃ³', 'Ä‘Æ°á»£c', 'tá»«', 'nÃ y', 'Ä‘Ã³',
    'nÄƒm', 'thÃ¡ng', 'ngÃ y', 'sau', 'trÆ°á»›c', 'cÅ©ng', 'nhÆ°', 'khi', 'náº¿u',
    'bÃ i', 'hÃ¡t', 'ca', 'khÃºc', 'album', 'single', 'ep', 'mv',
    
    # Tá»« bá»‹ nháº­n nháº§m thÆ°á»ng gáº·p
    'aideul', 'n nay', 'ch', 'hottest rookies', 'i-land', 'who am i',
    'version', 'ver', 'remix', 'inst', 'instrumental', 'acoustic',
    'live', 'repackage', 'repack', 'special', 'deluxe', 'limited',
    
    # Thuáº­t ngá»¯ K-pop (khÃ´ng pháº£i tÃªn riÃªng)
    'k-pop', 'kpop', 'k pop', 'idol', 'idols', 'chart', 'charts',
    'gaon', 'oricon', 'billboard', 'melon', 'hanteo',
    'sales', 'vol', 'vol.', 'mr', 'mr.', 'ms', 'ms.',
    'producer', 'school', 'corp', 'corp.', 'inc', 'inc.',
    'lands no', 'earns madison beer', 'k-pop big bang',
    
    # Viáº¿t táº¯t ngáº¯n vÃ´ nghÄ©a (1-2 kÃ½ tá»±)
    'al', 'ba', 'be', 'bo', 'bu', 'don', 'dr', 'el', 'fi', 'fo',
    'ga', 'go', 'ha', 'he', 'hi', 'ho', 'hu', 'i.o', 'h.o', 'fin',
    'ja', 'ji', 'jo', 'ju', 'ka', 'ki', 'ko', 'ku', 'la', 'le',
    'li', 'lo', 'lu', 'ma', 'me', 'mi', 'mo', 'mu', 'na', 'ne',
    'ni', 'no', 'nu', 'pa', 'pe', 'pi', 'po', 'pu', 'ra', 're',
    'ri', 'ro', 'ru', 'sa', 'se', 'si', 'so', 'su', 'ta', 'te',
    'ti', 'to', 'tu', 'va', 've', 'vi', 'vo', 'vu', 'wa', 'we',
    'wi', 'wo', 'wu', 'xa', 'xe', 'xi', 'xo', 'xu', 'ya', 'ye',
    'yi', 'yo', 'yu', 'za', 'ze', 'zi', 'zo', 'zu',
    
    # Suffix cÃ´ng ty (khÃ´ng pháº£i nhÃ³m nháº¡c)
    'n.v', 'n.v.', 'inc', 'inc.', 'ltd', 'ltd.', 'corp', 'corp.',
    'llc', 'llc.', 'co', 'co.', 'plc', 'plc.',
    
    # Tá»« chung khÃ¡c
    'always', 'back', 'best', 'big', 'new', 'old', 'good', 'bad',
    'first', 'last', 'next', 'top', 'hit', 'hot', 'cool', 'nice',
    'love', 'like', 'want', 'need', 'know', 'think', 'feel',
    'day', 'night', 'time', 'year', 'week', 'month',
    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten',
    'beautiful', 'because of you', 'bo peep',
    
    # Tá»« tá»•ng quÃ¡t vá» media/technology (khÃ´ng pháº£i tÃªn nghá»‡ sÄ©/album/bÃ i hÃ¡t)
    'video', 'audio', 'music', 'clip', 'film', 'movie', 'photo', 'picture',
    'image', 'graphic', 'media', 'content', 'file', 'download', 'stream',
    'playback', 'recording', 'broadcast', 'television', 'tv', 'radio',
    
    # ChÆ°Æ¡ng trÃ¬nh thá»±c táº¿/Show (khÃ´ng pháº£i nghá»‡ sÄ©)
    'contest', 'season', 'episode', 'show', 'program', 'programme',
    'dictation contest', 'singing contest', 'dance contest',
    'audition', 'survival', 'competition', 'challenge',
    'talk tv', 'idol room', 'idol world', 'idol room', 'idol world',
    'team b', 'team a', 'team c', 'team d', 'team 8',  # CÃ¡c team chung chung
    'mbc ep', 'radio', 'school class', 'idol maknae rebellion',
    'ost', 'producer idol producer', 'new storm',
    'to the beautiful you',  # Phim
    'hits mr',  # Node sai
    'idol intern king', 'idol maknae rebellion',  # ChÆ°Æ¡ng trÃ¬nh cÃ³ chá»¯ Idol
    'intern king', 'maknae rebellion',  # TÃªn chÆ°Æ¡ng trÃ¬nh (khÃ´ng cáº§n chá»¯ idol á»Ÿ Ä‘áº§u)
    'debut countdown',  # ChÆ°Æ¡ng trÃ¬nh Ä‘áº¿m ngÆ°á»£c
    'dream team',  # ChÆ°Æ¡ng trÃ¬nh Let's Go Dream Team
}

# =====================================================
# Äá»ŠA DANH (KHÃ”NG PHáº¢I NGHá»† SÄ¨/NHÃ“M)
# =====================================================
LOCATION_NAMES = {
    'seoul', 'san francisco', 'busan', 'tokyo', 'osaka',
    'new york', 'los angeles', 'london', 'paris', 'berlin',
    'sydney', 'melbourne', 'bangkok', 'singapore', 'hong kong',
    'taipei', 'beijing', 'shanghai', 'mumbai', 'delhi',
    'manila', 'jakarta', 'kuala lumpur', 'ho chi minh',
    # Quáº­n/huyá»‡n HÃ n Quá»‘c thÆ°á»ng xuáº¥t hiá»‡n trong pháº§n nÆ¡i sinh
    'dongdaemun-gu', 'dongdaemun gu',
}

# =====================================================
# Tá»ª KHÃ“A QUá»C GIA KHÃ”NG PHáº¢I HÃ€N QUá»C
# =====================================================
NON_KOREAN_COUNTRIES = {
    # TÃªn quá»‘c gia tiáº¿ng Anh
    'malaysia', 'malaysian', 'thailand', 'thai', 'vietnam', 'vietnamese',
    'indonesia', 'indonesian', 'philippines', 'filipino', 'filipina',
    'singapore', 'singaporean', 'china', 'chinese', 'taiwan', 'taiwanese',
    'japan', 'japanese', 'india', 'indian', 'usa', 'american', 'america',
    'uk', 'british', 'england', 'english', 'australia', 'australian',
    'canada', 'canadian', 'france', 'french', 'germany', 'german',
    'brazil', 'brazilian', 'mexico', 'mexican', 'spain', 'spanish',
    'italy', 'italian', 'russia', 'russian', 'hong kong',
    'puerto rico', 'puerto rican',
    
    # TÃªn quá»‘c gia tiáº¿ng Viá»‡t  
    'má»¹', 'nháº­t báº£n', 'trung quá»‘c', 'Ä‘Ã i loan', 'thÃ¡i lan', 'malaysia',
    'indonesia', 'philippines', 'singapore', 'áº¥n Ä‘á»™', 'Ãºc', 'anh',
    'phÃ¡p', 'Ä‘á»©c', 'Ã½', 'nga', 'brazil', 'canada',
}

# =====================================================
# Tá»ª KHÃ“A CHá»ˆ CHÆ¯Æ NG TRÃŒNH/SHOW (KHÃ”NG PHáº¢I NGHá»† SÄ¨)
# =====================================================
SHOW_KEYWORDS = {
    'contest', 'season', 'episode', 'show', 'program', 'programme',
    'audition', 'survival', 'competition', 'challenge', 'festival',
    'awards', 'award', 'ceremony', 'gala', 'concert tour',
    'dictation', 'singing', 'dance', 'talent', 'reality',
    'championship', 'tournament', 'battle', 'game', 'quiz',
    'talk tv', 'idol room', 'idol world', 'room', 'world',
    'tv', 'television', 'broadcast', 'variety',
    'radio', 'school class', 'idol maknae rebellion',
    'mbc ep', 'ep 347', 'ep ', ' ep',  # Pattern chÆ°Æ¡ng trÃ¬nh truyá»n hÃ¬nh
    'ost', 'producer idol producer',  # OST vÃ  Producer
    'intern king', 'maknae rebellion',  # TÃªn chÆ°Æ¡ng trÃ¬nh (khÃ´ng cáº§n chá»¯ idol á»Ÿ Ä‘áº§u)
}

# =====================================================
# BLACKLIST CA SÄ¨ NÆ¯á»šC NGOÃ€I (KHÃ”NG PHáº¢I K-POP)
# =====================================================
FOREIGN_ARTIST_BLACKLIST = {
    # Ca sÄ© Viá»‡t Nam
    'thu minh', 'má»¹ tÃ¢m', 'há»“ng nhung', 'thanh lam', 'hÃ  tráº§n',
    'Ä‘Ã m vÄ©nh hÆ°ng', 'lam trÆ°á»ng', 'Ä‘an trÆ°á»ng', 'sÆ¡n tÃ¹ng m-tp',
    'soobin hoÃ ng sÆ¡n', 'sÆ¡n tÃ¹ng', 'Ä‘á»©c phÃºc', 'minh háº±ng',
    'hÆ°Æ¡ng trÃ m', 'hoa minzy', 'minh háº±ng', 'chi pu',
    
    # Ca sÄ© Má»¹/Quá»‘c táº¿
    'nicki minaj', 'cardi b', 'ariana grande', 'taylor swift',
    'beyoncÃ©', 'rihanna', 'lady gaga', 'katy perry', 'selena gomez',
    'justin bieber', 'ed sheeran', 'bruno mars', 'the weeknd',
    'drake', 'post malone', 'billie eilish', 'dua lipa',
    'adele', 'shakira', 'jennifer lopez', 'madonna',
    'mariah carey', 'arnold', 'lionel richie',
    'britney spears', 'hilary duff', 'michael jackson',
    
    # Ca sÄ© Nháº­t Báº£n
    'utada hikaru', 'ayumi hamasaki', 'namie amuro', 'boa',  # BoA lÃ  K-pop nhÆ°ng cáº§n kiá»ƒm tra context
    
    # Ca sÄ© Trung Quá»‘c
    'wang lee hom', 'jay chou', 'jolin tsai', 'g.e.m',
    
    # Ca sÄ© ThÃ¡i Lan
    'lisa',  # Cáº§n kiá»ƒm tra context (cÃ³ thá»ƒ lÃ  Lisa cá»§a BLACKPINK)
    
    # Ca sÄ© Malaysia
    'mizz nina', 'yuna',
}

# =====================================================
# Tá»ª THá»ªA Cáº¦N LOáº I Bá» á» CUá»I TÃŠN
# =====================================================
SUFFIX_WORDS_TO_REMOVE = {
    'rapping', 'singing', 'dancing', 'performing', 'performer',
    'singer', 'rapper', 'dancer', 'idol', 'artist', 'vocalist',
    'producer', 'composer', 'songwriter', 'musician',
    'ca sÄ©', 'nghá»‡ sÄ©', 'tháº§n tÆ°á»£ng', 'rapper', 'dancer',
}

# =====================================================
# THá»‚ LOáº I NHáº C (KHÃ”NG PHáº¢I NGHá»† SÄ¨)
# =====================================================
MUSIC_GENRES = {
    'hip-hop', 'hip hop', 'hiphop', 'rap', 'r&b', 'rnb',
    'pop', 'rock', 'jazz', 'blues', 'country', 'folk',
    'electronic', 'edm', 'house', 'techno', 'trance',
    'classical', 'opera', 'reggae', 'salsa', 'latin',
    'k-pop', 'kpop', 'j-pop', 'jpop', 'c-pop', 'cpop',
    'ballad', 'dance', 'trot', 'indie', 'alternative',
    'metal', 'punk', 'grunge', 'soul', 'funk', 'disco',
    'gospel', 'christian', 'gospel', 'world music',
}

# =====================================================
# TÃŠN NHÃ“M NHáº C K-POP ÄÃƒ BIáº¾T (Ä‘á»ƒ phÃ¡t hiá»‡n pattern "Group + Member")
# =====================================================
KNOWN_KPOP_GROUPS = {
    'exo', 'girls generation', "girls' generation", 'snsd',
    'bts', 'blackpink', 'twice', 'nct', 'aespa', 'ive',
    'newjeans', 'stray kids', 'seventeen', 'txt', 'enhypen',
    'le sserafim', 'itzy', 'red velvet', 'super junior',
    'shinee', 'got7', 'monsta x', 'ateez', 'the boyz',
    'treasure', 'bigbang', '2ne1', 'wonder girls', 'f(x)',
    'mamamoo', 'gfriend', 'apink', 'oh my girl', 'loona',
    'fromis_9', 'wjsn', 'everglow', 'dreamcatcher',
    'block b', 't-ara', 'kara', 'sistar', 'miss a',
    '4minute', '2pm', '2am', 'shinee', 'infinite',
    'beast', 'highlight', 'b1a4', 'cnblue', 'ftisland',
    'kara', 'after school', 'orange caramel', 'rainbow',
    'nine muses', 'girls day', 'aoa', 'exid', 'crayon pop',
    'ladies code', 'bestie', 'stellar', 'sonamoo',
    # ThÃªm cÃ¡c nhÃ³m nháº¡c Ä‘Ã£ biáº¿t
    'one day', 'onetwo', 'pentagon', 'rania', 'sm rookies',
    'seeya', 'shinhwa', 'the ark', 'vixx', 'wanna one',
    'up10tion', 'bonus baby',
    'hello venus', 'cosmic girls',
    # Bá»• sung thÃªm cÃ¡c nhÃ³m má»›i Ä‘á»ƒ trÃ¡nh pattern "Group + Member" bá»‹ giá»¯ lÃ m Artist
    'x1',
}

# =====================================================
# Tá»ª KHÃ“A XÃC Äá»ŠNH LÃ€ NGHá»† SÄ¨ Ã‚M NHáº C (Artist pháº£i cÃ³)
# =====================================================
MUSIC_ROLE_KEYWORDS = {
    'ca sÄ©', 'nghá»‡ sÄ©', 'rapper', 'dancer', 'idol', 'tháº§n tÆ°á»£ng',
    'vocalist', 'main vocal', 'lead vocal', 'sub vocal',
    'main rapper', 'lead rapper', 'main dancer', 'lead dancer',
    'thÃ nh viÃªn', 'cá»±u thÃ nh viÃªn', 'leader', 'trÆ°á»Ÿng nhÃ³m', 'maknae',
    'visual', 'center', 'all-rounder', 'producer', 'nhÃ  sáº£n xuáº¥t',
    'sÃ¡ng tÃ¡c', 'viáº¿t nháº¡c', 'composer', 'songwriter',
}

# =====================================================
# Tá»ª KHÃ“A LOáº I TRá»ª (KHÃ”NG PHáº¢I NGHá»† SÄ¨ Ã‚M NHáº C)
# =====================================================
EXCLUDE_KEYWORDS = {
    'diá»…n viÃªn', 'actor', 'actress', 'Ä‘áº¡o diá»…n', 'director',
    'nhÃ  vÄƒn', 'tÃ¡c giáº£', 'writer', 'author', 'tiá»ƒu thuyáº¿t',
    'mc', 'ngÆ°á»i dáº«n chÆ°Æ¡ng trÃ¬nh', 'host', 'å¸ä¼š',
    'váº­n Ä‘á»™ng viÃªn', 'cáº§u thá»§', 'athlete', 'player', 'football',
    'chÃ­nh trá»‹ gia', 'politician', 'tá»•ng thá»‘ng', 'president', 'bá»™ trÆ°á»Ÿng',
    'doanh nhÃ¢n', 'businessman', 'ceo', 'giÃ¡m Ä‘á»‘c',
    'giÃ¡o sÆ°', 'professor', 'bÃ¡c sÄ©', 'doctor', 'luáº­t sÆ°',
    'youtuber', 'streamer', 'influencer', 'tiktoker',
    'ngÆ°á»i máº«u', 'model', 'siÃªu máº«u',
}

# =====================================================
# CÃ”NG TY K-POP ÄÃƒ BIáº¾T
# =====================================================
KNOWN_COMPANIES = {
    'SM Entertainment', 'JYP Entertainment', 'YG Entertainment', 'HYBE',
    'Cube Entertainment', 'Starship Entertainment', 'Pledis Entertainment',
    'FNC Entertainment', 'Woollim Entertainment', 'RBW Entertainment',
    'WM Entertainment', 'DSP Media', 'MBK Entertainment',
    'Jellyfish Entertainment', 'Stone Music Entertainment',
    'Kakao Entertainment', 'CJ ENM', 'Big Hit Entertainment',
    'Source Music', 'KQ Entertainment', 'IST Entertainment',
    'Fantagio', 'Brand New Music', 'P Nation', 'AOMG',
    'H1GHR MUSIC', 'Antenna', 'TOP Media', 'Mystic Story',
    'ADOR', 'Belift Lab', 'Play M Entertainment',
}

# =====================================================
# Há»Œ HÃ€N QUá»C
# =====================================================
KOREAN_SURNAMES = {
    'Kim', 'Lee', 'Park', 'Choi', 'Jung', 'Jang', 'Cho', 'Kang', 'Yoon',
    'Shin', 'Han', 'Oh', 'Seo', 'Kwon', 'Hwang', 'Ahn', 'Song', 'Jeon',
    'Moon', 'Yang', 'Hong', 'Bae', 'Baek', 'Lim', 'Im', 'Ryu', 'Yoo',
    'Nam', 'Sim', 'Ha', 'Woo', 'Ji', 'Min', 'Cha', 'Jo', 'Noh', 'Ko',
}

# =====================================================
# HÃ€M CHUáº¨N HÃ“A TÃŠN (PHáº¢I Äá»ŠNH NGHÄ¨A TRÆ¯á»šC KHI Sá»¬ Dá»¤NG)
# =====================================================
def normalize_for_comparison(name: str) -> str:
    """
    Chuáº©n hÃ³a tÃªn Ä‘á»ƒ so sÃ¡nh (loáº¡i bá» khoáº£ng tráº¯ng, dáº¥u gáº¡ch ná»‘i, dáº¥u gáº¡ch dÆ°á»›i, lowercase)
    Äá»’NG Bá»˜ HÃ“A Vá»šI merge_and_import_neo4j.py Ä‘á»ƒ Ä‘áº£m báº£o cÃ¹ng cÃ¡ch chuáº©n hÃ³a
    
    Xá»­ lÃ½ cÃ¡c trÆ°á»ng há»£p:
    - "Ahn Ji-young" vs "Ahn Ji young" -> cÃ¹ng má»™t node
    - "Miyeon" vs "Miyeon (ca sÄ©)" -> cÃ¹ng má»™t node
    - "Cho Mi-yeon" vs "Miyeon" -> cÃ³ thá»ƒ match náº¿u dÃ¹ng substring matching
    """
    if not name:
        return ""
    
    # DÃ¹ng clean_text Ä‘á»ƒ chuáº©n hÃ³a cÆ¡ báº£n (loáº¡i bá» suffix, normalize khoáº£ng tráº¯ng)
    normalized = clean_text(name)
    
    # Loáº¡i bá» khoáº£ng tráº¯ng, dáº¥u gáº¡ch ná»‘i, dáº¥u gáº¡ch dÆ°á»›i vÃ  lowercase Ä‘á»ƒ so sÃ¡nh
    # Äiá»u nÃ y giÃºp match "Ahn Ji-young" vá»›i "Ahn Ji young"
    normalized = normalized.lower().replace(' ', '').replace('-', '').replace('_', '')
    return normalized

def clean_text(text):
    """LÃ m sáº¡ch text vÃ  loáº¡i bá» tá»« thá»«a á»Ÿ Ä‘áº§u/cuá»‘i"""
    text = text.strip()
    
    # ============================================
    # LOáº I Bá» TIá»€N Tá» "Kpop", "K-pop", "K pop" á» Äáº¦U
    # ============================================
    # Pattern: "Kpop BTS" -> "BTS", "K-pop Blackpink" -> "Blackpink"
    text = re.sub(r'^(?:k[\s\-]?pop|kpop|k-pop|k\s+pop)\s+', '', text, flags=re.IGNORECASE)
    
    # Xá»­ lÃ½ dáº¥u ngoáº·c Ä‘Æ¡n chÆ°a Ä‘Ã³ng (vÃ­ dá»¥: "Euiwoong (Lew" -> "Euiwoong Lew")
    # TÃ¬m cÃ¡c pattern cÃ³ dáº¥u má»Ÿ ngoáº·c nhÆ°ng khÃ´ng cÃ³ dáº¥u Ä‘Ã³ng ngoáº·c
    if '(' in text and text.count('(') > text.count(')'):
        # CÃ³ dáº¥u má»Ÿ ngoáº·c nhÆ°ng khÃ´ng Ä‘Ã³ng -> chuyá»ƒn pháº§n trong ngoáº·c thÃ nh text bÃ¬nh thÆ°á»ng
        # Pattern: "Name (Incomplete" -> "Name Incomplete"
        # TÃ¬m vá»‹ trÃ­ dáº¥u má»Ÿ ngoáº·c cuá»‘i cÃ¹ng khÃ´ng cÃ³ dáº¥u Ä‘Ã³ng
        last_open = text.rfind('(')
        if last_open != -1:
            # Láº¥y pháº§n trÆ°á»›c dáº¥u má»Ÿ ngoáº·c vÃ  pháº§n sau (bá» dáº¥u má»Ÿ ngoáº·c)
            before = text[:last_open].strip()
            after = text[last_open+1:].strip()
            # Gá»™p láº¡i vá»›i khoáº£ng tráº¯ng
            text = f"{before} {after}".strip()
    
    # Loáº¡i bá» cÃ¡c pattern trong ngoáº·c Ä‘Æ¡n á»Ÿ cuá»‘i (nhÆ° "(ca sÄ©)", "(nhÃ³m nháº¡c)")
    # NHÆ¯NG giá»¯ láº¡i náº¿u lÃ  (album), (bÃ i hÃ¡t), (EP) - vÃ¬ Ä‘Ã³ lÃ  thÃ´ng tin quan trá»ng
    text = re.sub(r'\s*\([^)]*(?:ca sÄ©|nhÃ³m nháº¡c|ban nháº¡c|nghá»‡ sÄ©|singer|group|band)[^)]*\)\s*$', '', text, flags=re.IGNORECASE)
    
    # Chuáº©n hÃ³a khoáº£ng tráº¯ng
    text = re.sub(r'\s+', ' ', text)
    # Chuáº©n hÃ³a dáº¥u gáº¡ch ná»‘i giá»¯a chá»¯ cÃ¡i thÃ nh khoáº£ng tráº¯ng (Ahn Ji-young -> Ahn Ji young)
    text = re.sub(r'(?<=\w)-(?!\s)(?=\w)', ' ', text)
    # Loáº¡i bá» kÃ½ tá»± thá»«a á»Ÿ Ä‘áº§u/cuá»‘i
    text = text.strip('.,;:!?"\'-()[]{}')
    
    # Loáº¡i bá» tá»« thá»«a á»Ÿ cuá»‘i tÃªn (nhÆ° "rapping", "singing", "dancing")
    words = text.split()
    if len(words) > 1:
        last_word = words[-1].lower()
        if last_word in SUFFIX_WORDS_TO_REMOVE:
            text = ' '.join(words[:-1])
    
    return text

# =====================================================
# LOAD Dá»® LIá»†U
# =====================================================
print("\nğŸ“‚ Äang load dá»¯ liá»‡u...")
with open('data/enrichment_text_data.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

records = data.get('data', [])
print(f"âœ“ ÄÃ£ load {len(records)} records")

# Táº¡o mapping node_id -> text (lowercase) Ä‘á»ƒ kiá»ƒm tra context
node_texts = {}
# QUAN TRá»ŒNG: LÆ°u cáº£ type Ä‘á»ƒ check trÃ¹ng theo cáº£ tÃªn VÃ€ type
# existing_lower: Dict[normalized_name] -> Set[type]
existing_lower: Dict[str, Set[str]] = defaultdict(set)
for record in records:
    node_id = record.get('node_id', '')
    node_name = record.get('node_name', '')
    node_label = record.get('node_label', 'Entity')  # Láº¥y label/type tá»« record
    text = record.get('text', '')
    node_texts[node_id] = text.lower()
    if node_name:
        # CHUáº¨N HÃ“A tÃªn node gá»‘c Ä‘á»ƒ check trÃ¹ng
        # DÃ¹ng normalize_for_comparison Ä‘á»ƒ Ä‘áº£m báº£o cÃ¹ng cÃ¡ch chuáº©n hÃ³a vá»›i merge_and_import_neo4j.py
        # Loáº¡i bá» khoáº£ng tráº¯ng, dáº¥u gáº¡ch ná»‘i, dáº¥u gáº¡ch dÆ°á»›i Ä‘á»ƒ check trÃ¹ng (Big Bang = BIGBANG = Big-Bang)
        key_normalized = normalize_for_comparison(node_name)
        existing_lower[key_normalized].add(node_label)

total_existing = sum(len(types) for types in existing_lower.values())
print(f"âœ“ CÃ³ {total_existing} entities trong Ä‘á»“ thá»‹ (theo tÃªn vÃ  type)")

# =====================================================
# LOAD THÃ”NG TIN THÃ€NH VIÃŠN Tá»ª INFOBOX (ÄÃƒ CRAWL Sáº´N)
# =====================================================
try:
    with open('data/infobox_members.json', 'r', encoding='utf-8') as f:
        INFOBOX_MEMBERS = json.load(f)
except Exception:
    INFOBOX_MEMBERS = {"groups": {}, "artists": {}}


# =====================================================
# HÃ€M KIá»‚M TRA CONTEXT K-POP
# =====================================================
def has_kpop_context(source_nodes, min_keywords=3):
    """
    Kiá»ƒm tra entity cÃ³ trong context K-pop khÃ´ng
    
    Cáº£i thiá»‡n: Sá»­ dá»¥ng trá»ng sá»‘ cho tá»« khÃ³a quan trá»ng
    
    Args:
        source_nodes: Danh sÃ¡ch node IDs nguá»“n
        min_keywords: Sá»‘ tá»« khÃ³a K-pop tá»‘i thiá»ƒu (máº·c Ä‘á»‹nh 3)
    """
    if isinstance(source_nodes, str):
        source_nodes = [source_nodes]
    
    # Tá»« khÃ³a quan trá»ng cÃ³ trá»ng sá»‘ cao hÆ¡n
    HIGH_WEIGHT_KEYWORDS = {
        'k-pop', 'kpop', 'k pop', 'idol', 'idols', 'tháº§n tÆ°á»£ng',
        'debut', 'ra máº¯t', 'comeback', 'trá»Ÿ láº¡i',
        'nhÃ³m nháº¡c', 'ca sÄ©', 'hÃ n quá»‘c', 'korea', 'korean',
        'sm entertainment', 'jyp entertainment', 'yg entertainment', 'hybe',
    }
    
    for source in source_nodes:
        text = node_texts.get(source, '')
        if text:
            text_lower = text.lower()
            # Äáº¿m vá»›i trá»ng sá»‘: tá»« khÃ³a quan trá»ng = 2 Ä‘iá»ƒm, tá»« khÃ³a thÆ°á»ng = 1 Ä‘iá»ƒm
            kpop_score = 0
            for kw in KPOP_KEYWORDS:
                if kw.lower() in text_lower:
                    if kw.lower() in HIGH_WEIGHT_KEYWORDS:
                        kpop_score += 2
                    else:
                        kpop_score += 1
            
            # NgÆ°á»¡ng: Ã­t nháº¥t 3 Ä‘iá»ƒm (tÆ°Æ¡ng Ä‘Æ°Æ¡ng 3 tá»« khÃ³a thÆ°á»ng hoáº·c 1.5 tá»« khÃ³a quan trá»ng)
            if kpop_score >= min_keywords:
                return True
    return False

def is_music_artist(entity_text, source_nodes):
    """
    Kiá»ƒm tra xem entity cÃ³ pháº£i lÃ  nghá»‡ sÄ© Ã¢m nháº¡c khÃ´ng
    - Pháº£i cÃ³ tá»« khÃ³a vai trÃ² Ã¢m nháº¡c trong context gáº§n
    - KhÃ´ng Ä‘Æ°á»£c cÃ³ tá»« khÃ³a loáº¡i trá»« (diá»…n viÃªn, MC, etc.)
    """
    if isinstance(source_nodes, str):
        source_nodes = [source_nodes]
    
    entity_lower = entity_text.lower()
    
    for source in source_nodes:
        full_text = node_texts.get(source, '')
        if not full_text:
            continue
        
        # TÃ¬m vá»‹ trÃ­ entity trong text
        idx = full_text.find(entity_lower)
        if idx == -1:
            continue
        
        # Láº¥y context gáº§n (200 kÃ½ tá»± xung quanh)
        start = max(0, idx - 100)
        end = min(len(full_text), idx + len(entity_text) + 100)
        context = full_text[start:end]
        
        # Kiá»ƒm tra cÃ³ tá»« khÃ³a loáº¡i trá»« khÃ´ng
        has_exclude = any(kw in context for kw in EXCLUDE_KEYWORDS)
        if has_exclude:
            return False
        
        # Kiá»ƒm tra cÃ³ tá»« khÃ³a vai trÃ² Ã¢m nháº¡c khÃ´ng
        has_music_role = any(kw in context for kw in MUSIC_ROLE_KEYWORDS)
        if has_music_role:
            return True
    
    # Náº¿u khÃ´ng tÃ¬m tháº¥y context rÃµ rÃ ng, kiá»ƒm tra toÃ n bá»™ text
    for source in source_nodes:
        full_text = node_texts.get(source, '')
        # Náº¿u cÃ³ tá»« khÃ³a loáº¡i trá»« trong toÃ n bá»™ text -> loáº¡i
        if any(kw in full_text for kw in EXCLUDE_KEYWORDS):
            # NhÆ°ng náº¿u cÃ³ nhiá»u tá»« khÃ³a Ã¢m nháº¡c hÆ¡n -> cÃ³ thá»ƒ lÃ  nghá»‡ sÄ© kiÃªm diá»…n viÃªn
            music_count = sum(1 for kw in MUSIC_ROLE_KEYWORDS if kw in full_text)
            exclude_count = sum(1 for kw in EXCLUDE_KEYWORDS if kw in full_text)
            if music_count > exclude_count * 2:  # Tá»« khÃ³a Ã¢m nháº¡c pháº£i gáº¥p Ä‘Ã´i
                return True
            return False
    
    return False  # Máº·c Ä‘á»‹nh khÃ´ng pháº£i nghá»‡ sÄ© náº¿u khÃ´ng cÃ³ context rÃµ rÃ ng

def is_related_to_existing_nodes(entity_text, source_nodes, existing_names, min_mentioned=2):
    """
    Kiá»ƒm tra entity cÃ³ liÃªn quan Ä‘áº¿n cÃ¡c node hiá»‡n cÃ³ trong máº¡ng khÃ´ng
    - Xuáº¥t hiá»‡n cÃ¹ng vá»›i cÃ¡c nghá»‡ sÄ©/nhÃ³m nháº¡c Ä‘Ã£ cÃ³
    
    Cáº£i thiá»‡n: Kiá»ƒm tra tá»‘t hÆ¡n vá»›i normalize vÃ  partial matching
    """
    if isinstance(source_nodes, str):
        source_nodes = [source_nodes]
    
    # Normalize entity text Ä‘á»ƒ so sÃ¡nh
    entity_normalized = normalize_for_comparison(entity_text) if 'normalize_for_comparison' in globals() else entity_text.lower()
    
    for source in source_nodes:
        # source_node chÃ­nh lÃ  má»™t node trong máº¡ng
        source_normalized = normalize_for_comparison(source) if 'normalize_for_comparison' in globals() else source.lower()
        if source_normalized in existing_names:
            return True
        
        full_text = node_texts.get(source, '')
        if not full_text:
            continue
        
        full_text_lower = full_text.lower()
        
        # Kiá»ƒm tra cÃ³ nháº¯c Ä‘áº¿n cÃ¡c node hiá»‡n cÃ³ khÃ´ng
        # Cáº£i thiá»‡n: Kiá»ƒm tra cáº£ exact match vÃ  partial match (tÃªn dÃ i)
        mentioned_count = 0
        for name in existing_names:
            name_lower = name.lower()
            # Exact match
            if name_lower in full_text_lower:
                mentioned_count += 1
            # Partial match cho tÃªn dÃ i (Ã­t nháº¥t 4 kÃ½ tá»±)
            elif len(name_lower) >= 4 and name_lower in full_text_lower:
                mentioned_count += 0.5  # Partial match cÃ³ trá»ng sá»‘ tháº¥p hÆ¡n
        
        if mentioned_count >= min_mentioned:  # Pháº£i nháº¯c Ä‘áº¿n Ã­t nháº¥t min_mentioned node hiá»‡n cÃ³
            return True
    
    return False

def is_valid_entity(text, entity_type):
    """Kiá»ƒm tra entity cÃ³ há»£p lá»‡ khÃ´ng"""
    # Äá»™ dÃ i cÆ¡ báº£n
    if not text or len(text) > 50:
        return False
    
    # Loáº¡i bá» entities quÃ¡ ngáº¯n (trá»« má»™t sá»‘ tÃªn nghá»‡ sÄ© há»£p lá»‡ nhÆ° RM, IU, CL)
    # Bá»• sung thÃªm cÃ¡c tÃªn ngáº¯n há»£p lá»‡ tá»« infobox: DK, ZN, P.O, The8
    valid_short_names = {'rm', 'iu', 'cl', 'bm', 'jb', 'jj', 'jo', 'im', 'do', 'dk', 'zn', 'p.o', 'the8'}
    if len(text) < 3 and text.lower() not in valid_short_names:
        return False
    # KhÃ´ng cháº¥p nháº­n nghá»‡ sÄ© chá»‰ 1 kÃ½ tá»± (trÃ¡nh cÃ¡c tÃªn bá»‹ cáº¯t cá»¥t nhÆ° "B", "K")
    if entity_type == 'Artist' and len(text) == 1:
        return False
    
    # Kiá»ƒm tra tá»« khÃ´ng há»£p lá»‡
    if text.lower() in INVALID_WORDS:
        return False
    
    text_lower = text.lower()
    words = text_lower.split()
    
    # ============================================
    # LOáº I Bá» CA SÄ¨ NÆ¯á»šC NGOÃ€I (BLACKLIST)
    # ============================================
    if text_lower in FOREIGN_ARTIST_BLACKLIST:
        return False
    # Kiá»ƒm tra tÃªn cÃ³ chá»©a tÃªn trong blacklist khÃ´ng
    for blacklisted in FOREIGN_ARTIST_BLACKLIST:
        if blacklisted in text_lower or text_lower in blacklisted:
            return False
    
    # ============================================
    # LOáº I Bá» NGHá»† SÄ¨ Tá»ª QUá»C GIA KHÃC (khÃ´ng pháº£i HÃ n Quá»‘c)
    # ============================================
    for country in NON_KOREAN_COUNTRIES:
        if country in text_lower:
            return False
    # Kiá»ƒm tra tá»«ng tá»« cÃ³ pháº£i tÃªn quá»‘c gia khÃ´ng
    if any(w in NON_KOREAN_COUNTRIES for w in words):
        return False
    
    # ============================================
    # LOáº I Bá» CHÆ¯Æ NG TRÃŒNH/SHOW (khÃ´ng pháº£i nghá»‡ sÄ©/nhÃ³m)
    # ============================================
    # Náº¿u entity chá»©a tá»« khÃ³a show/contest vÃ  entity_type lÃ  Artist/Group -> loáº¡i
    if entity_type in ['Artist', 'Group']:
        for show_kw in SHOW_KEYWORDS:
            if show_kw in text_lower:
                return False
    
    # Loáº¡i bá» cÃ¡c pattern nhÆ° "... Season X", "... Contest", "... Show"
    show_patterns = [
        r'season\s*\d+', r'episode\s*\d+', r'part\s*\d+',
        r'contest$', r'show$', r'program$', r'competition$',
        r'audition', r'survival', r'challenge$', r'festival$',
        r'awards?$', r'ceremony$', r'gala$',
        r'talk\s*tv', r'idol\s*room', r'idol\s*world',  # ChÆ°Æ¡ng trÃ¬nh thá»±c táº¿
        r'^team\s+[a-z]$', r'^team\s+[a-z]\s*$',  # Team A, Team B, Team C...
        r'countdown$', r'debut\s+countdown',  # ChÆ°Æ¡ng trÃ¬nh Ä‘áº¿m ngÆ°á»£c
    ]
    for pattern in show_patterns:
        if re.search(pattern, text_lower):
            return False
    
    # Loáº¡i bá» cÃ¡c node chung chung nhÆ° "Team B", "Team A", "Team 8"
    if re.match(r'^team\s+[a-z]$', text_lower) or re.match(r'^team\s+\d+$', text_lower):
        return False
    if text_lower in ['team a', 'team b', 'team c', 'team d', 'team 8']:
        return False
    
    # Pháº£i báº¯t Ä‘áº§u báº±ng chá»¯ in hoa, sá»‘, hoáº·c kÃ½ tá»± Ä‘áº·c biá»‡t
    if not re.match(r'^[A-Z0-9ê°€-í£("\']', text):
        return False
    
    # KhÃ´ng chá»©a chá»‰ sá»‘ hoáº·c kÃ½ tá»± Ä‘áº·c biá»‡t
    if re.match(r'^[\d\.\-\s]+$', text):
        return False
    
    # ============================================
    # LOáº I Bá» THá»‚ LOáº I NHáº C (KHÃ”NG PHáº¢I NGHá»† SÄ¨)
    # ============================================
    if entity_type == 'Artist':
        if text_lower in MUSIC_GENRES:
            return False
        # Kiá»ƒm tra tá»«ng tá»« cÃ³ pháº£i thá»ƒ loáº¡i nháº¡c khÃ´ng
        if any(w in MUSIC_GENRES for w in words):
            return False
    
    # ============================================
    # LOáº I Bá» Tá»ª Tá»”NG QUÃT Vá»€ MEDIA/TECHNOLOGY (KHÃ”NG PHáº¢I NGHá»† SÄ¨)
    # ============================================
    if entity_type == 'Artist':
        generic_media_words = {
            'video', 'audio', 'music', 'clip', 'film', 'movie', 'photo', 'picture',
            'image', 'graphic', 'media', 'content', 'file', 'download', 'stream',
            'playback', 'recording', 'broadcast', 'television', 'tv', 'radio',
            'track', 'album', 'single', 'ep', 'mv', 'teaser', 'trailer',
        }
        if text_lower in generic_media_words:
            return False
    
    # ============================================
    # LOáº I Bá» CÃC NHÃ“M NHáº C ÄÃƒ BIáº¾T (KHÃ”NG PHáº¢I ARTIST)
    # ============================================
    if entity_type == 'Artist':
        if text_lower in KNOWN_KPOP_GROUPS:
            return False
    
    # ============================================
    # LOáº I Bá» PATTERN "SOLO + TÃŠN NGHá»† SÄ¨"
    # ============================================
    if entity_type == 'Artist':
        # Loáº¡i bá» pattern "Solo Somi Zion" (nÃªn tÃ¡ch thÃ nh 2 nghá»‡ sÄ© riÃªng)
        if text_lower.startswith('solo '):
            return False
    
    # ============================================
    # LOáº I Bá» PATTERN "EP" HOáº¶C "EPISODE" TRONG TÃŠN
    # ============================================
    if entity_type == 'Artist':
        # Loáº¡i bá» pattern nhÆ° "MBC Ep 347", "UP10TION Ep"
        if re.search(r'\bep\s*\d+', text_lower) or re.search(r'\bepisode\s*\d+', text_lower):
            return False
        # Loáº¡i bá» náº¿u káº¿t thÃºc báº±ng " Ep" hoáº·c " Episode"
        if text_lower.endswith(' ep') or text_lower.endswith(' episode'):
            return False
    
    # ============================================
    # LOáº I Bá» PHIM
    # ============================================
    if entity_type == 'Artist':
        # Loáº¡i bá» phim nhÆ° "To The Beautiful You"
        if 'phim' in text_lower or 'film' in text_lower or 'movie' in text_lower:
            return False
        # Loáº¡i bá» cÃ¡c phim Ä‘Ã£ biáº¿t
        if text_lower in ['to the beautiful you']:
            return False
    
    # ============================================
    # LOáº I Bá» CHÆ¯Æ NG TRÃŒNH RADIO
    # ============================================
    if entity_type == 'Artist':
        # Loáº¡i bá» pattern nhÆ° "Radio' The Boyz Younghoon"
        if text_lower.startswith("radio'") or text_lower.startswith("radio "):
            return False
        # Loáº¡i bá» náº¿u chá»©a "radio" vÃ  tÃªn nhÃ³m
        for group in KNOWN_KPOP_GROUPS:
            if f"radio" in text_lower and group in text_lower:
                return False
    
    # ============================================
    # LOáº I Bá» PATTERN "ALBUM + NÄ‚M + Sá»" HOáº¶C "ALBUM + Sá»"
    # ============================================
    if entity_type in ['Artist', 'Album', 'Song']:
        # Loáº¡i bá» pattern nhÆ° "Album 2011 05"
        if re.match(r'^album\s+\d{4}\s+\d+', text_lower):
            return False
        if re.match(r'^album\s+\d+', text_lower):
            return False
    
    # ============================================
    # LOáº I Bá» PATTERN "IDOL + TÃŠN CHÆ¯Æ NG TRÃŒNH" HOáº¶C CHá»ˆ TÃŠN CHÆ¯Æ NG TRÃŒNH
    # ============================================
    if entity_type == 'Artist':
        # Loáº¡i bá» pattern nhÆ° "Idol Intern King", "Idol Maknae Rebellion"
        if text_lower.startswith('idol '):
            # Kiá»ƒm tra xem cÃ³ pháº£i chÆ°Æ¡ng trÃ¬nh khÃ´ng
            remaining = text_lower[5:].strip()  # Bá» "idol "
            # Náº¿u pháº§n cÃ²n láº¡i cÃ³ tá»« khÃ³a chÆ°Æ¡ng trÃ¬nh -> loáº¡i bá»
            show_keywords = ['intern', 'maknae', 'rebellion', 'king', 'show', 'program']
            if any(kw in remaining for kw in show_keywords):
                return False
        
        # Loáº¡i bá» cÃ¡c tÃªn chÆ°Æ¡ng trÃ¬nh ngay cáº£ khi khÃ´ng cÃ³ chá»¯ "idol" á»Ÿ Ä‘áº§u
        show_names = ['intern king', 'maknae rebellion']
        if text_lower in show_names:
            return False
        # Kiá»ƒm tra xem cÃ³ chá»©a tÃªn chÆ°Æ¡ng trÃ¬nh khÃ´ng
        for show_name in show_names:
            if show_name in text_lower:
                return False
    
    # ============================================
    # LOáº I Bá» Äá»ŠA DANH CHUNG CHUNG
    # ============================================
    if entity_type in ['Artist', 'Group']:
        # Loáº¡i bá» Ä‘á»‹a danh nhÆ° "Seoul", "San Francisco"
        if text_lower in LOCATION_NAMES:
            return False
        # Kiá»ƒm tra tá»«ng tá»« cÃ³ pháº£i Ä‘á»‹a danh khÃ´ng
        if any(w in LOCATION_NAMES for w in words):
            return False
        # Loáº¡i bá» pattern Ä‘á»‹a danh HÃ n Quá»‘c dáº¡ng "X-gu", "X si", "X-do"
        if re.search(r'\b(?:gu|si|do)\b$', text_lower.replace('-', ' ')):
            return False
    
    # ============================================
    # LOáº I Bá» PATTERN "HITS MR" HOáº¶C TÆ¯Æ NG Tá»°
    # ============================================
    if entity_type == 'Artist':
        # Loáº¡i bá» pattern nhÆ° "Hits Mr"
        if text_lower.startswith('hits ') or text_lower == 'hits mr':
            return False
    
    # ============================================
    # LOáº I Bá» TÃŠN Bá»Š Cáº®T Cá»¤T TRÃ™NG Vá»šI NODE Gá»C
    # ============================================
    if entity_type == 'Artist':
        # Kiá»ƒm tra xem cÃ³ pháº£i tÃªn bá»‹ cáº¯t cá»¥t khÃ´ng (vÃ­ dá»¥: "Shin Hye" vs "Park Shin-hye")
        # CHUáº¨N HÃ“A entity text trÆ°á»›c khi check
        normalized_entity = clean_text(text)
        normalized_entity_lower = normalized_entity.lower()
        # Náº¿u entity lÃ  pháº§n cuá»‘i cá»§a má»™t node hiá»‡n cÃ³ -> loáº¡i bá»
        for existing_name in existing_lower:
            # Náº¿u entity lÃ  pháº§n cuá»‘i cá»§a tÃªn hiá»‡n cÃ³ (Ã­t nháº¥t 3 kÃ½ tá»±)
            if len(normalized_entity_lower) >= 3 and existing_name.endswith(normalized_entity_lower):
                # Kiá»ƒm tra xem cÃ³ pháº£i tÃªn bá»‹ cáº¯t cá»¥t khÃ´ng (khÃ´ng pháº£i trÃ¹ng hoÃ n toÃ n)
                if existing_name != normalized_entity_lower and len(existing_name) > len(normalized_entity_lower):
                    # CÃ³ thá»ƒ lÃ  tÃªn bá»‹ cáº¯t cá»¥t -> loáº¡i bá»
                    return False
    
    # ============================================
    # LOáº I Bá» PATTERN "TÃŠN NHÃ“M + TÃŠN THÃ€NH VIÃŠN"
    # ============================================
    if entity_type == 'Artist':
        # Kiá»ƒm tra xem cÃ³ pháº£i pattern "Group Name + Member Name" khÃ´ng
        # VÃ­ dá»¥: "EXO Xiumin", "Girls' Generation Tiffany"
        for group_name in KNOWN_KPOP_GROUPS:
            if text_lower.startswith(group_name + ' '):
                # CÃ³ thá»ƒ lÃ  "Group Name + Member Name"
                remaining = text_lower[len(group_name):].strip()
                if remaining and len(remaining) > 1:
                    # Náº¿u pháº§n cÃ²n láº¡i lÃ  tÃªn thÃ nh viÃªn -> loáº¡i bá»
                    return False
    
    # ============================================
    # LOáº I Bá» TÃŠN Bá»Š Cáº®T Cá»¤T (CHá»ˆ CÃ“ 1 CHá»® CÃI CUá»I)
    # ============================================
    if entity_type == 'Artist':
        # Kiá»ƒm tra pattern nhÆ° "Block B P" (chá»‰ cÃ³ 1 chá»¯ cÃ¡i cuá»‘i)
        # Hoáº·c "Dani T-ara N4" (cÃ³ thá»ƒ lÃ  tÃªn bá»‹ nháº§m)
        words = text.split()
        if len(words) >= 2:
            last_word = words[-1]
            # Náº¿u tá»« cuá»‘i chá»‰ cÃ³ 1 chá»¯ cÃ¡i hoáº·c 1 chá»¯ cÃ¡i + sá»‘ -> cÃ³ thá»ƒ bá»‹ cáº¯t cá»¥t
            if len(last_word) == 1 or (len(last_word) == 2 and last_word[1].isdigit()):
                # Kiá»ƒm tra xem cÃ³ pháº£i tÃªn nhÃ³m khÃ´ng
                prefix = ' '.join(words[:-1]).lower()
                if prefix in KNOWN_KPOP_GROUPS:
                    return False
            # Kiá»ƒm tra pattern "Name Group N4" hoáº·c tÆ°Æ¡ng tá»±
            if len(words) >= 3:
                # VÃ­ dá»¥: "Dani T-ara N4"
                if any(w.lower() in KNOWN_KPOP_GROUPS for w in words):
                    return False
    
    # Kiá»ƒm tra theo loáº¡i
    if entity_type == 'Artist':
        if len(words) > 4:
            return False
        if any(w in INVALID_WORDS for w in words):
            return False
        # Loáº¡i bá» pattern X.Y (2 chá»¯ cÃ¡i + dáº¥u cháº¥m) nhÆ° "T.O"
        if re.match(r'^[A-Z]\.[A-Z]\.?$', text):
            return False
        # Loáº¡i bá» tÃªn bá»‹ cáº¯t tá»« tÃªn nhÃ³m, vÃ­ dá»¥ "T ara" tá»« "T-ara"
        normalized = re.sub(r'[^a-z0-9]', '', text_lower)
        for group_name in KNOWN_KPOP_GROUPS:
            g_norm = re.sub(r'[^a-z0-9]', '', group_name)
            if normalized == g_norm and normalized != group_name:
                return False
        # TÃªn nghá»‡ sÄ© thÆ°á»ng cÃ³ Ã­t nháº¥t 3 kÃ½ tá»± (trá»« ngoáº¡i lá»‡)
        if len(text) < 3 and text.lower() not in valid_short_names:
            return False
            
    elif entity_type == 'Group':
        # Loáº¡i bá» prefix lÃ  thá»ƒ loáº¡i nháº¡c Ä‘á»©ng trÆ°á»›c tÃªn nhÃ³m (vÃ­ dá»¥: "Indie OKDAL", "K-pop Big Bang")
        # DÃ¹ng MUSIC_GENRES Ä‘á»ƒ cáº¯t bá» 1 hoáº·c nhiá»u thá»ƒ loáº¡i á»Ÿ Ä‘áº§u, miá»…n lÃ  cÃ²n láº¡i >= 1 tá»«
        original_text = text
        while True:
            lowered = text.lower()
            stripped = lowered.lstrip()
            if stripped != lowered:
                # Äá»“ng bá»™ láº¡i text náº¿u cÃ³ khoáº£ng tráº¯ng Ä‘áº§u
                text = text[len(text) - len(stripped):]
                lowered = stripped
            # TÃ¬m genre prefix dÃ i nháº¥t khá»›p á»Ÿ Ä‘áº§u
            genre_prefix = None
            for genre in sorted(MUSIC_GENRES, key=lambda g: -len(g)):
                if lowered.startswith(genre + ' ') and len(text.split()) > len(genre.split()):
                    genre_prefix = genre
                    break
            if not genre_prefix:
                break
            # Cáº¯t bá» genre prefix + khoáº£ng tráº¯ng
            cut_len = len(genre_prefix)
            text = text[cut_len:].lstrip()
        text_lower = text.lower()
        words = text_lower.split()

        if len(text) > 30 or text.count(' ') > 5:
            return False
        # TÃªn nhÃ³m thÆ°á»ng cÃ³ Ã­t nháº¥t 3 kÃ½ tá»±
        if len(text) < 3:
            return False
        # KhÃ´ng pháº£i thuáº­t ngá»¯ K-pop
        kpop_terms = {'k-pop', 'kpop', 'idol', 'chart', 'gaon', 'billboard'}
        if text_lower in kpop_terms:
            return False
        
        # ============================================
        # LOáº I Bá» TÃŠN CÃ”NG TY (KHÃ”NG PHáº¢I NHÃ“M NHáº C)
        # ============================================
        company_names = {
            'warner bros', 'warner music', 'warner bros.', 'warner brothers',
            'sony music', 'sony entertainment', 'sony bmg',
            'universal music', 'universal music group', 'umg',
            'emi', 'emi music', 'capitol records',
            'atlantic records', 'columbia records', 'rca records',
            'interscope', 'def jam', 'republic records',
            'geffen records', 'virgin records', 'island records',
        }
        if text_lower in company_names:
            return False
        # Kiá»ƒm tra tá»«ng pháº§n cá»§a tÃªn cÃ³ pháº£i cÃ´ng ty khÃ´ng
        for company in company_names:
            if company in text_lower:
                return False
        
        # ============================================
        # LOáº I Bá» CÃ‚U MÃ” Táº¢ (KHÃ”NG PHáº¢I TÃŠN NHÃ“M)
        # ============================================
        # CÃ¡c Ä‘á»™ng tá»« thÆ°á»ng cÃ³ trong cÃ¢u mÃ´ táº£
        sentence_verbs = [
            'drops', 'releases', 'announces', 'reveals', 'launches',
            'taps', 'hires', 'appoints', 'names', 'promotes',
            'signs', 'debuts', 'debut', 'debuting',
            'performs', 'sings', 'dances',
            'returns', 'confirms', 'denies', 'shares', 'posts',
            'being', 'breezes', 'bringing', 'hits',
        ]
        for verb in sentence_verbs:
            if f' {verb} ' in text_lower or text_lower.startswith(f'{verb} '):
                return False
        
        # Loáº¡i bá» cÃ¢u báº¯t Ä‘áº§u báº±ng Ä‘á»™ng tá»« (khÃ´ng pháº£i tÃªn nhÃ³m)
        first_word = words[0] if words else ''
        if first_word in sentence_verbs:
            return False

        # Loáº¡i bá» cá»¥m tá»« tiáº¿ng Viá»‡t thÃ´ng dá»¥ng (khÃ´ng pháº£i tÃªn riÃªng), vÃ­ dá»¥: "Sau khi", "TrÆ°á»›c khi"
        # Náº¿u táº¥t cáº£ cÃ¡c tá»« Ä‘á»u náº±m trong INVALID_WORDS (tá»« chá»©c nÄƒng) thÃ¬ khÃ´ng pháº£i tÃªn nhÃ³m
        if len(words) >= 2 and all(w in INVALID_WORDS for w in words):
            return False
        
        # ============================================
        # LOáº I Bá» CÃ‚U CÃ“ Dáº¤U NHÃY Má» KHÃ”NG ÄÃ“NG
        # ============================================
        # VÃ­ dá»¥: "NewJeans drops 'Hype Boy" - cÃ³ dáº¥u ' má»Ÿ nhÆ°ng khÃ´ng Ä‘Ã³ng
        if "'" in text and text.count("'") == 1:
            # CÃ³ 1 dáº¥u nhÃ¡y Ä‘Æ¡n - cÃ³ thá»ƒ lÃ  cÃ¢u bá»‹ cáº¯t cá»¥t
            return False
        if '"' in text and text.count('"') == 1:
            # CÃ³ 1 dáº¥u nhÃ¡y kÃ©p - cÃ³ thá»ƒ lÃ  cÃ¢u bá»‹ cáº¯t cá»¥t
            return False
        
        # ============================================
        # LOáº I Bá» SUFFIX CÃ”NG TY
        # ============================================
        company_suffixes = ['n.v', 'n.v.', 'inc', 'inc.', 'ltd', 'ltd.', 
                           'corp', 'corp.', 'llc', 'llc.', 'co.', 'plc']
        if text_lower in company_suffixes:
            return False
        # Loáº¡i bá» náº¿u káº¿t thÃºc báº±ng suffix cÃ´ng ty
        for suffix in company_suffixes:
            if text_lower.endswith(f' {suffix}'):
                return False
        
        # ============================================
        # LOáº I Bá» TÃŠN NGÆ¯á»œI (KHÃ”NG PHáº¢I NHÃ“M)
        # ============================================
        # Pattern "Taps David Blackman" hoáº·c "Firstname Lastname"
        # Náº¿u cÃ³ tá»« "David", "Scott", "Michael"... cÃ³ thá»ƒ lÃ  tÃªn ngÆ°á»i
        common_western_names = {
            'david', 'scott', 'michael', 'john', 'james', 'robert', 'william',
            'richard', 'joseph', 'thomas', 'chris', 'daniel', 'mark', 'paul',
            'steven', 'kevin', 'brian', 'george', 'edward', 'ronald', 'anthony',
        }
        if any(name in text_lower for name in common_western_names):
            # CÃ³ thá»ƒ lÃ  tÃªn ngÆ°á»i phÆ°Æ¡ng TÃ¢y, khÃ´ng pháº£i nhÃ³m K-pop
            return False
        
        # ============================================
        # LOáº I Bá» CÃC TÃŠN GROUP SAI / ROMANIZATION Ká»² Láº  / CÃ‚U VÄ‚N
        # (Tá»I Æ¯U CHO Bá»˜ Dá»® LIá»†U HIá»†N Táº I)
        # ============================================
        bad_group_texts = {
            # NhÃ³m nÆ°á»›c ngoÃ i / J-pop / non K-pop hoáº·c cÃ¢u vÄƒn
            'a.k.b. forty-eight', 'akb48 breezes through d',
            'beatles', 'being in hiatus right now',
            'girl next door', 'girl next',
            'daisokaku matsuri', 'declares debut in 2025',
            'doping panda', 'drippin on first full album',
            'exo-cbx hits no', 'garfunkel. sg wannabe',
            'kard talk tour', 'kep1er to debut on january 3rd',
            'k-pop blackpink', 'k-pop m3', 'kpop bts',
            'los angeles. txt', 'mbc chorus',
            'mum48',
            
            # Romanization/phiÃªn Ã¢m tiáº¿ng HÃ n cá»§a nhÃ³m Ä‘Ã£ cÃ³ node chuáº©n
            'aideul', 'akdong myujisyeon', 'aseuteuro',
            'beu-ah-geol', 'beureibeu geolseu',
            'bolbbalgan sachungi', 'bolbbalgan sachungi ',
            'hacheutuhacheu', 'hacheutuhacheu ',
            'pipeuti pipeuti', 'pipeuti pipeuti ',
            'geullaem ', 'reddo berubetto ',
            'aseuteuro ', 'aideul ',
            'tee -eks-tee',
            
            # Máº£nh tÃªn / tá»« chung chung / bá»‹ cáº¯t cá»¥t
            'btob (2012', 'berhad', 'bernad',
            'boram . t-ara', 'gen4', 'gb9 b',
            'honeydew', 'jebewon ', 'junsu',
            'labelle', 'lesserafim', 'mio', 'muses ',
            'ne1', 'next year', 'note', 'one ',
            'oh won bin', 'rd ', 'rglow ', 'record',
            'seung-hyun', 'shabet hay dalshabet',
            'take over the u', 'syupeo junieo', 'teurejeo', 'yeoja chingu',
            'ensiti', 'jebewon', 'reddo berubetto', 'shoo',
            # Viáº¿t táº¯t khÃ´ng Ä‘áº§y Ä‘á»§ / tá»« bá»‹ cáº¯t
            'one', 'rd', 'rglow', 'muses', 'tpst',
            # Tá»« chung chung
            # NhÃ³m nháº¡c nÆ°á»›c ngoÃ i
            'the beatles', 'beatles',
            # Bá»• sung cÃ¡c phiÃªn Ã¢m / máº£ng tÃªn sai má»›i phÃ¡t hiá»‡n
            'k pop big bang',
            'a.k.b. forty eight', 'a.k.b. forty eight ',  # biáº¿n thá»ƒ spacing
            'beu ah geol', 'beu ah geol ',
            'boram . t ara', 'boram . t-ara',
            # Soloist / nghá»‡ sÄ© khÃ´ng pháº£i nhÃ³m
            'g-dragon', 'g dragon',
            # Máº£nh tÃªn nhÃ³m bá»‹ cáº¯t cá»¥t
            'f ve',  # tá»« "F-ve Dolls" nhÆ°ng chá»‰ cÃ²n "F ve"
            # CÃ¡c thá»±c thá»ƒ khÃ´ng pháº£i group trong Ä‘á»“ thá»‹ cá»§a báº¡n
            'indie okdal y', 'indie okdal',  # cá»¥m "Indie OKDAL (Y.BIRD from Jellyfish...)"
            'jewelry 2001',                  # tÃªn nhÃ³m kÃ¨m nÄƒm debut -> khÃ´ng pháº£i tÃªn group riÃªng
            'produce 101', 'produce 48',     # show tuyá»ƒn chá»n, khÃ´ng pháº£i nhÃ³m nháº¡c
            'unchanging',                    # album "Unchanging", khÃ´ng pháº£i nhÃ³m
        }
        if text_lower.strip() in bad_group_texts:
            return False
        
        # Loáº¡i bá» tÃªn group cÃ³ Ä‘Ã­nh kÃ¨m nÄƒm 19xx/20xx (Jewelry 2001, Fin.K.L 1998, ...)
        # Trong máº¡ng lÆ°á»›i cá»§a báº¡n, nÄƒm debut khÃ´ng pháº£i má»™t pháº§n cá»§a tÃªn node group
        if re.search(r'\b(19|20)\d{2}\b', text_lower):
            return False
        
        # Loáº¡i bá» cá»¥m cÃ³ tá»« khÃ³a mang tÃ­nh mÃ´ táº£, khÃ´ng pháº£i tÃªn riÃªng group
        if any(kw in text_lower for kw in ['indie okdal', ' y.bird', ' y bird ']):
            return False
        
        # ============================================
        # LOáº I Bá» GROUP Báº®T Äáº¦U Báº°NG "K POP" / "K-POP" / "KPOP"
        # ============================================
        # VÃ­ dá»¥: "K pop Big Bang", "K-pop BTS", "Kpop Blackpink"
        if re.match(r'^k[\s\-]?pop\s+', text_lower):
            return False
        
        # ============================================
        # LOáº I Bá» PHIÃŠN Ã‚M TIáº¾NG ANH Cá»¦A TÃŠN NHÃ“M (A.K.B. Forty Eight, etc.)
        # ============================================
        # Pattern: TÃªn viáº¿t táº¯t cÃ³ dáº¥u cháº¥m + tá»« tiáº¿ng Anh (Forty, Eight, etc.)
        english_number_words = {'one', 'two', 'three', 'four', 'five', 'six', 'seven', 
                                'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen',
                                'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen',
                                'nineteen', 'twenty', 'thirty', 'forty', 'fifty', 'sixty',
                                'seventy', 'eighty', 'ninety', 'hundred', 'thousand'}
        words_list = text_lower.split()
        if any(w in english_number_words for w in words_list):
            # CÃ³ tá»« sá»‘ tiáº¿ng Anh -> cÃ³ thá»ƒ lÃ  phiÃªn Ã¢m nhÆ° "A.K.B. Forty Eight"
            if '.' in text or len(words_list) >= 2:
                return False
        
        # ============================================
        # LOáº I Bá» PATTERN "TÃŠN . TÃŠN NHÃ“M" (Boram . T ara)
        # ============================================
        # Pattern: "TÃªn ngÆ°á»i . TÃªn nhÃ³m" hoáº·c cÃ³ dáº¥u cháº¥m láº» giá»¯a cÃ¡c tá»«
        if re.search(r'\s+\.\s+', text):
            # CÃ³ dáº¥u cháº¥m Ä‘Æ°á»£c bao quanh bá»Ÿi khoáº£ng tráº¯ng -> khÃ´ng pháº£i tÃªn nhÃ³m há»£p lá»‡
            return False
        
        # ============================================
        # LOáº I Bá» PHIÃŠN Ã‚M TIáº¾NG HÃ€N Dáº NG "BEU AH GEOL" (viáº¿t hoa tá»«ng Ã¢m tiáº¿t)
        # ============================================
        # Pattern: Nhiá»u tá»« ngáº¯n (2-4 kÃ½ tá»±), viáº¿t hoa Ä‘áº§u, cÃ³ nguyÃªn Ã¢m HÃ n
        korean_syllable_vowels = ('eu', 'eo', 'ae', 'ui', 'eui', 'yeo', 'weo', 'oe', 'wo', 'wa', 'ya', 'ye', 'yo', 'yu')
        if len(words_list) >= 2:
            short_syllable_count = 0
            korean_vowel_count = 0
            for w in words_list:
                w_lower = w.lower()
                if len(w) <= 5:  # Ã‚m tiáº¿t ngáº¯n
                    short_syllable_count += 1
                if any(v in w_lower for v in korean_syllable_vowels):
                    korean_vowel_count += 1
            # Náº¿u háº§u háº¿t cÃ¡c tá»« Ä‘á»u ngáº¯n vÃ  cÃ³ nguyÃªn Ã¢m HÃ n -> phiÃªn Ã¢m
            if short_syllable_count >= len(words_list) * 0.6 and korean_vowel_count >= 1:
                # Kiá»ƒm tra khÃ´ng pháº£i nhÃ³m K-pop tháº­t
                if text_lower not in KNOWN_KPOP_GROUPS:
                    return False
        
        # Loáº¡i thÃªm cÃ¡c phiÃªn Ã¢m dáº¡ng "tee -eks-tee", "dee -ei-en" (chá»‰ toÃ n chá»¯ thÆ°á»ng + dáº¥u gáº¡ch)
        if re.search(r'\b[a-z]+\s*-\s*[a-z]+', text_lower):
            return False
        
        # ============================================
        # LOáº I Bá» PHIÃŠN Ã‚M TIáº¾NG HÃ€N (ROMAJA/LATINH HÃ“A)
        # ============================================
        # Pattern phá»• biáº¿n cá»§a phiÃªn Ã¢m HÃ n Quá»‘c:
        # - Káº¿t thÃºc báº±ng -eo, -eu, -ae, -ui, -eun, -eon
        # - CÃ³ cÃ¡c cá»¥m nguyÃªn Ã¢m Ä‘áº·c trÆ°ng: eu, eo, ae, ui, eui
        # - ThÆ°á»ng viáº¿t liá»n hoáº·c cÃ³ khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ã¢m tiáº¿t
        korean_romanization_patterns = [
            r'^[A-Z]?[a-z]*(?:eu|eo|ae|ui|eui)[a-z]*$',  # Má»™t tá»« cÃ³ nguyÃªn Ã¢m HÃ n
            r'^[A-Z]?[a-z]+(?:eo|eu)$',  # Káº¿t thÃºc báº±ng -eo hoáº·c -eu
            r'^[A-Z]?[a-z]+(?:eun|eon|eul)$',  # Káº¿t thÃºc báº±ng -eun, -eon, -eul
        ]
        # CÃ¡c háº­u tá»‘ phiÃªn Ã¢m HÃ n phá»• biáº¿n
        korean_suffixes = ('eo', 'eu', 'eun', 'eon', 'eul', 'eung')
        # Náº¿u lÃ  má»™t tá»« Ä‘Æ¡n (khÃ´ng cÃ³ khoáº£ng tráº¯ng) vÃ  káº¿t thÃºc báº±ng suffix HÃ n
        if ' ' not in text and text_lower.endswith(korean_suffixes):
            # Loáº¡i trá»« cÃ¡c tá»« tiáº¿ng Anh há»£p lá»‡
            english_exceptions = {'neo', 'stereo', 'romeo', 'video', 'cameo'}
            if text_lower not in english_exceptions:
                return False
        
        # PhÃ¡t hiá»‡n pattern phiÃªn Ã¢m 2+ Ã¢m tiáº¿t viáº¿t hoa Ä‘áº§u (Syupeo Junieo, Teurejeo)
        # Náº¿u cÃ³ nhiá»u tá»« vÃ  má»—i tá»« Ä‘á»u cÃ³ pattern nguyÃªn Ã¢m HÃ n
        words_in_text = text.split()
        if len(words_in_text) >= 1:
            korean_vowel_combos = ('eu', 'eo', 'ae', 'ui', 'eui', 'yeo', 'weo')
            romanization_word_count = 0
            for word in words_in_text:
                word_lower = word.lower()
                if any(combo in word_lower for combo in korean_vowel_combos):
                    romanization_word_count += 1
            # Náº¿u táº¥t cáº£ cÃ¡c tá»« Ä‘á»u cÃ³ nguyÃªn Ã¢m HÃ n -> cÃ³ thá»ƒ lÃ  phiÃªn Ã¢m
            if romanization_word_count == len(words_in_text) and len(words_in_text) <= 3:
                # Kiá»ƒm tra thÃªm: khÃ´ng pháº£i cÃ¡c nhÃ³m K-pop thá»±c sá»± viáº¿t theo kiá»ƒu nÃ y
                known_valid = {'aespa', 'neo', 'exo'}  
                if text_lower not in known_valid:
                    return False
        
        # ============================================
        # LOáº I Bá» PATTERN "NHÃ“M + THÃ€NH VIÃŠN"
        # ============================================
        # VÃ­ dá»¥: "Blackpink Jennie" khÃ´ng pháº£i lÃ  tÃªn nhÃ³m
        for group_name in KNOWN_KPOP_GROUPS:
            if text_lower.startswith(group_name + ' '):
                # CÃ³ thá»ƒ lÃ  "Group Name + Member Name"
                remaining = text_lower[len(group_name):].strip()
                if remaining and len(remaining) > 1:
                    return False
        
        # ============================================
        # LOáº I Bá» NHÃ“M NHáº C NÆ¯á»šC NGOÃ€I (KHÃ”NG PHáº¢I K-POP)
        # ============================================
        non_kpop_groups = {
            'chopstick brothers',  # NhÃ³m Trung Quá»‘c
            'jonas brothers',      # NhÃ³m Má»¹
            'backstreet boys',     # NhÃ³m Má»¹
            'one direction',       # NhÃ³m Anh
            'westlife',            # NhÃ³m Ireland
            'nsync', "n'sync",     # NhÃ³m Má»¹
        }
        if text_lower in non_kpop_groups:
            return False
        
        # ============================================
        # LOáº I Bá» TÃŠN Bá»Š Cáº®T Cá»¤T (VIáº¾T Táº®T KHÃ”NG Äáº¦Y Äá»¦)
        # ============================================
        # VÃ­ dá»¥: "S.E" (tá»« S.E.S.), "T.O" (tá»« T.O.P)
        # Pattern: 1-2 chá»¯ cÃ¡i + dáº¥u cháº¥m, nhÆ°ng khÃ´ng pháº£i tÃªn Ä‘áº§y Ä‘á»§
        if re.match(r'^[A-Z]\.[A-Z]$', text) and len(text) == 3:
            # Kiá»ƒm tra xem cÃ³ pháº£i tÃªn Ä‘áº§y Ä‘á»§ khÃ´ng
            valid_short_groups = {'s.e.s', 'h.o.t', 'n.r.g'}
            if text_lower not in valid_short_groups:
                return False
        # Loáº¡i bá» pattern X.Y (2 chá»¯ cÃ¡i + 1 dáº¥u cháº¥m á»Ÿ giá»¯a)
        if re.match(r'^[A-Z]\.[A-Z]\.?$', text):
            return False
            
    elif entity_type in ['Album', 'Song']:
        if len(text) > 40:
            return False
        # Album/Song thÆ°á»ng cÃ³ Ã­t nháº¥t 4 kÃ½ tá»± (loáº¡i bá» tá»« quÃ¡ ngáº¯n nhÆ° "Act", "Again")
        if len(text) < 4:
            return False
        
        # ============================================
        # LOáº I Bá» THUáº¬T NGá»® CHUNG / Tá»ª LIÃŠN QUAN Báº¢NG Xáº¾P Háº NG / KHÃ”NG PHáº¢I ALBUM
        # ============================================
        chart_terms = {
            'chart', 'gaon', 'oricon', 'billboard', 'sales', 'vol', 'mr',
            'cover', 'remix', 'intro', 'outro', 'interlude',
            # Tá»• chá»©c/báº£ng xáº¿p háº¡ng liÃªn quan K-pop
            'miak',  # Music Industry Association of Korea
        }
        if text_lower in chart_terms:
            return False
        
        # Loáº¡i bá» pattern "Chart + nÄƒm/sá»‘" nhÆ° "Chart 2022", "Chart 20"
        if re.match(r'^chart\s*\d+', text_lower):
            return False
        
        # Loáº¡i bá» pattern báº¯t Ä‘áº§u báº±ng "Top + sá»‘" (Top 40, Top 100...)
        if re.match(r'^top\s+\d+', text_lower):
            return False
        
        # Loáº¡i bá» tÃªn cÃ³ cáº£ "miak" vÃ  "kpop/k-pop/k pop" (MIAK K-pop chart)
        if 'miak' in text_lower and ('k pop' in text_lower or 'k-pop' in text_lower or 'kpop' in text_lower):
            return False

        # Loáº¡i bá» cÃ¡c album tá»•ng há»£p/best-of chung chung (Best of, Best Selection, Best Album, Compilation)
        # vÃ­ dá»¥: "BEST OF CNBLUE", "Best Selection 2010", "Best of Album"
        compilation_phrases = [
            'best of ', ' best of', 'best selection', 'greatest hits',
            'best album', 'best single', 'best collection',
        ]
        if any(phrase in text_lower for phrase in compilation_phrases):
            # Tuy nhiÃªn váº«n cho qua náº¿u tÃªn quÃ¡ cá»¥ thá»ƒ (cÃ³ tÃªn nhÃ³m rÃµ rÃ ng vÃ  báº¡n muá»‘n giá»¯)
            # á» Ä‘Ã¢y Æ°u tiÃªn an toÃ n: loáº¡i bá» Ä‘á»ƒ trÃ¡nh nháº§m vá»›i danh má»¥c/playlist/giáº£i thÆ°á»Ÿng
            return False
        
        # Loáº¡i bá» tÃªn bá»‹ cáº¯t cá»¥t kiá»ƒu "U KISS cho" (cá»¥m tiáº¿ng Viá»‡t "cho" á»Ÿ cuá»‘i)
        if text_lower.endswith(' cho'):
            return False
        
        # Loáº¡i bá» cÃ¡c cá»¥m rÃµ rÃ ng lÃ  mÃ´ táº£ J-pop / nhÃ³m Nháº­t, khÃ´ng pháº£i album K-pop
        jpop_keywords_in_album = ['akb48', 'morning musume', 'musume']
        if any(kw in text_lower for kw in jpop_keywords_in_album):
            return False
        
        # ============================================
        # LOáº I Bá» Tá»ª ÄÆ N CHUNG CHUNG (KHÃ”NG Äá»¦ Äáº¶C TRÆ¯NG Äá»‚ LÃ€ TÃŠN ALBUM)
        # ============================================
        # CHÃš Ã: Má»™t sá»‘ tá»« nhÆ° "Tonight", "Always", "Alive", "Blue" lÃ  tÃªn album K-pop tháº­t
        # ChÃºng Ä‘Ã£ Ä‘Æ°á»£c lá»c bá»Ÿi pattern matching context-aware, nÃªn bá» khá»i blacklist
        generic_single_words = {
            'act', 'again', 'chain', 'cover', 'dreaming', 'sorry', 'love', 'heart',
            'step', 'dance', 'night', 'day', 'fire', 'water', 'star', 'moon', 'sun',
            'world', 'life', 'time', 'dream', 'hope', 'light', 'dark',  # Bá»: blue, red, black, white, pink
            'gold', 'silver', 'sweet', 'crazy', 'happy',
            'sad', 'bad', 'good', 'new', 'old', 'young', 'wild', 'free',  # Bá»: alive
            'forever', 'never', 'maybe', 'baby', 'honey', 'angel', 'devil',  # Bá»: always
            'hero', 'power', 'magic', 'fantasy', 'miracle', 'secret', 'mystery',
            'story', 'memory', 'moment', 'feeling', 'emotion', 'passion', 'desire',
            'title', 'song', 'track', 'album', 'single', 'debut', 'comeback',
            'returns', 'youth', 'access', 'wings',  # Bá»: tonight, solar
            'solo', 'champion', 'crown',  # CÃ¡c tá»« Ä‘Ã£ thÃªm trÆ°á»›c Ä‘Ã³
        }
        if text_lower in generic_single_words:
            return False
        
        # ============================================
        # CHO PHÃ‰P CÃC TÃŠN ALBUM/SONG K-POP ÄÃƒ BIáº¾T (1 Tá»ª)
        # ============================================
        # Nhá»¯ng tÃªn album/bÃ i hÃ¡t K-pop ná»•i tiáº¿ng chá»‰ cÃ³ 1 tá»«
        known_kpop_album_song_names = {
            # Big Bang albums
            'tonight', 'alive', 'always', 'remember', 'made',
            # BTS albums
            'wings', 'proof',
            # BLACKPINK songs/albums
            'pink', 'born',
            # Other common K-pop album/song names (1 word, viáº¿t hoa)
            'blue', 'red', 'noir', 'neon', 'fever', 'bloom', 
            'lilac', 'palette', 'yellow', 'violet',
            # ThÃªm cÃ¡c tÃªn Ä‘áº·c biá»‡t
            'solar',  # MAMAMOO member nhÆ°ng cÅ©ng lÃ  album name pattern
        }
        # Náº¿u lÃ  tÃªn Ä‘Ã£ biáº¿t cá»§a K-pop, CHO PHÃ‰P
        if text_lower in known_kpop_album_song_names:
            return True  # Bypass cÃ¡c filter cÃ²n láº¡i
        
        # ============================================
        # LOáº I Bá» TÃŠN NGHá»† SÄ¨ Bá»Š NHáº¦M LÃ€ ALBUM
        # ============================================
        # Má»™t sá»‘ tÃªn nghá»‡ sÄ© K-pop cÃ³ thá»ƒ bá»‹ nháº§m lÃ  album
        artist_names_not_album = {
            'solar', 'moonbyul', 'wheein', 'hwasa',  # MAMAMOO members
            'irene', 'seulgi', 'wendy', 'joy', 'yeri',  # Red Velvet members
            'taeyeon', 'tiffany', 'jessica', 'sunny', 'yoona', 'sooyoung', 'yuri', 'hyoyeon', 'seohyun',  # SNSD
        }
        if text_lower in artist_names_not_album:
            return False
        
        # ============================================
        # LOáº I Bá» PATTERN Bá»Š Cáº®T Cá»¤T / CÃ‚U VÄ‚N
        # ============================================
        # Pattern "By Step", "Your Head Down" - bá»‹ cáº¯t tá»« tÃªn dÃ i hÆ¡n
        truncated_patterns = [
            r'^by\s+',               # "By Step" tá»« "Step By Step"
            r'^your\s+',             # "Your Head Down" tá»« "Keep Your Head Down"
            r'^the\s+\w+$',          # "The End" quÃ¡ ngáº¯n (chá»‰ 2 tá»«)
            r'^my\s+\w+$',           # "My Love" quÃ¡ ngáº¯n
            r'^our\s+\w+$',          # "Our Story" quÃ¡ ngáº¯n
            r'\s+pt\.?$',            # Káº¿t thÃºc báº±ng "Pt" hoáº·c "Pt." - bá»‹ cáº¯t
        ]
        for pattern in truncated_patterns:
            if re.match(pattern, text_lower):
                return False
        # Loáº¡i bá» náº¿u káº¿t thÃºc báº±ng "Pt" (bá»‹ cáº¯t tá»« "Pt. 1", "Pt. 2")
        if text_lower.endswith(' pt') or text_lower.endswith(' pt.'):
            return False
        
        # ============================================
        # LOáº I Bá» CÃ‚U VÄ‚N / MÃ” Táº¢ (KHÃ”NG PHáº¢I TÃŠN ALBUM)
        # ============================================
        # Pattern cÃ³ Ä‘á»™ng tá»« hoáº·c cáº¥u trÃºc cÃ¢u
        sentence_indicators = [
            r"exceeds\s+\d+",        # "Fearless' exceeds 380"
            r"has\s+now\s+hit",      # "Has Now Hit No"
            r"hits?\s+no\.?\s*\d*",  # "Hits No 1"
            r"reaches?\s+\d+",       # "Reaches 100"
            r"sells?\s+\d+",         # "Sells 1 Million"
            r"debuts?\s+at",         # "Debuts At No"
            r"peaks?\s+at",          # "Peaks At No"
            r"chart\s*\d+",          # "Chart 2022"
            r"kor\s+down",           # "KOR Down"
            r"title\s+song",         # "Title Song"
            r"love\s+day\s+\d+",     # "Love Day 2012 Jung Eunji"
            r"miak\s+k-?pop",        # "MIAK K-pop"
            r"ranking[s]?\s+\w+\s+\d+",  # "Ranking February 19", "Rankings April 10"
            r"sales\s+chart",        # "Sales Chart", "Sales Chart as Tom Petty"
            r"as\s+tom\s+petty",     # "... as Tom Petty"
            r"already\s+at\s+\d+",   # "Already at 150"
            r"award\s+for",          # "Award for 5 Consecutive Years"
            r"consecutive\s+years",  # "... Consecutive Years"
            r"authentic.*takes",     # "BE 'authentic' but takes 'few risks"
            r"but\s+takes",          # "... but takes ..."
            r"few\s+risks",          # "... few risks"
            r"preview\s+released",   # "Beam of Prism' preview released"
            r"surpasses?\s+\d+",     # "Blue Hour' surpasses 300"
            r"chart\s*-\s*\w+",      # "Chart - Annual", "Chart - Week 13"
            r"chart\s*-\s*week",     # "Chart - Week XX"
            r"charts?\s*-\s*\w+",    # "Charts - July", "Charts - September"
            r"chart\s+dated",        # "Chart dated February 1"
            r"chart\s+for\s+week",   # "Chart for Week ending November 23"
            r"chart\s+from",         # "Chart from September 6-12"
            r"chart\s+in\s+\w+",     # "Chart in November"
            r"to\s+be\s+released",   # "Chat-shire' to be released on October 23"
            r"released\s+on\s+\w+",  # "... released on October 23"
            r"pre-?order\s+begins",  # "IM HERO' pre-order begins"
            r"kicks\s+off",          # "Kicks Off With 'Freal Luv' Video ft"
            r"in\s+sales\s+with",    # "King in Sales with 400"
            r"ranking\s+as\s+of",    # "Ranking as of November 20"
            r"ranking\s+for\s+\w+",  # "Ranking for February 21"
            r"ranking\s+on\s+\w+",   # "Ranking on January 30"
            r"ranks?\s+no",          # "Ranks No"
            r"on\s+march\s+\d+",     # "Ruby on March 7"
            r"on\s+\w+\s+\d+",       # "... on October 23"
            r"top-?\d+\s+uge",       # "Top-40 Uge 38"
            r"label\s+notes?\s+ref", # "Label Notes Ref"
            r"up-?and-?coming",      # "Up-and-coming girls..."
            r"kpop\s+week\s+\d+",    # "KPOP Week 25"
            r"chart\s+week\s+\d+",   # "Chart Week 24"
            r"sold\s+more\s+than",   # "DYE' Sold More Than 280"
            r"\s+sau\s+khi",         # "Dear Santa sau khi" - cÃ³ tá»« tiáº¿ng Viá»‡t
            r"tracklist\s+\d+",      # "Hear Things tracklist 1"
            r"is\s+an?\s+\w+ing",    # "Is an Inviting"
            r"k-?pop\s+miak",        # "K-pop MIAK"
            r"releases?\s+today",     # "Producer releases today"
            r"releases?\s+tomorrow",  # "... releases tomorrow"
            r"releases?\s+on\s+\w+", # "... releases on ..."
            r"producer\s+releases?",  # "Producer releases ..."
            r"on\s+why",              # "... on Why New 'Holler' EP Represents..."
            r"represents?\s+their",    # "... Represents Their 'Mind, Body and Soul'"
            r"represents?\s+",        # "... Represents ..."
        ]
        for pattern in sentence_indicators:
            if re.search(pattern, text_lower):
                return False
        
        # ============================================
        # LOáº I Bá» CÃ‚U VÄ‚N Báº®T Äáº¦U Báº°NG DANH Tá»ª + Äá»˜NG Tá»ª
        # ============================================
        # Pattern: "Producer releases today", "Album drops tomorrow"
        sentence_starters = ['producer', 'album', 'single', 'ep', 'song', 'track']
        if text_lower.split()[0] in sentence_starters:
            # Kiá»ƒm tra xem cÃ³ Ä‘á»™ng tá»« khÃ´ng
            if any(verb in text_lower for verb in ['releases', 'release', 'drops', 'drop', 'comes', 'come', 'arrives', 'arrive']):
                return False
        
        # ============================================
        # LOáº I Bá» TÃŠN Bá»Š Cáº®T Cá»¤T (Káº¾T THÃšC Báº°NG "VOL", "FIN", ETC.)
        # ============================================
        truncated_suffixes = [' vol', ' fin', ' pt', ' cmb', ' ver', ' o', ' d', " don", " don'"]
        for suffix in truncated_suffixes:
            if text_lower.endswith(suffix):
                return False
        
        # Loáº¡i bá» pattern bá»‹ cáº¯t cá»¥t phá»• biáº¿n
        # "I Don" tá»« "I Don't...", "As If It" tá»« "As If It's Your Last", "Yes I" tá»« "Yes I Am"
        truncated_patterns = [
            r"^i don$",              # "I Don" tá»« "I Don't..."
            r"^baby don$",           # "Baby don" tá»« "Baby don't..."
            r"^as if it$",           # "As If It" tá»« "As If It's Your Last"
            r"^yes i$",              # "Yes I" tá»« "Yes I Am"
            r"^coup d$",             # "Coup d" tá»« "Coup d'Etat"
            r"\w+ don$",             # Báº¥t ká»³ tá»« nÃ o káº¿t thÃºc báº±ng " don"
        ]
        for pattern in truncated_patterns:
            if re.match(pattern, text_lower):
                return False
        
        # ============================================
        # LOáº I Bá» PATTERN "VERSE + Sá»"
        # ============================================
        # "Verse 2" - khÃ´ng pháº£i album, lÃ  pháº§n cá»§a album
        if re.match(r'^verse\s+\d+$', text_lower):
            return False
        
        # ============================================
        # LOáº I Bá» TÃŠN CÃ“ Dáº¤U NHÃY Láºº + TÃŠN TRANG WEB
        # ============================================
        # "Red Light' Allkpop" - cÃ³ dáº¥u nhÃ¡y láº» + tÃªn trang web
        website_names = ['allkpop', 'soompi', 'koreaboo', 'billboard', 'genius']
        if "'" in text:
            # CÃ³ dáº¥u nhÃ¡y Ä‘Æ¡n
            for website in website_names:
                if website in text_lower:
                    return False
        
        # ============================================
        # LOáº I Bá» TÃŠN Ná»€N Táº¢NG / Dá»ŠCH Vá»¤
        # ============================================
        platform_names = {'itunes', 'spotify', 'melon', 'genie', 'bugs', 'flo'}
        if text_lower in platform_names:
            return False
        
        # ============================================
        # LOáº I Bá» VIáº¾T Táº®T KHÃ”NG RÃ• RÃ€NG
        # ============================================
        abbreviation_patterns = [
            r'^jpn\s+\w+$',          # "JPN Cmb"
            r'^kor\s+\w+$',          # "KOR ..."
            r'^eng\s+\w+$',          # "ENG ..."
        ]
        for pattern in abbreviation_patterns:
            if re.search(pattern, text_lower):
                return False
        
        # ============================================
        # LOáº I Bá» TÃŠN THÃ€NH VIÃŠN K-POP Bá»Š NHáº¦M LÃ€ ALBUM
        # ============================================
        kpop_member_names = {
            'jeonghan', 'wonwoo', 'mingyu', 'seungkwan', 'vernon', 'dino',  # Seventeen
            'gigi', 'bella',  # TÃªn ngÆ°á»i ná»•i tiáº¿ng khÃ¡c
            'minkyeung', 'nayoung', 'kyulkyung', 'eunwoo', 'roa', 'yuha', 'rena', 'kyla', 'sungyeon',  # Pristin
        }
        if text_lower in kpop_member_names:
            return False
        
        # ============================================
        # LOáº I Bá» Tá»ª CHUNG CHUNG KHÃC (chá»‰ nhá»¯ng tá»« rÃµ rÃ ng khÃ´ng pháº£i album)
        # ============================================
        generic_album_words = {
            'group note', 'notes ref',
            'makestar',  # TÃªn ná»n táº£ng crowdfunding
        }
        if text_lower in generic_album_words:
            return False
        
        # ============================================
        # LOáº I Bá» PATTERN CÃ“ Dáº¤U NHÃY Láºº + NÄ‚M
        # ============================================
        # "CRUSH' 2014" - cÃ³ dáº¥u nhÃ¡y láº»
        if re.search(r"'\s*\d{4}$", text):
            return False
        
        # ============================================
        # LOáº I Bá» TÃŠN CHÆ¯Æ NG TRÃŒNH / LIVE
        # ============================================
        if 'countdown live' in text_lower or 'live concert' in text_lower:
            return False
        
        # ============================================
        # LOáº I Bá» THÃ”NG TIN CHART (ORICON + Sá»)
        # ============================================
        if re.search(r'^oricon\s+\d+', text_lower):
            return False
        
        # ============================================
        # LOáº I Bá» PATTERN "TÃŠN + Sá» THá»¨ Háº NG" (chart positions)
        # ============================================
        # Pattern nhÆ° "Crayon 16 1", "DDARA 12 1", "Feel me 17 1"
        # ThÆ°á»ng lÃ : TÃªn bÃ i + vá»‹ trÃ­ chart + tuáº§n
        if re.search(r'\s+\d+\s+\d+$', text):
            return False
        # Pattern káº¿t thÃºc báº±ng "sá»‘ 1" hoáº·c "sá»‘ sá»‘"
        if re.search(r'\s+\d{1,3}\s+1$', text):
            return False
        
        # ============================================
        # LOáº I Bá» PATTERN VIáº¾T Táº®T CHART
        # ============================================
        chart_abbreviations = [
            r'^gaon\s+',             # "Gaon 151", "Gaon khi"
            r'^hq\s+',               # "HQ Down", "HQ Gaon TQ Baidu"
            r'\s+hq\s+',             # "... HQ ..."
            r'^tq\s+',               # "TQ Baidu"
            r'\s+tq\s+',             # "... TQ ..."
            r'baidu',                # "... Baidu"
        ]
        for pattern in chart_abbreviations:
            if re.search(pattern, text_lower):
                return False
        
        # ============================================
        # LOáº I Bá» TÃŠN CÃ”NG TY Bá»Š NHáº¦M LÃ€ ALBUM
        # ============================================
        company_patterns = [
            r's\.?m\.?\s+entertainment',  # "S.M Entertainment Co"
            r'entertainment\s+co',
            r'yg\s+entertainment',
            r'jyp\s+entertainment',
            r'hybe\s+',
        ]
        for pattern in company_patterns:
            if re.search(pattern, text_lower):
                return False
        
        # ============================================
        # LOáº I Bá» TÃŠN NHÃ“M + Tá»ª Láºº
        # ============================================
        # Pattern "U-KISS cho", "BTS vÃ ", "EXO vá»›i"
        group_plus_word = [
            r'^u-kiss\s+\w{1,4}$',    # "U-KISS cho"
            r'^bts\s+\w{1,4}$',
            r'^exo\s+\w{1,4}$',
            r'^nct\s+\w{1,4}$',
        ]
        for pattern in group_plus_word:
            if re.search(pattern, text_lower):
                return False
        
        # ============================================
        # LOáº I Bá» PATTERN UNLOCK/EP LáºªN Lá»˜N
        # ============================================
        # "Unlock UNIQ EP Falling In Love" - nhiá»u album gá»™p láº¡i
        if 'unlock' in text_lower and 'ep' in text_lower:
            return False
        if text.count(' ') >= 4 and ('EP' in text or 'Album' in text):
            # QuÃ¡ nhiá»u tá»« vÃ  cÃ³ EP/Album trong tÃªn -> cÃ³ thá»ƒ lÃ  lá»—i
            return False
        
        # ============================================
        # LOáº I Bá» TÃŠN CÃ“ CHá»¨A TÃŠN NGHá»† SÄ¨/NHÃ“M NHáº C LáºªN Lá»˜N
        # ============================================
        # Pattern "Album Name + Artist Name" nhÆ° "Beep BTOB Yoojin"
        kpop_group_names_in_album = ['btob', 'exo', 'bts', 'nct', 'got7', 'ikon', 'winner', 'ateez', 'stray kids']
        for group in kpop_group_names_in_album:
            if group in text_lower and len(text.split()) >= 2:
                # CÃ³ tÃªn nhÃ³m trong tÃªn album vÃ  cÃ³ nhiá»u tá»« -> cÃ³ thá»ƒ lÃ  lá»—i
                words_after_group = text_lower.split(group)[-1].strip()
                if words_after_group and len(words_after_group) > 2:
                    return False
        
        # ============================================
        # LOáº I Bá» TÃŠN NHÃ“M NHáº C Bá»Š NHáº¦M LÃ€ ALBUM
        # ============================================
        group_names_not_album = {
            'april', 'twice', 'blackpink', 'bts', 'exo', 'nct', 'red velvet',
            'mamamoo', 'itzy', 'aespa', 'ive', 'newjeans', 'le sserafim',
            'stayc', 'nmixx', 'kep1er', 'gidle', 'everglow', 'loona',
        }
        if text_lower in group_names_not_album:
            return False
        
        # ============================================
        # LOáº I Bá» TÃŠN NGÆ¯á»œI (KHÃ”NG PHáº¢I ALBUM)
        # ============================================
        # Pattern "Firstname Lastname" vá»›i tÃªn phÆ°Æ¡ng TÃ¢y
        western_names = {
            'danny', 'chung', 'david', 'scott', 'michael', 'john', 'james', 
            'robert', 'william', 'richard', 'joseph', 'thomas', 'chris', 
            'daniel', 'mark', 'paul', 'steven', 'kevin', 'brian', 'george',
            'jung', 'eunji', 'kim', 'lee', 'park', 'choi', 'kang',
        }
        words_in_album = text_lower.split()
        # Náº¿u táº¥t cáº£ cÃ¡c tá»« Ä‘á»u lÃ  tÃªn ngÆ°á»i -> khÃ´ng pháº£i album
        if len(words_in_album) >= 2 and all(w in western_names for w in words_in_album):
            return False
        # Náº¿u cÃ³ tÃªn + nÄƒm -> cÃ³ thá»ƒ lÃ  lá»—i
        if re.search(r'\b\d{4}\b.*[A-Z][a-z]+', text) or re.search(r'[A-Z][a-z]+.*\b\d{4}\b', text):
            # CÃ³ nÄƒm trong tÃªn album -> kiá»ƒm tra thÃªm
            if any(name in text_lower for name in ['jung', 'eunji', 'kim', 'lee', 'park']):
                return False
        
        # ============================================
        # LOáº I Bá» Tá»ª VIáº¾T Táº®T / THUáº¬T NGá»® Ã‚M NHáº C
        # ============================================
        music_abbreviations = {
            'all out', 'kor down', 'jpn', 'usa', 'uk', 'eng', 'chn', 'twn',
            'mv', 'pv', 'ost', 'bgm', 'inst', 'ver', 'version',
        }
        if text_lower in music_abbreviations:
            return False
            
    elif entity_type == 'Company':
        company_kw = ['entertainment', 'music', 'media', 'records', 'label']
        if not any(kw in text_lower for kw in company_kw):
            if len(text) > 20 or not text[0].isupper():
                return False
    
    return True

# =====================================================
# PATTERNS NER (Má» Rá»˜NG Äá»‚ Báº®T NHIá»€U THá»°C THá»‚ HÆ N)
# =====================================================
patterns = {
    'Artist': [
        # Pattern cÆ¡ báº£n
        r'(?:ca sÄ©|nghá»‡ sÄ©|rapper|idol|tháº§n tÆ°á»£ng|thÃ nh viÃªn)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s+(?:lÃ |sinh|Ä‘Ã£|Ä‘Æ°á»£c|cÃ³)|\,|\.|$)',
        r'([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s+(?:lÃ  má»™t|lÃ )\s+(?:ca sÄ©|nghá»‡ sÄ©|rapper|idol)',
        # ThÃ nh viÃªn nhÃ³m: "thÃ nh viÃªn G-Dragon vÃ  T.O.P"
        r'thÃ nh viÃªn\s+([A-Z][a-zA-Z0-9\-\.]+)(?:\s+vÃ |\s*,)',
        # Solo artist: "G-Dragon phÃ¡t hÃ nh album solo"
        r'([A-Z][a-zA-Z0-9\-\.]+)\s+phÃ¡t hÃ nh\s+(?:album|EP|single)\s+solo',
        # "do X viáº¿t lá»i" - nháº¡c sÄ©
        r'do\s+(?:chÃ­nh\s+)?([A-Z][a-zA-Z0-9\-\.]+)\s+(?:viáº¿t|sÃ¡ng tÃ¡c|sáº£n xuáº¥t)',
        # "X tham gia" - nghá»‡ sÄ©
        r'([A-Z][a-zA-Z0-9\-\.]+)\s+(?:tham gia|há»£p tÃ¡c|gÃ³p máº·t|viáº¿t lá»i)',
        # "thÃ nh viÃªn Verbal cá»§a M-Flo" pattern
        r'thÃ nh viÃªn\s+([A-Z][a-zA-Z0-9\-\.]+)\s+cá»§a',
    ],
    'Group': [
        r'(?:nhÃ³m nháº¡c|ban nháº¡c|group|boyband|girlgroup)\s+([A-Z][a-zA-Z0-9\s\-\'\.()]+?)(?:\s+(?:lÃ |gá»“m|cÃ³|Ä‘Æ°á»£c|ra máº¯t)|\,|\.|$)',
        r'([A-Z][a-zA-Z0-9\s\-\'\.()]+?)\s+(?:lÃ  má»™t|lÃ )\s+(?:nhÃ³m nháº¡c|ban nháº¡c)',
        # "nhÃ³m X trá»Ÿ láº¡i", "nhÃ³m X phÃ¡t hÃ nh"
        r'nhÃ³m\s+([A-Z][a-zA-Z0-9\s\-\'\.()]+?)\s+(?:trá»Ÿ láº¡i|phÃ¡t hÃ nh|ra máº¯t|biá»ƒu diá»…n)',
        # "cá»§a nhÃ³m nháº¡c nam HÃ n Quá»‘c Big Bang" - ráº¥t phá»• biáº¿n trong Wikipedia
        r'cá»§a\s+nhÃ³m\s+nháº¡c\s+(?:nam|ná»¯)?\s*(?:HÃ n\s+Quá»‘c|HÃ nâ€“Trung\s+Quá»‘c)?\s*([A-Z][a-zA-Z0-9\s\-\'\.()]+?)(?:\s*[,\.]|\s+(?:Ä‘Æ°á»£c|do|lÃ |bao gá»“m))',
        # "cá»§a ban nháº¡c HÃ n Quá»‘c Big Bang"
        r'cá»§a\s+ban\s+nháº¡c\s+(?:HÃ n\s+Quá»‘c)?\s*([A-Z][a-zA-Z0-9\s\-\'\.()]+?)(?:\s*[,\.]|\s+(?:Ä‘Æ°á»£c|do|lÃ ))',
        # "nhÃ³m nháº¡c nam HÃ n Quá»‘c X" - ngay sau Ä‘á»‹nh nghÄ©a
        r'nhÃ³m\s+nháº¡c\s+(?:nam|ná»¯)?\s*(?:HÃ n\s+Quá»‘c|HÃ nâ€“Trung\s+Quá»‘c)?\s+([A-Z][a-zA-Z0-9\s\-\'\.()]+?)(?:\s*[,\.]|\s+(?:Ä‘Æ°á»£c|do|lÃ |gá»“m|bao gá»“m|thÃ nh láº­p))',
        # "nhÃ³m nhá» X cá»§a" - subgroup
        r'nhÃ³m\s+nhá»\s+(?:chÃ­nh\s+thá»©c)?\s*([A-Z][a-zA-Z0-9\s\-\'\.()]+?)\s+cá»§a',
        # "bá»™ Ä‘Ã´i X" - duo group
        r'bá»™\s+Ä‘Ã´i\s+([A-Z][a-zA-Z0-9\s\-\'\.()]+?)(?:\s*[,\.]|\s+(?:Ä‘Æ°á»£c|do|lÃ |gá»“m))',
    ],
    'Album': [
        # === PATTERNS CÆ  Báº¢N ===
        r'(?:album|mini[- ]?album|EP)\s+["\']?([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']?(?:\s+(?:lÃ |Ä‘Æ°á»£c|phÃ¡t hÃ nh)|\,|\.|$)',
        # Album vá»›i dáº¥u ngoáº·c kÃ©p Ä‘áº·c biá»‡t (Wikipedia thÆ°á»ng dÃ¹ng)
        r'(?:album|mini[- ]?album|EP)\s+["""]([A-Z][a-zA-Z0-9\s\-\'\.]+?)["""]',
        
        # === PATTERNS THEO NGá»® Cáº¢NH TIáº¾NG VIá»†T ===
        # "EP Always Ä‘Æ°á»£c phÃ¡t hÃ nh vÃ o nÄƒm 2007"
        r'EP\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s+(?:Ä‘Æ°á»£c phÃ¡t hÃ nh|ra máº¯t|bÃ¡n Ä‘Æ°á»£c)',
        # "mini album Ä‘áº§u tiÃªn Always"
        r'mini album\s+(?:Ä‘áº§u tiÃªn|thá»© \w+|tiáº¿p theo|má»›i)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:Ä‘Æ°á»£c|bÃ¡n|ra|Ä‘áº¡t|giÃ nh))',
        # "album Ä‘áº§u tay Since 2007"
        r'album\s+(?:Ä‘áº§u tay|Ä‘áº§u tiÃªn|thá»© \w+|tiáº¿p theo|má»›i nháº¥t|phiÃªn báº£n Ä‘áº·c biá»‡t)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:Ä‘Æ°á»£c|bÃ¡n|ra|tá»•ng há»£p))',
        # "phÃ¡t hÃ nh album Tonight"
        r'phÃ¡t hÃ nh\s+(?:album|EP|mini album)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:vÃ o|vá»›i|bao gá»“m))',
        # "ra máº¯t album Alive"
        r'ra máº¯t\s+(?:album|EP|mini album)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:vÃ o|vá»›i|dÆ°á»›i))',
        # "trá»Ÿ láº¡i vá»›i album Tonight"
        r'trá»Ÿ láº¡i\s+(?:vá»›i|báº±ng|cÃ¹ng)\s+(?:album|EP)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:vÃ o|vá»›i))',
        # "album thÃ nh cÃ´ng nháº¥t cá»§a mÃ¬nh, Alive"
        r'album\s+(?:thÃ nh cÃ´ng nháº¥t|ná»•i tiáº¿ng nháº¥t|hay nháº¥t)[^,]*,\s*([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:Ä‘Æ°á»£c|lÃ ))',
        
        # === PATTERNS TIáº¾NG ANH (PHá»” BIáº¾N TRONG WIKIPEDIA TIáº¾NG VIá»†T) ===
        # "album tiáº¿ng Nháº­t Ä‘áº§u tiÃªn mang tÃªn Big Bang"
        r'album\s+(?:tiáº¿ng\s+\w+)?\s*(?:Ä‘áº§u tiÃªn|thá»© \w+)?\s*(?:mang tÃªn|cÃ³ tÃªn|tÃªn lÃ )\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.])',
        # "album Remember, vá»›i ca khÃºc"
        r'album\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s*,\s*vá»›i\s+(?:ca khÃºc|bÃ i hÃ¡t)',
        # "EP Stand Up - káº¿t há»£p vá»›i"
        r'(?:EP|album)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s*-\s*(?:káº¿t há»£p|bao gá»“m|vá»›i)',
        
        # === PATTERNS Má»šI - PHá»” BIáº¾N TRONG WIKIPEDIA ===
        # "lÃ  album phÃ²ng thu Ä‘áº§u tay cá»§a X" - báº¯t album tá»« Ä‘áº§u cÃ¢u
        r'([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s+lÃ \s+(?:album|mini-album|EP)\s+(?:phÃ²ng thu|studio)?\s*(?:Ä‘áº§u tay|Ä‘áº§u tiÃªn|thá»© \w+)',
        # "album X Ä‘Æ°á»£c phÃ¡t hÃ nh" - album + tÃªn + Ä‘á»™ng tá»«
        r'album\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s+(?:Ä‘Æ°á»£c phÃ¡t hÃ nh|ra máº¯t|phÃ¡t hÃ nh|bÃ¡n Ä‘Æ°á»£c)',
        # "tá»« album X" - trÃ­ch tá»« album
        r'tá»«\s+(?:album|EP)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:phÃ¡t hÃ nh|cá»§a))',
        # "trong album X" - bÃ i hÃ¡t trong album
        r'(?:trong|náº±m trong)\s+(?:album|EP)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:phÃ¡t hÃ nh|cá»§a))',
        # "phiÃªn báº£n tiáº¿ng Nháº­t cá»§a X"
        r'phiÃªn báº£n\s+tiáº¿ng\s+\w+\s+cá»§a\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.])',
        # "Ä‘Ä©a Ä‘Æ¡n trÃ­ch tá»« album X"
        r'trÃ­ch\s+tá»«\s+album\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:phÃ¡t hÃ nh))',
    ],
    'Song': [
        # === PATTERNS CÆ  Báº¢N ===
        # Dáº¡ng cÃ³ dáº¥u ngoáº·c kÃ©p chuáº©n
        r'(?:bÃ i hÃ¡t|ca khÃºc|single|Ä‘Ä©a Ä‘Æ¡n)\s+["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']',
        # Dáº¡ng cÃ³ dáº¥u ngoáº·c kÃ©p Ä‘áº·c biá»‡t (Wikipedia)
        r'(?:bÃ i hÃ¡t|ca khÃºc|single|Ä‘Ä©a Ä‘Æ¡n)\s+["""]([A-Z][a-zA-Z0-9\s\-\'\.]+?)["""]',
        # Ca khÃºc chá»§ Ä‘á»
        r'ca khÃºc chá»§ Ä‘á»\s+["\']?([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']?',
        # Dáº¡ng khÃ´ng dáº¥u ngoáº·c kÃ©p + Ä‘á»™ng tá»«
        r'(?:bÃ i hÃ¡t|ca khÃºc|single|Ä‘Ä©a Ä‘Æ¡n)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s+(?:Ä‘Æ°á»£c|do|cá»§a|ra máº¯t|phÃ¡t hÃ nh|trong|lÃ |Ä‘á»©ng Ä‘áº§u|giÃ nh|trá»Ÿ thÃ nh)\b',
        # Dáº¡ng "cÃ³ tÃªn"/"mang tÃªn"
        r'(?:bÃ i hÃ¡t|ca khÃºc|single|Ä‘Ä©a Ä‘Æ¡n)\s+(?:cÃ³ tÃªn|mang tÃªn)\s+["\']?([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']?',
        
        # === PATTERNS THEO NGá»® Cáº¢NH TIáº¾NG VIá»†T ===
        # "Ä‘Ä©a Ä‘Æ¡n sá»‘ má»™t cá»§a há» lÃ  \"Lies\""
        r'Ä‘Ä©a Ä‘Æ¡n\s+(?:sá»‘ má»™t|Ä‘áº§u tiÃªn|thá»© \w+)[^"]*["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']',
        # "ca khÃºc hit Ä‘á»™t phÃ¡ Ä‘áº§u tiÃªn cá»§a nhÃ³m" - thÆ°á»ng theo sau lÃ  tÃªn bÃ i
        r'ca khÃºc\s+(?:hit|ná»•i tiáº¿ng|Ä‘á»™t phÃ¡)[^,]*,?\s*["\']?([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']?(?:\s*[,\.]|\s+(?:trá»Ÿ thÃ nh|Ä‘á»©ng Ä‘áº§u|giÃ nh))',
        # "single tiáº¿ng Nháº­t Ä‘áº§u tiÃªn \"My Heaven\""
        r'single\s+(?:tiáº¿ng\s+\w+)?\s*(?:Ä‘áº§u tiÃªn|thá»© \w+|má»›i)?\s*["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']',
        # "bÃ i hÃ¡t chá»§ Ä‘á» \"Monster\""
        r'bÃ i hÃ¡t\s+chá»§ Ä‘á»\s+["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']',
        # "ca khÃºc \"Lies\" (Tiáº¿ng Triá»u TiÃªn: ...)"
        r'ca khÃºc\s+["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\'](?:\s*\()',
        # "BÃ i hÃ¡t \" Flower Road \" Ä‘Æ°á»£c phÃ¡t hÃ nh" (cÃ³ khoáº£ng tráº¯ng trong ngoáº·c kÃ©p)
        r'[Bb]Ã i hÃ¡t\s+["\"]\s*([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s*["\"]\s+(?:Ä‘Æ°á»£c|do|lÃ |Ä‘á»©ng)',
        
        # === PATTERNS DANH SÃCH CA KHÃšC ===
        # "cÃ¡c ca khÃºc \"Lies\", \"Last Farewell\""
        r'(?:cÃ¡c\s+)?ca khÃºc\s+["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\'](?:\s*,|\s+vÃ )',
        # "bao gá»“m cÃ¡c ca khÃºc \"We Belong Together\""
        r'bao gá»“m\s+(?:cÃ¡c\s+)?ca khÃºc\s+["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']',
        
        # === PATTERNS CHO HIT/SINGLE PHá»” BIáº¾N ===
        # "hit X cá»§a nhÃ³m"
        r'hit\s+["\']?([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']?\s+(?:cá»§a|giÃºp|Ä‘Æ°a)',
        # "single X Ä‘áº¡t Ä‘Æ°á»£c"
        r'single\s+["\']?([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']?\s+(?:Ä‘áº¡t Ä‘Æ°á»£c|Ä‘á»©ng|vÆ°Æ¡n)',
        # "CÃº hÃ­t \"Lies\" Ä‘Ã£ Ä‘Æ°a Big Bang"
        r'[Cc]Ãº hÃ­t\s+["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']',
        
        # === PATTERNS Má»šI - ESCAPED QUOTES TRONG JSON ===
        # Pattern cho dáº¥u ngoáº·c kÃ©p escaped: \"X\"
        r'(?:bÃ i hÃ¡t|ca khÃºc|single|Ä‘Ä©a Ä‘Æ¡n)\s+\\"([A-Z][a-zA-Z0-9\s\-\'\.]+?)\\"',
        # "Ä‘Ä©a Ä‘Æ¡n \"Blue\", \"Fantastic Baby\""
        r'Ä‘Ä©a Ä‘Æ¡n\s*,?\s*\\"([A-Z][a-zA-Z0-9\s\-\'\.]+?)\\"',
        # "vá»›i ca khÃºc \"X\""
        r'vá»›i\s+ca\s+khÃºc\s+\\"([A-Z][a-zA-Z0-9\s\-\'\.]+?)\\"',
        # "bÃ i hÃ¡t \"X\" cá»§a"
        r'bÃ i\s+hÃ¡t\s+\\"([A-Z][a-zA-Z0-9\s\-\'\.]+?)\\"\s+(?:cá»§a|trong|lÃ )',
        # Pattern cho Ä‘Ä©a Ä‘Æ¡n chÃ­nh
        r'Ä‘Ä©a\s+Ä‘Æ¡n\s+(?:chÃ­nh|má»›i)?\s*(?:mang tÃªn)?\s*\\"([A-Z][a-zA-Z0-9\s\-\'\.]+?)\\"',
        # "\" X \"lÃ " pattern - tÃªn bÃ i á»Ÿ Ä‘áº§u Ä‘oáº¡n text
        r'\\"\s*([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s*\\"\s*(?:lÃ  Ä‘Ä©a Ä‘Æ¡n|lÃ  ca khÃºc|lÃ  bÃ i hÃ¡t)',
    ],
    'Company': [
        r'(?:cÃ´ng ty|agency|label)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?(?:Entertainment|Music|Media)?)',
        # "Ä‘Æ°á»£c thÃ nh láº­p bá»Ÿi YG Entertainment"
        r'(?:Ä‘Æ°á»£c thÃ nh láº­p|thuá»™c|quáº£n lÃ½)\s+bá»Ÿi\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?(?:Entertainment|Music|Media))',
        # "dÆ°á»›i sá»± dáº«n dáº¯t cá»§a YG Entertainment"
        r'(?:dÆ°á»›i sá»±|thuá»™c)\s+(?:dáº«n dáº¯t|quáº£n lÃ½)\s+(?:cá»§a\s+)?([A-Z][a-zA-Z0-9\s\-\'\.]+?(?:Entertainment|Music|Media))',
        # "thÃ´ng qua hÃ£ng thu Ã¢m X Entertainment"
        r'(?:thÃ´ng qua|bá»Ÿi)\s+(?:hÃ£ng\s+thu\s+Ã¢m|cÃ´ng ty)?\s*([A-Z][a-zA-Z0-9\s\-\'\.]+?(?:Entertainment|Music|Media))',
        # "Ä‘Æ°á»£c X Entertainment phÃ¡t hÃ nh"
        r'Ä‘Æ°á»£c\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?(?:Entertainment|Music|Media))\s+(?:phÃ¡t hÃ nh|phÃ¢n phá»‘i)',
        # "kÃ½ há»£p Ä‘á»“ng vá»›i X Entertainment"
        r'kÃ½\s+há»£p\s+Ä‘á»“ng\s+vá»›i\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?(?:Entertainment|Music|Media))',
    ],
}

# =====================================================
# TRÃCH XUáº¤T ENTITIES
# =====================================================
def extract_entities(text, entity_type, pattern_list):
    """TrÃ­ch xuáº¥t entities báº±ng regex"""
    entities = []
    seen = set()
    
    for pattern in pattern_list:
        try:
            for match in re.finditer(pattern, text, re.IGNORECASE | re.MULTILINE):
                entity_text = match.group(1) if match.lastindex else match.group(0)
                entity_text = clean_text(entity_text)
                
                if not entity_text or entity_text.lower() in seen:
                    continue
                # CHUáº¨N HÃ“A entity text trÆ°á»›c khi check vá»›i existing_lower
                # QUAN TRá»ŒNG: DÃ¹ng CÃ™NG cÃ¡ch chuáº©n hÃ³a nhÆ° khi táº¡o existing_lower
                # DÃ¹ng normalize_for_comparison Ä‘á»ƒ Ä‘áº£m báº£o cÃ¹ng cÃ¡ch chuáº©n hÃ³a vá»›i merge_and_import_neo4j.py
                entity_key = normalize_for_comparison(entity_text)
                # QUAN TRá»ŒNG: Chá»‰ loáº¡i bá» náº¿u cÃ¹ng tÃªn VÃ€ cÃ¹ng type
                # Náº¿u trÃ¹ng -> bá» qua (khÃ´ng táº¡o node má»›i)
                if entity_key in existing_lower and entity_type in existing_lower[entity_key]:
                    continue
                if not is_valid_entity(entity_text, entity_type):
                    continue
                
                seen.add(entity_text.lower())
                entities.append({
                    'text': entity_text,
                    'type': entity_type,
                    'method': 'rule-based',
                    'confidence': 0.7
                })
        except:
            continue
    return entities

def extract_members_from_list(text):
    """TrÃ­ch xuáº¥t thÃ nh viÃªn tá»« pattern liá»‡t kÃª nhÆ° 'bao gá»“m X thÃ nh viÃªn: A, B, C vÃ  D'"""
    entities = []
    seen = set()
    name_list_pattern = r'([A-Za-z\-\'\.\s,&/]+?)'
    
    role_keywords_vi = [
        'thÃ nh viÃªn', 'cÃ¡c thÃ nh viÃªn', 'thÃ nh viÃªn gá»“m', 'cÃ¡c thÃ nh viÃªn gá»“m',
        'cá»±u thÃ nh viÃªn', 'thÃ nh viÃªn hiá»‡n táº¡i', 'thÃ nh viÃªn cÅ©', 'thÃ nh viÃªn má»›i',
        'ca sÄ©', 'cÃ¡c ca sÄ©', 'nghá»‡ sÄ©', 'cÃ¡c nghá»‡ sÄ©', 'rapper', 'cÃ¡c rapper',
        'idol', 'cÃ¡c idol', 'giá»ng ca', 'giá»ng hÃ¡t', 'vocal', 'vocal line',
        'rap line', 'dance line', 'trÆ°á»Ÿng nhÃ³m', 'leader', 'maknae', 'visual', 'center'
    ]
    
    role_keywords_en = [
        'member', 'members', 'current members', 'former members', 'original members',
        'new members', 'lineup', 'line-up', 'line up', 'singer', 'singers',
        'artist', 'artists', 'rapper', 'rappers', 'idol', 'idols',
        'vocalist', 'vocalists', 'dancer', 'dancers', 'dance line', 'rap line',
        'vocal line', 'leader', 'leaders', 'maknae'
    ]
    
    # CÃ¡c pattern liá»‡t kÃª thÃ nh viÃªn - sá»­ dá»¥ng greedy match Ä‘á»ƒ láº¥y Ä‘á»§ danh sÃ¡ch
    member_list_patterns = [
        # === TIáº¾NG VIá»†T (cá»‘ Ä‘á»‹nh) ===
        # "bao gá»“m X thÃ nh viÃªn: A, B, C vÃ  D"
        r'(?:bao gá»“m|gá»“m cÃ³|gá»“m)\s+\d+\s+thÃ nh viÃªn\s*[:\s]\s*([A-Za-z\-\'\.\s,vÃ ]+?)(?:\s*,\s*há»|\s*\.|$)',
        # "thÃ nh viÃªn: A, B, C vÃ  D"
        r'thÃ nh viÃªn\s*:\s*([A-Za-z\-\'\.\s,vÃ ]+?)(?:\s*\.|$)',
        # "X thÃ nh viÃªn: list"
        r'\d+\s+thÃ nh viÃªn\s*:\s*([A-Za-z\-\'\.\s,vÃ ]+?)(?:\s*,\s*há»|\s*\.|$)',
        # "cÃ¡c thÃ nh viÃªn A, B, C vÃ  D"
        r'cÃ¡c\s+thÃ nh viÃªn\s+([A-Za-z\-\'\.\s,vÃ ]+?)(?:\s*\.|$)',
        # "thÃ nh viÃªn gá»“m A, B, C"
        r'thÃ nh viÃªn\s+gá»“m\s+([A-Za-z\-\'\.\s,vÃ ]+?)(?:\s*\.|$)',
        # "thÃ nh viÃªn lÃ  A, B, C"
        r'thÃ nh viÃªn\s+lÃ \s+([A-Za-z\-\'\.\s,vÃ ]+?)(?:\s*\.|$)',
        # "nhÃ³m cÃ³ X ngÆ°á»i: A, B, C"
        r'nhÃ³m\s+(?:cÃ³|gá»“m)\s+\d+\s+(?:ngÆ°á»i|thÃ nh viÃªn)\s*[:\s]\s*([A-Za-z\-\'\.\s,vÃ ]+?)(?:\s*\.|$)',
        # "má»™t sá»‘ thÃ nh viÃªn, bao gá»“m A, B, C"
        r'(?:má»™t sá»‘|nhiá»u|vÃ i)\s+thÃ nh viÃªn\s*,?\s*(?:bao gá»“m|gá»“m|nhÆ°|lÃ )\s+([A-Za-z\-\'\.\s,vÃ ]+?)(?:\s*\.|$)',
        # "cÃ¡c ca sÄ© gá»“m A, B, C"
        r'cÃ¡c\s+ca sÄ©\s+(?:gá»“m|bao gá»“m|nhÆ°|lÃ )\s+([A-Za-z\-\'\.\s,vÃ ]+?)(?:\s*\.|$)',
        # "cÃ¡c nghá»‡ sÄ© nhÆ° A, B, C"
        r'cÃ¡c\s+nghá»‡ sÄ©\s+(?:nhÆ°|gá»“m|bao gá»“m|lÃ )\s+([A-Za-z\-\'\.\s,vÃ ]+?)(?:\s*\.|$)',
        
        # === TIáº¾NG ANH (cá»‘ Ä‘á»‹nh) ===
        # "consists of X members: A, B, C and D"
        r'consists?\s+of\s+\d+\s+members?\s*[:\s]\s*([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "members: A, B, C and D"
        r'members?\s*:\s*([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "X members: A, B, C"
        r'\d+\s+members?\s*:\s*([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "the members are A, B, C"
        r'(?:the\s+)?members?\s+(?:are|include|including)\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "some members, including A, B, C"
        r'(?:some|several|many|various)\s+members?\s*,?\s*(?:including|such as|like)\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "singers such as A, B, C"
        r'singers?\s+(?:such as|like|including|include)\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "artists including A, B, C"
        r'artists?\s+(?:including|such as|like)\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "comprising A, B, C"
        r'comprising\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "composed of A, B, C"
        r'composed\s+of\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "formed by A, B, C"
        r'formed\s+by\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "featuring A, B, C"
        r'featuring\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "with members A, B, C"
        r'with\s+members?\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "lineup: A, B, C" hoáº·c "line-up: A, B, C"
        r'line[\-\s]?up\s*:\s*([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "current members: A, B, C"
        r'(?:current|original|former)\s+members?\s*:\s*([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        
        # === PATTERN CHUNG ===
        # "(A, B, C, D)" - danh sÃ¡ch trong ngoáº·c sau tÃªn nhÃ³m
        r'\(\s*([A-Z][a-z]+(?:\s*,\s*[A-Z][a-z]+){2,})\s*\)',
    ]
    
    # Dynamic patterns cho cÃ¡c tá»« khÃ³a vai trÃ² (tiáº¿ng Viá»‡t)
    connectors_vi = r'(?:bao gá»“m|gá»“m|gá»“m cÃ³|gá»“m cáº£|bao gá»“m cáº£|bao gá»“m nhá»¯ng|bao gá»“m cÃ¡c|gá»“m nhá»¯ng|gá»“m cÃ¡c|lÃ |lÃ  nhá»¯ng|lÃ  cÃ¡c)'
    for kw in role_keywords_vi:
        kw_pattern = re.escape(kw)
        member_list_patterns.append(
            rf'{kw_pattern}\s+{connectors_vi}\s*{name_list_pattern}(?:\s*\.|$)'
        )
        member_list_patterns.append(
            rf'{kw_pattern}\s*[:\-]\s*{name_list_pattern}(?:\s*\.|$)'
        )
    
    # Dynamic patterns cho tá»« khÃ³a tiáº¿ng Anh
    connectors_en = r'(?:include|includes|including|consist of|consists of|consisting of|are|were|feature|featuring|with|comprise|comprises|comprised of)'
    for kw in role_keywords_en:
        kw_pattern = re.escape(kw)
        member_list_patterns.append(
            rf'(?:the\s+)?{kw_pattern}\s+{connectors_en}\s*{name_list_pattern}(?:\s*\.|$)'
        )
        member_list_patterns.append(
            rf'(?:the\s+)?{kw_pattern}\s*[:\-]\s*{name_list_pattern}(?:\s*\.|$)'
        )
    
    for pattern in member_list_patterns:
        try:
            for match in re.finditer(pattern, text, re.IGNORECASE):
                member_list_text = match.group(1)
                if not member_list_text:
                    continue
                
                # TÃ¡ch cÃ¡c thÃ nh viÃªn báº±ng dáº¥u pháº©y hoáº·c "vÃ "/"and"/"&"
                # Thay cÃ¡c tá»« ná»‘i báº±ng dáº¥u pháº©y Ä‘á»ƒ dá»… tÃ¡ch
                member_list_text = re.sub(r'\s+vÃ \s+', ', ', member_list_text, flags=re.IGNORECASE)
                member_list_text = re.sub(r'\s+and\s+', ', ', member_list_text, flags=re.IGNORECASE)
                member_list_text = re.sub(r'\s*&\s*', ', ', member_list_text)
                member_list_text = re.sub(r'\s*;\s*', ', ', member_list_text)  # Dáº¥u cháº¥m pháº©y
                member_list_text = re.sub(r'\s*/\s*', ', ', member_list_text)  # Dáº¥u gáº¡ch chÃ©o
                
                # TÃ¡ch báº±ng dáº¥u pháº©y
                members = [m.strip() for m in member_list_text.split(',')]
                
                for member in members:
                    member = clean_text(member)
                    
                    # Bá» qua náº¿u quÃ¡ ngáº¯n hoáº·c quÃ¡ dÃ i
                    if not member or len(member) < 1 or len(member) > 30:
                        continue
                    
                    # Bá» qua náº¿u chá»©a sá»‘ (trá»« khi lÃ  tÃªn nhÆ° "2PM")
                    if re.search(r'\d', member) and not re.match(r'^[0-9][A-Za-z]+', member):
                        continue
                    
                    # Bá» qua náº¿u lÃ  tá»« chung chung
                    if member.lower() in INVALID_WORDS:
                        continue
                    
                    # Bá» qua náº¿u Ä‘Ã£ tá»“n táº¡i trong graph gá»‘c (existing_lower)
                    # CHUáº¨N HÃ“A member trÆ°á»›c khi check
                    # DÃ¹ng normalize_for_comparison Ä‘á»ƒ Ä‘áº£m báº£o cÃ¹ng cÃ¡ch chuáº©n hÃ³a vá»›i merge_and_import_neo4j.py
                    member_key = normalize_for_comparison(member)
                    # QUAN TRá»ŒNG: Chá»‰ loáº¡i bá» náº¿u cÃ¹ng tÃªn VÃ€ cÃ¹ng type (Artist)
                    if member_key in existing_lower and 'Artist' in existing_lower[member_key]:
                        continue
                    
                    if member.lower() in seen:
                        continue
                    
                    # Kiá»ƒm tra tÃ­nh há»£p lá»‡ - nhÆ°ng váº«n ná»›i lá»ng cho tÃªn thÃ nh viÃªn
                    lower_member = member.lower()
                    # Whitelist tÃªn ngáº¯n há»£p lá»‡ (trÃ¹ng vá»›i is_valid_entity)
                    # Bá»• sung thÃªm cÃ¡c tÃªn ngáº¯n há»£p lá»‡ tá»« infobox: DK, ZN, P.O, The8
                    valid_short_names = {'rm', 'iu', 'cl', 'bm', 'jb', 'jj', 'jo', 'im', 'do', 'dk', 'zn', 'p.o', 'the8'}
                    
                    if len(member) <= 2:
                        # Chá»‰ cho phÃ©p náº¿u lÃ  tÃªn ngáº¯n há»£p lá»‡ trong whitelist
                        if lower_member not in valid_short_names:
                            continue
                    elif len(member) == 3:
                        # TÃªn 3 kÃ½ tá»±: váº«n pháº£i báº¯t Ä‘áº§u báº±ng chá»¯ hoa vÃ  qua is_valid_entity
                        if not member[0].isupper() and not member.isupper():
                            continue
                        if not is_valid_entity(member, 'Artist'):
                            continue
                    else:
                        if not is_valid_entity(member, 'Artist'):
                            continue
                    
                    seen.add(member.lower())
                    entities.append({
                        'text': member,
                        'type': 'Artist',
                        'method': 'rule-based',
                        'confidence': 0.8  # Confidence cao vÃ¬ Ä‘Æ°á»£c liá»‡t kÃª rÃµ rÃ ng trong context thÃ nh viÃªn
                    })
        except Exception as e:
            continue
    
    return entities

def extract_groups_from_list(text):
    """TrÃ­ch xuáº¥t nhÃ³m nháº¡c tá»« cÃ¡c cÃ¢u liá»‡t kÃª nhÆ°:
    - 'cÃ¡c nhÃ³m nháº¡c chÃ­nh gá»“m TVXQ, Super Junior, ...'
    - 'Ä‘Ã£ tá»«ng quáº£n lÃ½ cÃ¡c nhÃ³m nháº¡c H.O.T, S.E.S., Shinhwa, ...'
    """
    entities = []
    seen = set()
    
    # Cho phÃ©p cáº£ chá»¯, sá»‘, dáº¥u cháº¥m, ngoáº·c, dáº¥u gáº¡ch, &, /
    name_list_pattern = r'([A-Za-z0-9\-\'\.\s&/()]+?)'
    
    group_list_patterns = [
        # === TIáº¾NG VIá»†T ===
        # "cÃ¡c nhÃ³m nháº¡c chÃ­nh gá»“m TVXQ, Super Junior, ..."
        r'(?:cÃ¡c|nhá»¯ng)\s+nhÃ³m nháº¡c(?:\s+\w+)*\s+(?:gá»“m|bao gá»“m|lÃ |nhÆ°)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "cÃ¡c nhÃ³m nháº¡c gá»“m TVXQ, Super Junior, ..."
        r'cÃ¡c\s+nhÃ³m nháº¡c\s+(?:gá»“m|bao gá»“m|nhÆ°|lÃ )\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "quáº£n lÃ½ cÃ¡c nhÃ³m nháº¡c TVXQ, Super Junior, ..."
        r'(?:Ä‘Ã£\s+)?(?:tá»«ng\s+)?quáº£n lÃ½\s+(?:cÃ¡c\s+)?nhÃ³m nháº¡c\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "cÃ¡c nhÃ³m nháº¡c TVXQ, Super Junior, ..."
        r'cÃ¡c\s+nhÃ³m nháº¡c\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "cÃ¡c nhÃ³m nháº¡c: TVXQ, Super Junior, ..." (cÃ³ dáº¥u :)
        r'cÃ¡c\s+nhÃ³m nháº¡c\s*:\s*' + name_list_pattern + r'(?:[.;]|$)',
        # "má»™t sá»‘ nhÃ³m nháº¡c, bao gá»“m A, B, C"
        r'(?:má»™t sá»‘|nhiá»u|vÃ i)\s+nhÃ³m nháº¡c\s*,?\s*(?:bao gá»“m|gá»“m|nhÆ°|lÃ )\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "nhÃ³m nháº¡c bao gá»“m A, B, C"
        r'nhÃ³m nháº¡c\s+(?:bao gá»“m|gá»“m|nhÆ°|lÃ )\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "cÃ¡c nhÃ³m nhÆ° A, B, C"
        r'(?:cÃ¡c|nhá»¯ng)\s+nhÃ³m\s+(?:nhÆ°|bao gá»“m|gá»“m)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "bao gá»“m cÃ¡c nhÃ³m A, B, C"
        r'bao gá»“m\s+(?:cÃ¡c|nhá»¯ng)?\s*nhÃ³m(?:\s*nháº¡c)?\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "gá»“m cÃ¡c nhÃ³m nháº¡c A, B, C"
        r'gá»“m\s+(?:cÃ¡c|nhá»¯ng)?\s*nhÃ³m(?:\s*nháº¡c)?\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "cÃ¡c nhÃ³m nháº¡c nam/ná»¯ A, B, C"
        r'(?:cÃ¡c|nhá»¯ng)\s+nhÃ³m(?:\s*nháº¡c)?(?:\s+nam|\s+ná»¯)?\s+(?:gá»“m|bao gá»“m|nhÆ°|lÃ )\s+' + name_list_pattern + r'(?:[.;]|$)',
        
        # === TIáº¾NG ANH ===
        # "groups such as A, B, C"
        r'(?:idol\s+)?groups?\s+(?:such as|like|including|include)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "some groups, including A, B, C"
        r'(?:some|several|many|various)\s+groups?\s*,?\s*(?:including|such as|like)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "groups including A, B, C"
        r'groups?\s+(?:including|such as|like)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "managed groups A, B, C"
        r'(?:managed|manages|managing)\s+(?:the\s+)?groups?\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "former/current/active groups include A, B, C"
        r'(?:former|current|active)\s+groups?\s+(?:include|including|such as|like)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "K-pop groups such as A, B, C"
        r'(?:k-?pop|korean)\s+groups?\s+(?:such as|like|including|include)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "boy groups A, B, C"
        r'(?:boy|girl)\s+groups?\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "groups: TVXQ, Super Junior, ..." (cÃ³ dáº¥u :)
        r'(?:idol\s+)?groups?\s*:\s*' + name_list_pattern + r'(?:[.;]|$)',
    ]
    
    for pattern in group_list_patterns:
        try:
            for match in re.finditer(pattern, text, re.IGNORECASE):
                group_list_text = match.group(1)
                if not group_list_text:
                    continue
                
                # Chuáº©n hÃ³a ná»‘i: 'vÃ ' / 'and' / '&'
                group_list_text = re.sub(r'\s+vÃ \s+', ', ', group_list_text, flags=re.IGNORECASE)
                group_list_text = re.sub(r'\s+and\s+', ', ', group_list_text, flags=re.IGNORECASE)
                group_list_text = re.sub(r'\s*&\s*', ', ', group_list_text)
                group_list_text = re.sub(r'\s*;\s*', ', ', group_list_text)
                
                groups = [g.strip() for g in group_list_text.split(',')]
                
                for grp in groups:
                    grp = clean_text(grp)
                    if not grp:
                        continue
                    
                    # Bá» cÃ¡c máº£nh cÃ¢u kiá»ƒu 'vÃ  Ä‘Ã£ tá»«ng quáº£n lÃ½'
                    low = grp.lower()
                    if any(kw in low for kw in ['quáº£n lÃ½', 'tá»«ng quáº£n', 'Ä‘Ã£ tá»«ng', 'Ä‘Ã£ quáº£n']):
                        continue
                    
                    if len(grp) < 2 or len(grp) > 40:
                        continue
                    
                    # Bá» qua náº¿u Ä‘Ã£ cÃ³ trong graph hoáº·c Ä‘Ã£ tháº¥y
                    # CHUáº¨N HÃ“A group name trÆ°á»›c khi check
                    # DÃ¹ng normalize_for_comparison Ä‘á»ƒ Ä‘áº£m báº£o cÃ¹ng cÃ¡ch chuáº©n hÃ³a vá»›i merge_and_import_neo4j.py
                    group_key = normalize_for_comparison(grp)
                    # QUAN TRá»ŒNG: Chá»‰ loáº¡i bá» náº¿u cÃ¹ng tÃªn VÃ€ cÃ¹ng type (Group)
                    if (group_key in existing_lower and 'Group' in existing_lower[group_key]) or group_key in seen:
                        continue
                    
                    # Pháº£i qua kiá»ƒm tra group há»£p lá»‡
                    if not is_valid_entity(grp, 'Group'):
                        continue
                    
                    seen.add(group_key)
                    entities.append({
                        'text': grp,
                        'type': 'Group',
                        'method': 'rule-based',
                        'confidence': 0.8,
                    })
        except Exception:
            continue
    
    return entities

def extract_companies_from_list(text):
    """TrÃ­ch xuáº¥t cÃ´ng ty tá»« cÃ¡c cÃ¢u liá»‡t kÃª, vÃ­ dá»¥:
    - 'cÃ¡c cÃ´ng ty giáº£i trÃ­ HÃ n Quá»‘c lÃ  YG Entertainment, Pledis Entertainment vÃ  Starship Entertainment'
    - 'ngÆ°á»i tá»«ng lÃ m viá»‡c vá»›i cÃ¡c cÃ´ng ty nhÆ° JYP Entertainment, Woollim Entertainment, Sony Music Korea vÃ  Blockberry Creative'
    - 'cÃ¡c cÃ´ng ty bao gá»“m Jin-ah Entertainment, Eru Entertainment vÃ  YMC Entertainment'
    """
    entities = []
    seen = set()
    
    # Cho phÃ©p cáº£ chá»¯, sá»‘, dáº¥u cháº¥m, ngoáº·c, dáº¥u gáº¡ch, &, /
    name_list_pattern = r'([A-Za-z0-9\-\'\.\s&/()]+?)'
    
    company_list_patterns = [
        # === TIáº¾NG VIá»†T ===
        # "cÃ¡c cÃ´ng ty giáº£i trÃ­ HÃ n Quá»‘c lÃ  YG Entertainment, Pledis Entertainment..."
        r'cÃ¡c\s+cÃ´ng ty(?:\s+giáº£i trÃ­)?(?:\s+[A-Za-zÃ€-á»¹]+)*\s+(?:lÃ |gá»“m|bao gá»“m|nhÆ°)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "cÃ¡c cÃ´ng ty: YG Entertainment, ..."
        r'cÃ¡c\s+cÃ´ng ty(?:\s+giáº£i trÃ­)?\s*:\s*' + name_list_pattern + r'(?:[.;]|$)',
        # "cÃ¡c cÃ´ng ty nhÆ° JYP Entertainment, Woollim Entertainment..."
        r'cÃ¡c\s+cÃ´ng ty(?:\s+giáº£i trÃ­)?\s+(?:nhÆ°|bao gá»“m|gá»“m)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "cÃ´ng ty ... bao gá»“m Jin-ah Entertainment, Eru Entertainment..."
        r'cÃ´ng ty(?:\s+giáº£i trÃ­)?(?:\s+[A-Za-zÃ€-á»¹]+)*\s+bao gá»“m\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "cÃ´ng ty ... nhÆ° JYP Entertainment, ..."
        r'cÃ´ng ty(?:\s+giáº£i trÃ­)?(?:\s+[A-Za-zÃ€-á»¹]+)*\s+nhÆ°\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "cÃ¡c cÃ´ng ty bao gá»“m Jin-ah Entertainment, ... "
        r'cÃ¡c\s+cÃ´ng ty(?:\s+giáº£i trÃ­)?\s+bao gá»“m\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "ngÆ°á»i tá»«ng lÃ m viá»‡c vá»›i cÃ¡c cÃ´ng ty nhÆ° JYP Entertainment, ..."
        r'cÃ¡c\s+cÃ´ng ty\s+nhÆ°\s+' + name_list_pattern + r'(?:[.;]|$)',
        
        # === TIáº¾NG ANH ===
        # "companies such as JYP Entertainment, Woollim Entertainment..."
        r'companies?\s+(?:such as|like|including|include)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "entertainment companies such as YG Entertainment, ..."
        r'(?:entertainment\s+companies?|record\s+labels?|agencies)\s+(?:such as|like|including|include)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "labels: YG Entertainment, JYP Entertainment, ..."
        r'(?:labels?|companies?)\s*:\s*' + name_list_pattern + r'(?:[.;]|$)',
    ]
    
    for pattern in company_list_patterns:
        try:
            for match in re.finditer(pattern, text, re.IGNORECASE):
                company_list_text = match.group(1)
                if not company_list_text:
                    continue
                
                # Chuáº©n hÃ³a ná»‘i: 'vÃ ' / 'and' / '&' / ';' / '/'
                company_list_text = re.sub(r'\s+vÃ \s+', ', ', company_list_text, flags=re.IGNORECASE)
                company_list_text = re.sub(r'\s+and\s+', ', ', company_list_text, flags=re.IGNORECASE)
                company_list_text = re.sub(r'\s*&\s*', ', ', company_list_text)
                company_list_text = re.sub(r'\s*;\s*', ', ', company_list_text)
                company_list_text = re.sub(r'\s*/\s*', ', ', company_list_text)
                
                # TÃ¡ch theo dáº¥u pháº©y
                companies = [c.strip() for c in company_list_text.split(',')]
                
                for comp in companies:
                    comp = clean_text(comp)
                    if not comp:
                        continue
                    
                    low = comp.lower()
                    
                    # Bá» cÃ¡c máº£nh cÃ¢u cÃ²n sÃ³t Ä‘á»™ng tá»«/mÃ´ táº£
                    if any(kw in low for kw in ['ngÆ°á»i', 'tá»«ng', 'lÃ m viá»‡c', 'há»£p tÃ¡c', 'cÃ¹ng', 'vá»›i']):
                        continue
                    
                    if len(comp) < 3 or len(comp) > 60:
                        continue
                    
                    # Bá» qua náº¿u Ä‘Ã£ cÃ³ trong graph hoáº·c Ä‘Ã£ tháº¥y
                    # CHUáº¨N HÃ“A company name trÆ°á»›c khi check
                    # DÃ¹ng normalize_for_comparison Ä‘á»ƒ Ä‘áº£m báº£o cÃ¹ng cÃ¡ch chuáº©n hÃ³a vá»›i merge_and_import_neo4j.py
                    company_key = normalize_for_comparison(comp)
                    # QUAN TRá»ŒNG: Chá»‰ loáº¡i bá» náº¿u cÃ¹ng tÃªn VÃ€ cÃ¹ng type (Company)
                    if (company_key in existing_lower and 'Company' in existing_lower[company_key]) or company_key in seen:
                        continue
                    
                    # Pháº£i qua kiá»ƒm tra company há»£p lá»‡
                    if not is_valid_entity(comp, 'Company'):
                        continue
                    
                    seen.add(normalized_company.lower())
                    entities.append({
                        'text': comp,
                        'type': 'Company',
                        'method': 'rule-based',
                        'confidence': 0.85,
                    })
        except Exception:
            continue
    
    return entities


def extract_artists_from_infobox_groups():
    """
    Táº¡o cÃ¡c node Artist má»›i tá»« infobox members cá»§a cÃ¡c Group gá»‘c.
    - DÃ¹ng dá»¯ liá»‡u Ä‘Ã£ crawl trong 'infobox_members.json' (INFOBOX_MEMBERS['groups'])
    - CÃ¡c trÆ°á»ng sá»­ dá»¥ng: 'Current members', 'Past members', 'ThÃ nh viÃªn', 'Cá»±u thÃ nh viÃªn', etc.
    - KhÃ´ng trÃ¹ng vá»›i node gá»‘c (existing_lower) vÃ  cÃ¡c node má»›i khÃ¡c
    """
    entities = []
    seen = set()

    groups = INFOBOX_MEMBERS.get('groups') or {}
    if not isinstance(groups, dict):
        return entities

    # Äá»’NG Bá»˜ HÃ“A Vá»šI RE: Sá»­ dá»¥ng cÃ¹ng member keys vÃ  logic parse
    member_keys = [
        # Current members (giá»‘ng RE)
        'Current members',
        'ThÃ nh viÃªn',
        'ThÃ nh viÃªn hiá»‡n táº¡i',
        'Members',
        # Past members (giá»‘ng RE)
        'Past members',
        'Cá»±u thÃ nh viÃªn',
        'Former members',
        # Bá»• sung thÃªm
        'ThÃ nh viÃªn cÅ©',
    ]

    for group_name, data in groups.items():
        info = data.get('infobox') or {}
        if not isinstance(info, dict):
            continue

        for key in member_keys:
            raw = info.get(key)
            if not raw:
                continue

            # Äá»’NG Bá»˜ HÃ“A Vá»šI RE: Parse giá»‘ng _parse_member_list()
            # TÃ¡ch theo dáº¥u pháº©y, dáº¥u *, dáº¥u â€¢ (giá»‘ng RE)
            parts = re.split(r'[,*â€¢]', raw)
            
            for part in parts:
                part = part.strip()
                if not part:
                    continue
                
                # Äá»’NG Bá»˜ HÃ“A Vá»šI RE: Loáº¡i bá» [1], [2], etc. vÃ  (notes) trÆ°á»›c khi parse
                part = re.sub(r'\[.*?\]', '', part)  # Loáº¡i bá» [1], [2], etc.
                part = re.sub(r'\(.*?\)', '', part)  # Loáº¡i bá» (notes)
                part = part.strip()
                
                if not part:
                    continue
                
                # Kiá»ƒm tra Ä‘á»™ dÃ i cÆ¡ báº£n (giá»‘ng RE)
                if len(part) < 2 or len(part) > 40:
                    continue
                
                # Kiá»ƒm tra báº¯t Ä‘áº§u báº±ng chá»¯ (giá»‘ng RE)
                if not re.match(r'^[A-Za-z\u3131-\u318E\u4E00-\u9FFF]', part):
                    continue
                
                # Äá»’NG Bá»˜ HÃ“A Vá»šI RE: Loáº¡i bá» cÃ¡c tá»« chung chung (khÃ´ng pháº£i tÃªn thÃ nh viÃªn)
                # Giá»‘ng RE: filter cÃ¡c tá»« nhÆ° "ThÃ nh viÃªn", "Danh sÃ¡ch", etc.
                GENERIC_TERMS = {
                    'thÃ nh viÃªn', 'members', 'member', 'cá»±u thÃ nh viÃªn', 'former members',
                    'past members', 'current members', 'thÃ nh viÃªn hiá»‡n táº¡i', 'thÃ nh viÃªn cÅ©',
                    'danh sÃ¡ch', 'danh sÃ¡ch thÃ nh viÃªn', 'danh sÃ¡ch cá»±u thÃ nh viÃªn',
                    'list', 'list of members', 'list of former members',
                    'current', 'former', 'past', 'cá»±u'
                }
                part_lower = part.lower()
                if part_lower in GENERIC_TERMS:
                    continue
                # Loáº¡i bá» náº¿u chá»©a cá»¥m tá»« chung chung (chá»‰ check cÃ¡c tá»« dÃ i hÆ¡n 3 kÃ½ tá»±)
                if any(term in part_lower for term in GENERIC_TERMS if len(term) > 3):
                    continue
                
                # Äá»’NG Bá»˜ HÃ“A Vá»šI RE: KHÃ”NG dÃ¹ng clean_text() vÃ¬ RE khÃ´ng dÃ¹ng
                # RE tráº£ vá» part trá»±c tiáº¿p, NER cÅ©ng pháº£i giá»¯ tÃªn gá»‘c nhÆ° váº­y
                # CHá»ˆ dÃ¹ng normalize_for_comparison Ä‘á»ƒ check trÃ¹ng láº·p (khÃ´ng thay Ä‘á»•i tÃªn gá»‘c)
                member = part  # Giá»¯ tÃªn gá»‘c nhÆ° RE
                if not member:
                    continue

                # ============================================
                # CHá»ˆ CHECK TRÃ™NG Láº¶P (KHÃ”NG CÃ“ Bá»˜ Lá»ŒC KHÃC)
                # ============================================
                # Giá»‘ng RE: Ä‘Ã£ filter tá»« chung chung á»Ÿ trÃªn, chá»‰ check trÃ¹ng láº·p
                # VÃ¬ Ä‘Ã£ Ä‘Æ°á»£c verify tá»« infobox Wikipedia
                
                # QUAN TRá»ŒNG: DÃ¹ng CÃ™NG cÃ¡ch chuáº©n hÃ³a nhÆ° khi táº¡o existing_lower
                # DÃ¹ng normalize_for_comparison Ä‘á»ƒ Ä‘áº£m báº£o cÃ¹ng cÃ¡ch chuáº©n hÃ³a vá»›i merge_and_import_neo4j.py
                member_key = normalize_for_comparison(member)
                
                # Check trÃ¹ng vá»›i node gá»‘c (cÃ¹ng tÃªn VÃ€ cÃ¹ng type Artist)
                if member_key in existing_lower and 'Artist' in existing_lower[member_key]:
                    continue
                
                # Check trÃ¹ng trong danh sÃ¡ch infobox Ä‘Ã£ thÃªm
                if member_key in seen:
                    continue

                # ThÃªm vÃ o seen vÃ  entities
                seen.add(member_key)
                entities.append({
                    'text': member,
                    'type': 'Artist',
                    'method': 'infobox_members',
                    'confidence': 0.9,
                    'source_node': group_name,
                })

    return entities


def extract_known_companies(text):
    """TrÃ­ch xuáº¥t cÃ´ng ty Ä‘Ã£ biáº¿t"""
    entities = []
    text_lower = text.lower()
    for company in KNOWN_COMPANIES:
        # CHUáº¨N HÃ“A company name trÆ°á»›c khi check
        # DÃ¹ng normalize_for_comparison Ä‘á»ƒ Ä‘áº£m báº£o cÃ¹ng cÃ¡ch chuáº©n hÃ³a vá»›i merge_and_import_neo4j.py
        company_key = normalize_for_comparison(company)
        # QUAN TRá»ŒNG: Chá»‰ thÃªm náº¿u chÆ°a cÃ³ trong graph (cÃ¹ng tÃªn VÃ€ cÃ¹ng type Company)
        if company.lower() in text_lower and not (company_key in existing_lower and 'Company' in existing_lower[company_key]):
            entities.append({
                'text': company,
                'type': 'Company',
                'method': 'known_list',
                'confidence': 0.95
            })
    return entities

# =====================================================
# Xá»¬ LÃ CHÃNH
# =====================================================
print("\nğŸ“Š BÆ°á»›c 1: Nháº­n dáº¡ng thá»±c thá»ƒ...")
all_entities = []  # Rule-based entities
ml_all_entities = []  # ML-based entities (riÃªng biá»‡t)

# TrÃ­ch xuáº¥t Artist má»›i tá»« infobox members cá»§a Group gá»‘c (náº¿u cÃ³ file)
infobox_artists = extract_artists_from_infobox_groups()
if infobox_artists:
    print(f"  âœ“ TrÃ­ch xuáº¥t {len(infobox_artists)} artist tá»« infobox members (file infobox_members.json)")
    all_entities.extend(infobox_artists)

for i, record in enumerate(records, 1):
    if i % 200 == 0:
        print(f"  ÄÃ£ xá»­ lÃ½: {i}/{len(records)} records...")
    
    text = record.get('text', '')
    node_id = record.get('node_id', '')
    
    # TrÃ­ch xuáº¥t theo tá»«ng loáº¡i (RULE-BASED)
    for entity_type, pattern_list in patterns.items():
        found = extract_entities(text, entity_type, pattern_list)
        for ent in found:
            ent['source_node'] = node_id
            all_entities.append(ent)
    
    # CÃ´ng ty Ä‘Ã£ biáº¿t
    for ent in extract_known_companies(text):
        ent['source_node'] = node_id
        all_entities.append(ent)
    
    # TrÃ­ch xuáº¥t cÃ´ng ty tá»« cÃ¡c cÃ¢u liá»‡t kÃª
    for ent in extract_companies_from_list(text):
        ent['source_node'] = node_id
        all_entities.append(ent)
    
    # TrÃ­ch xuáº¥t thÃ nh viÃªn tá»« danh sÃ¡ch liá»‡t kÃª
    for ent in extract_members_from_list(text):
        ent['source_node'] = node_id
        all_entities.append(ent)
    
    # TrÃ­ch xuáº¥t nhÃ³m nháº¡c tá»« cÃ¡c cÃ¢u liá»‡t kÃª nhÃ³m
    for ent in extract_groups_from_list(text):
        ent['source_node'] = node_id
        all_entities.append(ent)
    
    # TrÃ­ch xuáº¥t báº±ng ML model (ML-BASED) - LÆ¯U RIÃŠNG
    if ML_NER_AVAILABLE:
        try:
            ml_entities = extract_ml_entities(text, node_id)
            if ml_entities:
                for ent in ml_entities:
                    # ÃP Dá»¤NG is_valid_entity CHO ML ENTITIES (giá»‘ng rule-based)
                    entity_text = ent.get('text', '')
                    entity_type = ent.get('type', '')
                    if not is_valid_entity(entity_text, entity_type):
                        # Bá» qua entity khÃ´ng há»£p lá»‡
                        continue
                    
                    # CHECK TRÃ™NG Vá»šI GRAPH Gá»C (giá»‘ng rule-based)
                    # DÃ¹ng normalize_for_comparison Ä‘á»ƒ Ä‘áº£m báº£o cÃ¹ng cÃ¡ch chuáº©n hÃ³a vá»›i merge_and_import_neo4j.py
                    entity_key = normalize_for_comparison(entity_text)
                    # QUAN TRá»ŒNG: Chá»‰ loáº¡i bá» náº¿u cÃ¹ng tÃªn VÃ€ cÃ¹ng type
                    if entity_key in existing_lower and entity_type in existing_lower[entity_key]:
                        # Entity Ä‘Ã£ tá»“n táº¡i trong graph gá»‘c (cÃ¹ng tÃªn vÃ  type) -> bá» qua
                        continue
                    
                    # KHÃ”NG CHECK TRÃ™NG Vá»šI RULE-BASED (sáº½ lÆ°u riÃªng)
                    ml_all_entities.append(ent)
        except Exception as e:
            # Chá»‰ in lá»—i náº¿u debug (Ä‘á»ƒ trÃ¡nh spam)
            # Náº¿u cÃ³ lá»—i, bá» qua vÃ  tiáº¿p tá»¥c vá»›i rule-based
            if i <= 5:  # Chá»‰ in lá»—i cho 5 records Ä‘áº§u Ä‘á»ƒ debug
                print(f"  âš ï¸  Lá»—i ML NER á»Ÿ record {i}: {type(e).__name__}")
            pass

rule_based_count = len(all_entities)
print(f"  âœ“ Nháº­n dáº¡ng Ä‘Æ°á»£c {rule_based_count} entities thÃ´ (rule-based)")
if ML_NER_AVAILABLE:
    ml_count = len(ml_all_entities)
    print(f"  âœ“ Nháº­n dáº¡ng Ä‘Æ°á»£c {ml_count} entities thÃ´ (ML-based)")

# =====================================================
# Gá»˜P VÃ€ LOáº I Bá» TRÃ™NG Láº¶P (RULE-BASED)
# =====================================================
print("\nğŸ“Š BÆ°á»›c 2a: Gá»™p vÃ  loáº¡i bá» trÃ¹ng láº·p (Rule-based)...")
unique_rule = {}

for ent in all_entities:
    # QUAN TRá»ŒNG: Entities tá»« infobox KHÃ”NG Ä‘Æ°á»£c clean_text() vÃ¬ pháº£i giá»¯ tÃªn gá»‘c nhÆ° RE
    # Chá»‰ clean_text() cho cÃ¡c entities tá»« rule-based (text extraction)
    if ent.get('method') == 'infobox_members':
        # Giá»¯ nguyÃªn tÃªn gá»‘c, khÃ´ng clean_text()
        normalized_text = ent['text']
    else:
        # Chuáº©n hÃ³a text Ä‘á»ƒ trÃ¡nh trÃ¹ng do khÃ¡c khoáº£ng tráº¯ng / hoa thÆ°á»ng
        normalized_text = clean_text(ent['text'])
    
    ent['text'] = normalized_text
    
    # Táº¡o key Ä‘á»ƒ gá»™p: DÃ¹ng normalize_for_comparison() Ä‘á»ƒ match cÃ¡c biáº¿n thá»ƒ
    # (vÃ­ dá»¥: "Kwon Jung-yeol" vs "Kwon Jung yeol" -> cÃ¹ng má»™t node)
    # QUAN TRá»ŒNG: DÃ¹ng cÃ¹ng cÃ¡ch normalize nhÆ° khi check vá»›i existing_lower
    merge_key = normalize_for_comparison(normalized_text)
    key = (merge_key, ent['type'])
    
    if key not in unique_rule:
        unique_rule[key] = {**ent, 'sources': [ent.get('source_node', '')]}
    else:
        # Æ¯U TIÃŠN NODE Tá»ª INFOBOX: Náº¿u trÃ¹ng, giá»¯ node tá»« infobox, loáº¡i node cÃ²n láº¡i
        existing = unique_rule[key]
        existing_is_infobox = existing.get('method') == 'infobox_members'
        new_is_infobox = ent.get('method') == 'infobox_members'
        
        if new_is_infobox and not existing_is_infobox:
            # Node má»›i tá»« infobox, node existing khÃ´ng pháº£i -> thay tháº¿
            unique_rule[key] = {**ent, 'sources': [ent.get('source_node', '')]}
        elif existing_is_infobox and not new_is_infobox:
            # Node existing tá»« infobox, node má»›i khÃ´ng pháº£i -> bá» qua node má»›i (giá»¯ existing)
            continue
        else:
            # Cáº£ hai Ä‘á»u tá»« infobox hoáº·c cáº£ hai Ä‘á»u khÃ´ng -> merge nhÆ° bÃ¬nh thÆ°á»ng
            source_node = ent.get('source_node', '')
            if source_node and source_node not in existing.get('sources', []):
                existing['sources'].append(source_node)
            # Giá»¯ confidence cao nháº¥t
            existing['confidence'] = max(existing.get('confidence', 0), ent.get('confidence', 0))

merged_rule_entities = list(unique_rule.values())
print(f"  âœ“ CÃ²n {len(merged_rule_entities)} entities (rule-based) sau khi gá»™p")

# =====================================================
# Gá»˜P VÃ€ LOáº I Bá» TRÃ™NG Láº¶P (ML-BASED)
# =====================================================
merged_ml_entities = []
if ML_NER_AVAILABLE and ml_all_entities:
    print("\nğŸ“Š BÆ°á»›c 2b: Gá»™p vÃ  loáº¡i bá» trÃ¹ng láº·p (ML-based)...")
    unique_ml = {}
    
    for ent in ml_all_entities:
        # Chuáº©n hÃ³a text Ä‘á»ƒ trÃ¡nh trÃ¹ng do khÃ¡c khoáº£ng tráº¯ng / hoa thÆ°á»ng
        normalized_text = clean_text(ent['text'])
        ent['text'] = normalized_text
        
        # Táº¡o key Ä‘á»ƒ gá»™p: DÃ¹ng normalize_for_comparison() Ä‘á»ƒ match cÃ¡c biáº¿n thá»ƒ
        # QUAN TRá»ŒNG: DÃ¹ng cÃ¹ng cÃ¡ch normalize nhÆ° khi check vá»›i existing_lower
        merge_key = normalize_for_comparison(normalized_text)
        key = (merge_key, ent['type'])
        
        if key not in unique_ml:
            unique_ml[key] = {**ent, 'sources': [ent.get('source_node', '')]}
        else:
            # Gá»™p sources - chá»‰ merge náº¿u text hoÃ n toÃ n giá»‘ng nhau (sau normalize)
            existing = unique_ml[key]
            source_node = ent.get('source_node', '')
            if source_node and source_node not in existing.get('sources', []):
                existing['sources'].append(source_node)
            # Giá»¯ confidence cao nháº¥t
            existing['confidence'] = max(existing.get('confidence', 0), ent.get('confidence', 0))
    
    merged_ml_entities = list(unique_ml.values())
    print(f"  âœ“ CÃ²n {len(merged_ml_entities)} entities (ML-based) sau khi gá»™p")

# =====================================================
# HÃ€M FIX TYPE SAI
# =====================================================
def fix_entity_type(entity_text, entity_type, sources):
    """
    Sá»­a type sai cho entity.
    VÃ­ dá»¥: "Lee Su ji" bá»‹ nháº§m lÃ  Group nhÆ°ng thá»±c ra lÃ  Artist.
    """
    text_lower = entity_text.lower().strip()
    
    # ============================================
    # FIX: TÃŠN NGÆ¯á»œI Bá»Š NHáº¦M LÃ€ GROUP
    # ============================================
    if entity_type == 'Group':
        # Pattern tÃªn ngÆ°á»i HÃ n Quá»‘c: "Há» TÃªn" (2-3 tá»«, báº¯t Ä‘áº§u báº±ng há» HÃ n)
        korean_surnames_lower = {s.lower() for s in KOREAN_SURNAMES}
        words = entity_text.split()
        
        # Náº¿u cÃ³ 2-3 tá»« vÃ  tá»« Ä‘áº§u lÃ  há» HÃ n Quá»‘c -> cÃ³ thá»ƒ lÃ  tÃªn ngÆ°á»i
        if 2 <= len(words) <= 3:
            first_word = words[0].strip()
            if first_word.lower() in korean_surnames_lower:
                # Kiá»ƒm tra context: náº¿u cÃ³ tá»« khÃ³a nghá»‡ sÄ©/ca sÄ© -> chuyá»ƒn thÃ nh Artist
                for source in sources:
                    full_text = node_texts.get(source, '')
                    if full_text:
                        # TÃ¬m vá»‹ trÃ­ entity trong text
                        idx = full_text.find(text_lower)
                        if idx != -1:
                            # Láº¥y context xung quanh (200 kÃ½ tá»±)
                            start = max(0, idx - 100)
                            end = min(len(full_text), idx + len(entity_text) + 100)
                            context = full_text[start:end].lower()
                            
                            # Náº¿u cÃ³ tá»« khÃ³a nghá»‡ sÄ©/ca sÄ©/thÃ nh viÃªn -> lÃ  Artist
                            artist_keywords = ['ca sÄ©', 'nghá»‡ sÄ©', 'thÃ nh viÃªn', 'singer', 'artist', 'member', 'idol']
                            if any(kw in context for kw in artist_keywords):
                                return 'Artist'
                            
                            # Náº¿u cÃ³ tá»« khÃ³a nhÃ³m nháº¡c/group -> giá»¯ Group
                            group_keywords = ['nhÃ³m nháº¡c', 'ban nháº¡c', 'group', 'band']
                            if any(kw in context for kw in group_keywords):
                                return 'Group'
        
        # Danh sÃ¡ch tÃªn ngÆ°á»i Ä‘Ã£ biáº¿t bá»‹ nháº§m lÃ  Group
        known_artist_names = {
            'lee su ji', 'lee su-ji', 'leesuji',  # VÃ­ dá»¥ tá»« user
            # CÃ³ thá»ƒ thÃªm cÃ¡c tÃªn khÃ¡c náº¿u phÃ¡t hiá»‡n
        }
        if text_lower in known_artist_names:
            return 'Artist'
    
    return entity_type

# =====================================================
# Lá»ŒC THEO CONTEXT K-POP VÃ€ PHÃ™ Há»¢P Vá»šI Máº NG LÆ¯á»šI (RULE-BASED)
# =====================================================
print("\nğŸ“Š BÆ°á»›c 3a: Lá»c theo context K-pop vÃ  phÃ¹ há»£p máº¡ng lÆ°á»›i (Rule-based)...")
filtered_rule_entities = []
removed_count_rule = defaultdict(int)
removed_reason_rule = defaultdict(lambda: defaultdict(int))
fixed_type_count = defaultdict(int)

for ent in merged_rule_entities:
    sources = ent.get('sources', [ent.get('source_node', '')])
    entity_type = ent['type']
    entity_text = ent['text']
    
    # ============================================
    # FIX TYPE SAI TRÆ¯á»šC KHI FILTER
    # ============================================
    original_type = entity_type
    entity_type = fix_entity_type(entity_text, entity_type, sources)
    if entity_type != original_type:
        ent['type'] = entity_type
        fixed_type_count[f"{original_type}->{entity_type}"] += 1
        print(f"   ğŸ”§ Fixed type: '{entity_text}' {original_type} -> {entity_type}")
    
    # Safety filter bá»• sung cho Group Ä‘á»ƒ loáº¡i bá» cÃ¡c máº£nh tÃªn sai cÃ²n sÃ³t nhÆ° "Indie OKDAL Y"
    if entity_type == 'Group':
        low = entity_text.lower()
        if any(kw in low for kw in ['indie okdal', 'f ve', 'girl next door', 'girl next']):
            removed_count_rule[entity_type] += 1
            removed_reason_rule[entity_type]['post_filter_bad_group'] += 1
            continue
        
        # Cáº£i thiá»‡n: Validation vá»›i danh sÃ¡ch nhÃ³m K-pop Ä‘Ã£ biáº¿t
        # Náº¿u khÃ´ng cÃ³ trong danh sÃ¡ch nhÃ³m Ä‘Ã£ biáº¿t vÃ  khÃ´ng cÃ³ trong graph -> cáº§n kiá»ƒm tra ká»¹ hÆ¡n
        entity_normalized = normalize_for_comparison(entity_text)
        is_known_group = (
            low in KNOWN_KPOP_GROUPS or
            entity_normalized in existing_lower and 'Group' in existing_lower.get(entity_normalized, set())
        )
        
        # Náº¿u khÃ´ng pháº£i nhÃ³m Ä‘Ã£ biáº¿t vÃ  khÃ´ng cÃ³ trong graph -> giáº£m confidence
        if not is_known_group:
            # Kiá»ƒm tra xem cÃ³ pháº£i nhÃ³m tháº­t khÃ´ng báº±ng cÃ¡ch xem context
            # Náº¿u cÃ³ tá»« khÃ³a "nhÃ³m nháº¡c", "group", "band" trong context -> cÃ³ thá»ƒ lÃ  nhÃ³m tháº­t
            has_group_context = False
            for source in sources:
                full_text = node_texts.get(source, '')
                if full_text:
                    full_text_lower = full_text.lower()
                    group_keywords = ['nhÃ³m nháº¡c', 'ban nháº¡c', 'group', 'band', 'idol group']
                    if any(kw in full_text_lower for kw in group_keywords):
                        has_group_context = True
                        break
            
            # Náº¿u khÃ´ng cÃ³ context vá» nhÃ³m -> giáº£m confidence Ä‘Ã¡ng ká»ƒ
            if not has_group_context:
                ent['confidence'] = max(0.5, ent.get('confidence', 0.7) - 0.2)
    
    # Known list (cÃ´ng ty Ä‘Ã£ biáº¿t) -> luÃ´n giá»¯
    if ent.get('method') == 'known_list':
        filtered_rule_entities.append(ent)
        continue
    
    # QUAN TRá»ŒNG: Artists tá»« infobox -> luÃ´n giá»¯ (vÃ¬ Ä‘Ã£ Ä‘Æ°á»£c verify tá»« infobox cá»§a group)
    # KhÃ´ng cáº§n check context vÃ¬ há» lÃ  thÃ nh viÃªn cá»§a group Ä‘Ã£ cÃ³ trong graph
    if ent.get('method') == 'infobox_members':
        # Kiá»ƒm tra xem source_node (group name) cÃ³ trong graph khÃ´ng
        source_node = ent.get('source_node', '')
        if source_node:
            # Náº¿u group cÃ³ trong graph -> artist há»£p lá»‡
            # DÃ¹ng normalize_for_comparison Ä‘á»ƒ Ä‘áº£m báº£o cÃ¹ng cÃ¡ch chuáº©n hÃ³a vá»›i merge_and_import_neo4j.py
            source_normalized = normalize_for_comparison(source_node)
            # existing_lower lÃ  Dict[str, Set[str]] - check xem cÃ³ Group type khÃ´ng
            if source_normalized in existing_lower and 'Group' in existing_lower[source_normalized]:
                filtered_rule_entities.append(ent)
                continue
            # Hoáº·c náº¿u group cÃ³ trong danh sÃ¡ch groups tá»« infobox -> cÅ©ng há»£p lá»‡
            groups_infobox = INFOBOX_MEMBERS.get('groups', {})
            if source_node in groups_infobox or any(g.lower() == source_node.lower() for g in groups_infobox.keys()):
                filtered_rule_entities.append(ent)
                continue
        
        # Náº¿u khÃ´ng cÃ³ source_node, váº«n giá»¯ (cÃ³ thá»ƒ lÃ  tá»« infobox nhÆ°ng khÃ´ng cÃ³ group name)
        # VÃ¬ Ä‘Ã£ Ä‘Æ°á»£c verify tá»« infobox nÃªn Ä‘Ã¡ng tin cáº­y
        filtered_rule_entities.append(ent)
        continue
    
    # Kiá»ƒm tra 1: Pháº£i cÃ³ context K-pop
    if not has_kpop_context(sources):
        removed_count_rule[entity_type] += 1
        removed_reason_rule[entity_type]['no_kpop_context'] += 1
        continue
    
    # Kiá»ƒm tra 2a: Náº¿u entity Ä‘Æ°á»£c nháº­n dáº¡ng lÃ  Artist nhÆ°ng cÃ³ "album thÃ nh viÃªn" trong context -> loáº¡i bá» (vÃ¬ lÃ  album)
    if entity_type == 'Artist':
        is_album_context = False
        for source in sources:
            full_text = node_texts.get(source, '')
            if full_text and ('album thÃ nh viÃªn' in full_text or 'album cá»§a thÃ nh viÃªn' in full_text):
                entity_lower = entity_text.lower()
                idx = full_text.find(entity_lower)
                if idx != -1:
                    start = max(0, idx - 50)
                    end = min(len(full_text), idx + len(entity_text) + 50)
                    context = full_text[start:end]
                    if 'album' in context and 'thÃ nh viÃªn' in context:
                        is_album_context = True
                        break
        if is_album_context:
            removed_count_rule[entity_type] += 1
            removed_reason_rule[entity_type]['is_album_not_artist'] += 1
            continue
    
    # Kiá»ƒm tra 2b: Artist pháº£i lÃ  nghá»‡ sÄ© Ã¢m nháº¡c (khÃ´ng pháº£i diá»…n viÃªn, MC...)
    if entity_type == 'Artist':
        if not is_music_artist(entity_text, sources):
            removed_count_rule[entity_type] += 1
            removed_reason_rule[entity_type]['not_music_artist'] += 1
            continue
    
    # Kiá»ƒm tra 3: Pháº£i liÃªn quan Ä‘áº¿n máº¡ng lÆ°á»›i hiá»‡n cÃ³
    if not is_related_to_existing_nodes(entity_text, sources, existing_lower):
        removed_count_rule[entity_type] += 1
        removed_reason_rule[entity_type]['not_related_to_network'] += 1
        continue
    
    # Cáº£i thiá»‡n: TÃ­nh confidence dá»±a trÃªn nhiá»u yáº¿u tá»‘
    num_sources = len(set(sources))
    base_confidence = ent.get('confidence', 0.7)
    
    # Boost tá»« sá»‘ nguá»“n
    if num_sources >= 5:
        base_confidence = min(0.95, base_confidence + 0.2)
    elif num_sources >= 3:
        base_confidence = min(0.9, base_confidence + 0.15)
    elif num_sources >= 2:
        base_confidence = min(0.85, base_confidence + 0.1)
    
    # Boost tá»« viá»‡c cÃ³ trong danh sÃ¡ch Ä‘Ã£ biáº¿t
    entity_normalized = normalize_for_comparison(entity_text)
    if entity_type == 'Group' and entity_text.lower() in KNOWN_KPOP_GROUPS:
        base_confidence = min(0.95, base_confidence + 0.1)
    elif entity_type == 'Company' and entity_text in KNOWN_COMPANIES:
        base_confidence = min(0.95, base_confidence + 0.1)
    elif entity_type == 'Artist':
        # Kiá»ƒm tra cÃ³ trong graph khÃ´ng
        if entity_normalized in existing_lower and 'Artist' in existing_lower.get(entity_normalized, set()):
            base_confidence = min(0.9, base_confidence + 0.1)
    
    # Boost tá»« context quality (sá»‘ tá»« khÃ³a K-pop)
    kpop_score = 0
    for source in sources:
        text = node_texts.get(source, '')
        if text:
            text_lower = text.lower()
            kpop_score += sum(1 for kw in KPOP_KEYWORDS if kw.lower() in text_lower)
    
    if kpop_score >= 5:
        base_confidence = min(0.95, base_confidence + 0.05)
    elif kpop_score >= 3:
        base_confidence = min(0.9, base_confidence + 0.03)
    
    ent['confidence'] = base_confidence
    filtered_rule_entities.append(ent)

# =====================================================
# Lá»ŒC THEO CONTEXT K-POP VÃ€ PHÃ™ Há»¢P Vá»šI Máº NG LÆ¯á»šI (ML-BASED)
# =====================================================
filtered_ml_entities = []
removed_count_ml = defaultdict(int)
removed_reason_ml = defaultdict(lambda: defaultdict(int))
fixed_type_count_ml = defaultdict(int)

if ML_NER_AVAILABLE and merged_ml_entities:
    print("\nğŸ“Š BÆ°á»›c 3b: Lá»c theo context K-pop vÃ  phÃ¹ há»£p máº¡ng lÆ°á»›i (ML-based)...")
    
    for ent in merged_ml_entities:
        sources = ent.get('sources', [ent.get('source_node', '')])
        entity_type = ent['type']
        entity_text = ent['text']
        
        # ============================================
        # FIX TYPE SAI TRÆ¯á»šC KHI FILTER (giá»‘ng rule-based)
        # ============================================
        original_type = entity_type
        entity_type = fix_entity_type(entity_text, entity_type, sources)
        if entity_type != original_type:
            ent['type'] = entity_type
            fixed_type_count_ml[f"{original_type}->{entity_type}"] += 1
            print(f"   ğŸ”§ Fixed type (ML): '{entity_text}' {original_type} -> {entity_type}")
        
        # Kiá»ƒm tra 1: Pháº£i cÃ³ context K-pop
        if not has_kpop_context(sources):
            removed_count_ml[entity_type] += 1
            removed_reason_ml[entity_type]['no_kpop_context'] += 1
            continue
        
        # Kiá»ƒm tra 2: Artist pháº£i lÃ  nghá»‡ sÄ© Ã¢m nháº¡c
        if entity_type == 'Artist':
            if not is_music_artist(entity_text, sources):
                removed_count_ml[entity_type] += 1
                removed_reason_ml[entity_type]['not_music_artist'] += 1
                continue
        
        # Kiá»ƒm tra 3: Pháº£i liÃªn quan Ä‘áº¿n máº¡ng lÆ°á»›i hiá»‡n cÃ³
        if not is_related_to_existing_nodes(entity_text, sources, existing_lower):
            removed_count_ml[entity_type] += 1
            removed_reason_ml[entity_type]['not_related_to_network'] += 1
            continue
        
        # Kiá»ƒm tra 4: Loáº¡i bá» entities cÃ³ confidence quÃ¡ tháº¥p (< 0.65)
        if ent.get('confidence', 0) < 0.65:
            removed_count_ml[entity_type] += 1
            removed_reason_ml[entity_type]['ml_low_confidence'] += 1
            continue
        
        # Cáº£i thiá»‡n: TÃ­nh confidence dá»±a trÃªn nhiá»u yáº¿u tá»‘ (giá»‘ng rule-based)
        num_sources = len(set(sources))
        base_confidence = ent.get('confidence', 0.65)
        
        # Boost tá»« sá»‘ nguá»“n
        if num_sources >= 5:
            base_confidence = min(0.95, base_confidence + 0.2)
        elif num_sources >= 3:
            base_confidence = min(0.9, base_confidence + 0.15)
        elif num_sources >= 2:
            base_confidence = min(0.85, base_confidence + 0.1)
        
        # Boost tá»« viá»‡c cÃ³ trong danh sÃ¡ch Ä‘Ã£ biáº¿t
        entity_normalized = normalize_for_comparison(entity_text)
        if entity_type == 'Group' and entity_text.lower() in KNOWN_KPOP_GROUPS:
            base_confidence = min(0.95, base_confidence + 0.1)
        elif entity_type == 'Company' and entity_text in KNOWN_COMPANIES:
            base_confidence = min(0.95, base_confidence + 0.1)
        elif entity_type == 'Artist':
            # Kiá»ƒm tra cÃ³ trong graph khÃ´ng
            if entity_normalized in existing_lower and 'Artist' in existing_lower.get(entity_normalized, set()):
                base_confidence = min(0.9, base_confidence + 0.1)
        
        # Boost tá»« context quality (sá»‘ tá»« khÃ³a K-pop)
        kpop_score = 0
        for source in sources:
            text = node_texts.get(source, '')
            if text:
                text_lower = text.lower()
                kpop_score += sum(1 for kw in KPOP_KEYWORDS if kw.lower() in text_lower)
        
        if kpop_score >= 5:
            base_confidence = min(0.95, base_confidence + 0.05)
        elif kpop_score >= 3:
            base_confidence = min(0.9, base_confidence + 0.03)
        
        ent['confidence'] = base_confidence
        filtered_ml_entities.append(ent)

# =====================================================
# BÆ¯á»šC 4: CHUáº¨N HÃ“A & Gá»˜P Láº I Láº¦N CUá»I (RULE-BASED)
# =====================================================
final_unique_rule = {}
for ent in filtered_rule_entities:
    # QUAN TRá»ŒNG: Entities tá»« infobox KHÃ”NG Ä‘Æ°á»£c clean_text() vÃ¬ pháº£i giá»¯ tÃªn gá»‘c nhÆ° RE
    if ent.get('method') == 'infobox_members':
        norm_text = ent['text']  # Giá»¯ nguyÃªn tÃªn gá»‘c
    else:
        norm_text = clean_text(ent['text'])
    ent['text'] = norm_text
    
    # DÃ¹ng normalize_for_comparison() Ä‘á»ƒ match cÃ¡c biáº¿n thá»ƒ
    merge_key = normalize_for_comparison(norm_text)
    key = (merge_key, ent['type'])
    
    if key not in final_unique_rule:
        final_unique_rule[key] = {**ent}
    else:
        # Æ¯U TIÃŠN NODE Tá»ª INFOBOX: Náº¿u trÃ¹ng, giá»¯ node tá»« infobox, loáº¡i node cÃ²n láº¡i
        existing = final_unique_rule[key]
        existing_is_infobox = existing.get('method') == 'infobox_members'
        new_is_infobox = ent.get('method') == 'infobox_members'
        
        if new_is_infobox and not existing_is_infobox:
            # Node má»›i tá»« infobox, node existing khÃ´ng pháº£i -> thay tháº¿
            final_unique_rule[key] = {**ent}
        elif existing_is_infobox and not new_is_infobox:
            # Node existing tá»« infobox, node má»›i khÃ´ng pháº£i -> bá» qua node má»›i (giá»¯ existing)
            continue
        else:
            # Cáº£ hai Ä‘á»u tá»« infobox hoáº·c cáº£ hai Ä‘á»u khÃ´ng -> merge nhÆ° bÃ¬nh thÆ°á»ng
            existing_sources = set(existing.get('sources', []))
            new_sources = set(ent.get('sources', []))
            existing['sources'] = list(existing_sources | new_sources)
            existing['confidence'] = max(existing.get('confidence', 0), ent.get('confidence', 0))

filtered_rule_entities = list(final_unique_rule.values())
print(f"  âœ“ CÃ²n {len(filtered_rule_entities)} entities (rule-based) sau khi lá»c")

# =====================================================
# BÆ¯á»šC 4: CHUáº¨N HÃ“A & Gá»˜P Láº I Láº¦N CUá»I (ML-BASED)
# =====================================================
final_unique_ml = {}
for ent in filtered_ml_entities:
    norm_text = clean_text(ent['text'])
    ent['text'] = norm_text
    
    # DÃ¹ng normalize_for_comparison() Ä‘á»ƒ match cÃ¡c biáº¿n thá»ƒ
    merge_key = normalize_for_comparison(norm_text)
    key = (merge_key, ent['type'])
    
    if key not in final_unique_ml:
        final_unique_ml[key] = {**ent}
    else:
        existing = final_unique_ml[key]
        existing_sources = set(existing.get('sources', []))
        new_sources = set(ent.get('sources', []))
        existing['sources'] = list(existing_sources | new_sources)
        existing['confidence'] = max(existing.get('confidence', 0), ent.get('confidence', 0))

filtered_ml_entities = list(final_unique_ml.values())
if ML_NER_AVAILABLE:
    print(f"  âœ“ CÃ²n {len(filtered_ml_entities)} entities (ML-based) sau khi lá»c")

# =====================================================
# BÆ¯á»šC 5: Lá»šP Lá»ŒC CUá»I CÃ™NG Báº°NG SLM (SMALL LANGUAGE MODEL)
# =====================================================
print("\nğŸ¤– BÆ°á»›c 5: Lá»c cuá»‘i cÃ¹ng báº±ng Small Language Model (SLM)...")

# Import SLM náº¿u cÃ³
SLM_AVAILABLE = False
slm_validator = None
try:
    from chatbot.small_llm import get_llm
    try:
        slm_validator = get_llm("qwen2-0.5b")
        SLM_AVAILABLE = True
        print("  âœ… SLM Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ validation")
    except Exception as e:
        print(f"  âš ï¸  KhÃ´ng thá»ƒ load SLM: {e}")
        print("  âš ï¸  Bá» qua lá»›p lá»c SLM, chá»‰ dÃ¹ng rule-based filtering")
        SLM_AVAILABLE = False
except ImportError:
    print("  âš ï¸  Module small_llm khÃ´ng kháº£ dá»¥ng. Bá» qua lá»›p lá»c SLM.")
    SLM_AVAILABLE = False

def validate_entity_with_slm(entity_text, entity_type, sources, slm):
    """
    Validate entity báº±ng Small Language Model
    
    Args:
        entity_text: TÃªn entity
        entity_type: Loáº¡i entity (Artist, Group, Company, Album, Song)
        sources: Danh sÃ¡ch source nodes
        slm: SmallLLM instance
    
    Returns:
        Tuple (is_valid, confidence_adjustment, reason)
    """
    if not slm:
        return True, 0.0, "SLM khÃ´ng kháº£ dá»¥ng"
    
    # Láº¥y context tá»« sources
    context_parts = []
    for source in sources[:3]:  # Chá»‰ láº¥y 3 sources Ä‘áº§u Ä‘á»ƒ trÃ¡nh context quÃ¡ dÃ i
        text = node_texts.get(source, '')
        if text:
            # Láº¥y Ä‘oáº¡n text xung quanh entity (200 kÃ½ tá»±)
            entity_lower = entity_text.lower()
            idx = text.lower().find(entity_lower)
            if idx != -1:
                start = max(0, idx - 100)
                end = min(len(text), idx + len(entity_text) + 100)
                context_parts.append(text[start:end])
            else:
                context_parts.append(text[:200])  # Láº¥y 200 kÃ½ tá»± Ä‘áº§u
    
    context = "\n".join(context_parts[:2])  # Chá»‰ láº¥y 2 Ä‘oáº¡n context Ä‘áº§u
    
    # Táº¡o prompt validation
    validation_prompt = f"""Báº¡n lÃ  chuyÃªn gia vá» K-pop (nháº¡c HÃ n Quá»‘c). HÃ£y Ä‘Ã¡nh giÃ¡ xem thá»±c thá»ƒ sau cÃ³ há»£p lá»‡ khÃ´ng.

THá»°C THá»‚ Cáº¦N KIá»‚M TRA:
- TÃªn: "{entity_text}"
- Loáº¡i: {entity_type}
- Context: {context[:500]}

YÃŠU Cáº¦U:
1. Náº¿u lÃ  {entity_type} trong K-pop (nháº¡c HÃ n Quá»‘c) -> tráº£ lá»i "VALID"
2. Náº¿u KHÃ”NG pháº£i {entity_type} trong K-pop (vÃ­ dá»¥: nghá»‡ sÄ© nÆ°á»›c ngoÃ i, chÆ°Æ¡ng trÃ¬nh TV, Ä‘á»‹a danh, cÃ¢u vÄƒn...) -> tráº£ lá»i "INVALID"
3. Náº¿u khÃ´ng cháº¯c cháº¯n -> tráº£ lá»i "UNCERTAIN"

Chá»‰ tráº£ lá»i má»™t tá»«: VALID, INVALID, hoáº·c UNCERTAIN."""

    try:
        response = slm.generate(
            validation_prompt,
            context="",
            max_new_tokens=20,
            temperature=0.1  # Low temperature Ä‘á»ƒ cÃ³ káº¿t quáº£ nháº¥t quÃ¡n
        )
        
        response_upper = response.strip().upper()
        
        if "VALID" in response_upper:
            return True, 0.05, "SLM xÃ¡c nháº­n há»£p lá»‡"  # TÄƒng confidence nháº¹
        elif "INVALID" in response_upper:
            return False, -0.2, "SLM xÃ¡c nháº­n khÃ´ng há»£p lá»‡"  # Giáº£m confidence Ä‘Ã¡ng ká»ƒ
        else:
            # UNCERTAIN hoáº·c khÃ´ng rÃµ rÃ ng
            return True, -0.05, "SLM khÃ´ng cháº¯c cháº¯n"  # Giáº£m confidence nháº¹
    except Exception as e:
        # Náº¿u SLM lá»—i, giá»¯ nguyÃªn entity (fallback)
        return True, 0.0, f"SLM error: {str(e)[:50]}"

# Ãp dá»¥ng SLM validation cho rule-based entities
if SLM_AVAILABLE and slm_validator:
    print("  ğŸ” Äang validate rule-based entities báº±ng SLM...")
    slm_validated_rule = []
    slm_removed_rule = 0
    slm_adjusted_rule = 0
    
    # Chá»‰ validate cÃ¡c entities cÃ³ confidence >= 0.7 (Ä‘á»ƒ tiáº¿t kiá»‡m thá»i gian)
    entities_to_validate = [e for e in filtered_rule_entities if e.get('confidence', 0) >= 0.7]
    print(f"    Validating {len(entities_to_validate)} entities (confidence >= 0.7)...")
    
    for i, ent in enumerate(entities_to_validate, 1):
        if i % 50 == 0:
            print(f"    ÄÃ£ validate: {i}/{len(entities_to_validate)}...")
        
        is_valid, conf_adj, reason = validate_entity_with_slm(
            ent['text'],
            ent['type'],
            ent.get('sources', [ent.get('source_node', '')]),
            slm_validator
        )
        
        if is_valid:
            # Äiá»u chá»‰nh confidence
            new_confidence = max(0.0, min(1.0, ent.get('confidence', 0.7) + conf_adj))
            ent['confidence'] = new_confidence
            if conf_adj != 0:
                slm_adjusted_rule += 1
            slm_validated_rule.append(ent)
        else:
            slm_removed_rule += 1
            if i <= 10:  # In 10 entities Ä‘áº§u bá»‹ loáº¡i
                print(f"      âŒ Removed: '{ent['text']}' ({ent['type']}) - {reason}")
    
    # Giá»¯ láº¡i cÃ¡c entities cÃ³ confidence < 0.7 (khÃ´ng validate báº±ng SLM)
    low_conf_entities = [e for e in filtered_rule_entities if e.get('confidence', 0) < 0.7]
    filtered_rule_entities = slm_validated_rule + low_conf_entities
    
    print(f"  âœ“ SLM validation: Giá»¯ {len(slm_validated_rule)} entities, loáº¡i {slm_removed_rule} entities")
    print(f"  âœ“ Äiá»u chá»‰nh confidence cho {slm_adjusted_rule} entities")
else:
    print("  âš ï¸  Bá» qua SLM validation (SLM khÃ´ng kháº£ dá»¥ng)")

# Ãp dá»¥ng SLM validation cho ML-based entities
if ML_NER_AVAILABLE and SLM_AVAILABLE and slm_validator:
    print("  ğŸ” Äang validate ML-based entities báº±ng SLM...")
    slm_validated_ml = []
    slm_removed_ml = 0
    slm_adjusted_ml = 0
    
    # Chá»‰ validate cÃ¡c entities cÃ³ confidence >= 0.7
    entities_to_validate_ml = [e for e in filtered_ml_entities if e.get('confidence', 0) >= 0.7]
    print(f"    Validating {len(entities_to_validate_ml)} entities (confidence >= 0.7)...")
    
    for i, ent in enumerate(entities_to_validate_ml, 1):
        if i % 50 == 0:
            print(f"    ÄÃ£ validate: {i}/{len(entities_to_validate_ml)}...")
        
        is_valid, conf_adj, reason = validate_entity_with_slm(
            ent['text'],
            ent['type'],
            ent.get('sources', [ent.get('source_node', '')]),
            slm_validator
        )
        
        if is_valid:
            new_confidence = max(0.0, min(1.0, ent.get('confidence', 0.65) + conf_adj))
            ent['confidence'] = new_confidence
            if conf_adj != 0:
                slm_adjusted_ml += 1
            slm_validated_ml.append(ent)
        else:
            slm_removed_ml += 1
            if i <= 10:
                print(f"      âŒ Removed: '{ent['text']}' ({ent['type']}) - {reason}")
    
    low_conf_entities_ml = [e for e in filtered_ml_entities if e.get('confidence', 0) < 0.7]
    filtered_ml_entities = slm_validated_ml + low_conf_entities_ml
    
    print(f"  âœ“ SLM validation: Giá»¯ {len(slm_validated_ml)} entities, loáº¡i {slm_removed_ml} entities")
    print(f"  âœ“ Äiá»u chá»‰nh confidence cho {slm_adjusted_ml} entities")

# Sáº¯p xáº¿p theo confidence giáº£m dáº§n (sau khi SLM validation)
filtered_rule_entities.sort(key=lambda x: (-x['confidence'], x['type'], x['text']))
if ML_NER_AVAILABLE:
    filtered_ml_entities.sort(key=lambda x: (-x['confidence'], x['type'], x['text']))

# Äáº¿m theo type
counts_rule = defaultdict(int)
for ent in filtered_rule_entities:
    counts_rule[ent['type']] += 1

counts_ml = defaultdict(int)
if ML_NER_AVAILABLE:
    for ent in filtered_ml_entities:
        counts_ml[ent['type']] += 1

# =====================================================
# LÆ¯U Káº¾T QUáº¢ (RULE-BASED)
# =====================================================
output_rule = {
    'metadata': {
        'description': 'Thá»±c thá»ƒ K-pop Ä‘Æ°á»£c nháº­n dáº¡ng vÃ  lá»c (Rule-based)',
        'processed_at': datetime.now().isoformat(),
        'total_records': len(records),
        'raw_entities': len(all_entities),
        'merged_entities': len(merged_rule_entities),
        'final_entities': len(filtered_rule_entities),
        'entities_by_type': dict(counts_rule),
        'filter_criteria': [
            'Pháº£i cÃ³ context K-pop (>=3 tá»« khÃ³a K-pop trong vÄƒn báº£n nguá»“n)',
            'Artist: Pháº£i cÃ³ tá»« khÃ³a vai trÃ² Ã¢m nháº¡c (ca sÄ©, rapper, thÃ nh viÃªn...)',
            'Artist: Loáº¡i trá»« diá»…n viÃªn, MC, váº­n Ä‘á»™ng viÃªn, nhÃ  vÄƒn...',
            'Pháº£i liÃªn quan Ä‘áº¿n Ã­t nháº¥t 1 node hiá»‡n cÃ³ trong máº¡ng lÆ°á»›i',
            'TÃªn pháº£i báº¯t Ä‘áº§u báº±ng chá»¯ in hoa hoáº·c sá»‘',
            'KhÃ´ng chá»©a tá»« chung chung'
        ]
    },
    'entities': filtered_rule_entities
}

with open('data/kpop_ner_result.json', 'w', encoding='utf-8') as f:
    json.dump(output_rule, f, ensure_ascii=False, indent=2)

# =====================================================
# LÆ¯U Káº¾T QUáº¢ (ML-BASED)
# =====================================================
if ML_NER_AVAILABLE:
    output_ml = {
        'metadata': {
            'description': 'Thá»±c thá»ƒ K-pop Ä‘Æ°á»£c nháº­n dáº¡ng vÃ  lá»c (ML-based)',
            'processed_at': datetime.now().isoformat(),
            'total_records': len(records),
            'raw_entities': len(ml_all_entities),
            'merged_entities': len(merged_ml_entities),
            'final_entities': len(filtered_ml_entities),
            'entities_by_type': dict(counts_ml),
            'ml_model': 'NlpHUST/ner-vietnamese-electra-base',
            'filter_criteria': [
                'Pháº£i cÃ³ context K-pop (>=3 tá»« khÃ³a K-pop trong vÄƒn báº£n nguá»“n)',
                'Artist: Pháº£i cÃ³ tá»« khÃ³a vai trÃ² Ã¢m nháº¡c (ca sÄ©, rapper, thÃ nh viÃªn...)',
                'Artist: Loáº¡i trá»« diá»…n viÃªn, MC, váº­n Ä‘á»™ng viÃªn, nhÃ  vÄƒn...',
                'Pháº£i liÃªn quan Ä‘áº¿n Ã­t nháº¥t 1 node hiá»‡n cÃ³ trong máº¡ng lÆ°á»›i',
                'Confidence >= 0.65',
                'TÃªn pháº£i báº¯t Ä‘áº§u báº±ng chá»¯ in hoa hoáº·c sá»‘',
                'KhÃ´ng chá»©a tá»« chung chung'
            ]
        },
        'entities': filtered_ml_entities
    }
    
    with open('data/kpop_ner_ml_result.json', 'w', encoding='utf-8') as f:
        json.dump(output_ml, f, ensure_ascii=False, indent=2)

# =====================================================
# IN Káº¾T QUáº¢
# =====================================================
print("\n" + "=" * 70)
print("Káº¾T QUáº¢ NHáº¬N Dáº NG THá»°C THá»‚ K-POP")
print("=" * 70)
print(f"âœ“ ÄÃ£ lÆ°u: kpop_ner_result.json (Rule-based)")
if ML_NER_AVAILABLE:
    print(f"âœ“ ÄÃ£ lÆ°u: kpop_ner_ml_result.json (ML-based)")

print(f"\nğŸ“Š THá»NG KÃŠ RULE-BASED:")
print(f"   Records xá»­ lÃ½: {len(records)}")
print(f"   Entities thÃ´: {len(all_entities)}")
print(f"   Sau khi gá»™p: {len(merged_rule_entities)}")
print(f"   Sau khi lá»c K-pop: {len(filtered_rule_entities)}")

print(f"\n   PhÃ¢n loáº¡i cuá»‘i cÃ¹ng (Rule-based):")
for t in ['Company', 'Group', 'Artist', 'Album', 'Song']:
    print(f"     - {t}: {counts_rule.get(t, 0)}")

print(f"\n   Sá»‘ entities Ä‘Ã£ sá»­a type (Rule-based):")
if fixed_type_count:
    for fix_type, count in fixed_type_count.items():
        print(f"     - {fix_type}: {count}")
else:
    print(f"     - KhÃ´ng cÃ³")

print(f"\n   Sá»‘ entities bá»‹ loáº¡i (Rule-based):")
for t in ['Company', 'Group', 'Artist', 'Album', 'Song']:
    total_removed = removed_count_rule.get(t, 0)
    if total_removed > 0:
        reasons = removed_reason_rule.get(t, {})
        print(f"     - {t}: {total_removed}")
        for reason, count in reasons.items():
            reason_text = {
                'no_kpop_context': 'Thiáº¿u context K-pop',
                'not_music_artist': 'KhÃ´ng pháº£i nghá»‡ sÄ© Ã¢m nháº¡c',
                'not_related_to_network': 'KhÃ´ng liÃªn quan máº¡ng lÆ°á»›i'
            }.get(reason, reason)
            print(f"         + {reason_text}: {count}")

if ML_NER_AVAILABLE:
    print(f"\nğŸ“Š THá»NG KÃŠ ML-BASED:")
    print(f"   Entities thÃ´: {len(ml_all_entities)}")
    print(f"   Sau khi gá»™p: {len(merged_ml_entities)}")
    print(f"   Sau khi lá»c K-pop: {len(filtered_ml_entities)}")
    
    print(f"\n   PhÃ¢n loáº¡i cuá»‘i cÃ¹ng (ML-based):")
    for t in ['Company', 'Group', 'Artist', 'Album', 'Song']:
        print(f"     - {t}: {counts_ml.get(t, 0)}")
    
    print(f"\n   Sá»‘ entities Ä‘Ã£ sá»­a type (ML-based):")
    if fixed_type_count_ml:
        for fix_type, count in fixed_type_count_ml.items():
            print(f"     - {fix_type}: {count}")
    else:
        print(f"     - KhÃ´ng cÃ³")
    
    print(f"\n   Sá»‘ entities bá»‹ loáº¡i (ML-based):")
    for t in ['Company', 'Group', 'Artist', 'Album', 'Song']:
        total_removed = removed_count_ml.get(t, 0)
        if total_removed > 0:
            reasons = removed_reason_ml.get(t, {})
            print(f"     - {t}: {total_removed}")
            for reason, count in reasons.items():
                reason_text = {
                    'no_kpop_context': 'Thiáº¿u context K-pop',
                    'not_music_artist': 'KhÃ´ng pháº£i nghá»‡ sÄ© Ã¢m nháº¡c',
                    'not_related_to_network': 'KhÃ´ng liÃªn quan máº¡ng lÆ°á»›i',
                    'ml_low_confidence': 'Confidence < 0.65'
                }.get(reason, reason)
                print(f"         + {reason_text}: {count}")

# Hiá»ƒn thá»‹ top entities
print(f"\nğŸ“ TOP ENTITIES THEO Äá»˜ TIN Cáº¬Y (Rule-based):")
for t in ['Company', 'Group', 'Artist', 'Album', 'Song']:
    items = [e for e in filtered_rule_entities if e['type'] == t][:10]
    if items:
        print(f"\n   {t} (top 10):")
        for i, e in enumerate(items, 1):
            src = len(set(e.get('sources', [])))
            print(f"     {i}. {e['text']} (conf: {e['confidence']:.2f}, {src} nguá»“n)")

if ML_NER_AVAILABLE and filtered_ml_entities:
    print(f"\nğŸ“ TOP ENTITIES THEO Äá»˜ TIN Cáº¬Y (ML-based):")
    for t in ['Company', 'Group', 'Artist', 'Album', 'Song']:
        items = [e for e in filtered_ml_entities if e['type'] == t][:10]
        if items:
            print(f"\n   {t} (top 10):")
            for i, e in enumerate(items, 1):
                src = len(set(e.get('sources', [])))
                print(f"     {i}. {e['text']} (conf: {e['confidence']:.2f}, {src} nguá»“n)")

print("\nâœ… HOÃ€N Táº¤T!")
