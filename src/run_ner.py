# -*- coding: utf-8 -*-
"""
M√î H√åNH NH·∫¨N D·∫†NG TH·ª∞C TH·ªÇ K-POP (T√çCH H·ª¢P B·ªò L·ªåC)
===================================================
1. Nh·∫≠n d·∫°ng entities t·ª´ vƒÉn b·∫£n Wikipedia
2. L·ªçc theo context K-pop
3. Lo·∫°i b·ªè entities kh√¥ng h·ª£p l·ªá
"""
import sys
import io
import json
import re
from collections import defaultdict
from datetime import datetime

# Import ML-based NER module
try:
    from ml_ner import extract_ml_entities, get_ner_model
    ML_NER_AVAILABLE = True
except ImportError:
    ML_NER_AVAILABLE = False
    print("‚ö†Ô∏è  ml_ner module kh√¥ng kh·∫£ d·ª•ng. Ch·ªâ s·ª≠ d·ª•ng rule-based NER.")

if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

print("=" * 70)
print("M√î H√åNH NH·∫¨N D·∫†NG TH·ª∞C TH·ªÇ K-POP (HYBRID: RULE-BASED + ML)")
print("=" * 70)

# Kh·ªüi t·∫°o ML model n·∫øu c√≥
if ML_NER_AVAILABLE:
    print("\nü§ñ ƒêang kh·ªüi t·∫°o ML-based NER model...")
    try:
        ml_model = get_ner_model()
        if ml_model and ml_model.available:
            print("  ‚úì ML model ƒë√£ s·∫µn s√†ng")
        else:
            print("  ‚ö†Ô∏è  ML model kh√¥ng kh·∫£ d·ª•ng, ch·ªâ s·ª≠ d·ª•ng rule-based")
    except Exception as e:
        print(f"  ‚ö†Ô∏è  L·ªói kh·ªüi t·∫°o ML model: {e}")
        print("  ‚Üí Ch·ªâ s·ª≠ d·ª•ng rule-based NER")
else:
    print("\n‚ö†Ô∏è  ML-based NER kh√¥ng kh·∫£ d·ª•ng, ch·ªâ s·ª≠ d·ª•ng rule-based")

# =====================================================
# T·ª™ KH√ìA K-POP (ƒë·ªÉ ki·ªÉm tra context)
# =====================================================
KPOP_KEYWORDS = {
    # Thu·∫≠t ng·ªØ K-pop
    'k-pop', 'kpop', 'k pop', 'idol', 'idols', 'th·∫ßn t∆∞·ª£ng',
    'debut', 'ra m·∫Øt', 'comeback', 'tr·ªü l·∫°i', 'fandom', 'fan',
    'trainee', 'th·ª±c t·∫≠p sinh', 'agency', 'entertainment',
    'mv', 'music video', 'teaser', 'concept', 'mini album', 'ep',
    'title track', 'ca kh√∫c ch·ªß ƒë·ªÅ', 'b·∫£ng x·∫øp h·∫°ng', 'chart',
    'melon', 'gaon', 'billboard', 'inkigayo', 'music bank', 'm countdown',
    'daesang', 'bonsang', 'rookie', 't√¢n binh', 'world tour',
    # Qu·ªëc gia
    'h√†n qu·ªëc', 'korea', 'korean', 'seoul', 'nam h√†n',
    # Vai tr√≤
    'nh√≥m nh·∫°c', 'ca sƒ©', 'rapper', 'dancer', 'vocal', 'main vocal',
    'lead vocal', 'sub vocal', 'main dancer', 'lead dancer',
    'main rapper', 'leader', 'tr∆∞·ªüng nh√≥m', 'maknae', 'visual', 'center',
    # C√¥ng ty
    'sm entertainment', 'jyp entertainment', 'yg entertainment', 'hybe',
    'cube entertainment', 'starship', 'pledis', 'fnc', 'woollim',
    'rbw', 'wm entertainment', 'dsp media', 'mbk', 'jellyfish',
    'big hit', 'source music', 'kq entertainment', 'ist entertainment',
    # Nh√≥m nh·∫°c n·ªïi ti·∫øng
    'bts', 'blackpink', 'twice', 'exo', 'nct', 'aespa', 'ive', 'newjeans',
    'stray kids', 'seventeen', 'txt', 'enhypen', 'le sserafim', 'itzy',
    'red velvet', 'girls generation', 'snsd', 'super junior', 'shinee',
    'got7', 'monsta x', 'ateez', 'the boyz', 'treasure', 'bigbang',
    '2ne1', 'wonder girls', 'f(x)', 'mamamoo', 'gfriend', 'apink',
    'oh my girl', 'loona', 'fromis_9', 'wjsn', 'everglow', 'dreamcatcher',
}

# =====================================================
# T·ª™ KH√îNG H·ª¢P L·ªÜ (CHUNG CHUNG, KH√îNG PH·∫¢I T√äN RI√äNG)
# =====================================================
INVALID_WORDS = {
    # Ti·∫øng Anh chung
    'the', 'a', 'an', 'and', 'or', 'but', 'is', 'was', 'are', 'were',
    'has', 'have', 'had', 'been', 'to', 'for', 'of', 'in', 'on', 'at',
    'by', 'with', 'about', 'as', 'this', 'that', 'these', 'those',
    'my', 'your', 'his', 'her', 'its', 'our', 'their', 'it', 'he', 'she',
    
    # Ti·∫øng Vi·ªát chung
    'c·ªßa', 'l√†', 'v√†', 'v·ªõi', 'trong', 'c√≥', 'ƒë∆∞·ª£c', 't·ª´', 'n√†y', 'ƒë√≥',
    'nƒÉm', 'th√°ng', 'ng√†y', 'sau', 'tr∆∞·ªõc', 'c≈©ng', 'nh∆∞', 'khi', 'n·∫øu',
    'b√†i', 'h√°t', 'ca', 'kh√∫c', 'album', 'single', 'ep', 'mv',
    
    # T·ª´ b·ªã nh·∫≠n nh·∫ßm th∆∞·ªùng g·∫∑p
    'aideul', 'n nay', 'ch', 'hottest rookies', 'i-land', 'who am i',
    'version', 'ver', 'remix', 'inst', 'instrumental', 'acoustic',
    'live', 'repackage', 'repack', 'special', 'deluxe', 'limited',
    
    # Thu·∫≠t ng·ªØ K-pop (kh√¥ng ph·∫£i t√™n ri√™ng)
    'k-pop', 'kpop', 'k pop', 'idol', 'idols', 'chart', 'charts',
    'gaon', 'oricon', 'billboard', 'melon', 'hanteo',
    'sales', 'vol', 'vol.', 'mr', 'mr.', 'ms', 'ms.',
    'producer', 'school', 'corp', 'corp.', 'inc', 'inc.',
    'lands no', 'earns madison beer', 'k-pop big bang',
    
    # Vi·∫øt t·∫Øt ng·∫Øn v√¥ nghƒ©a (1-2 k√Ω t·ª±)
    'al', 'ba', 'be', 'bo', 'bu', 'don', 'dr', 'el', 'fi', 'fo',
    'ga', 'go', 'ha', 'he', 'hi', 'ho', 'hu', 'i.o', 'h.o', 'fin',
    'ja', 'ji', 'jo', 'ju', 'ka', 'ki', 'ko', 'ku', 'la', 'le',
    'li', 'lo', 'lu', 'ma', 'me', 'mi', 'mo', 'mu', 'na', 'ne',
    'ni', 'no', 'nu', 'pa', 'pe', 'pi', 'po', 'pu', 'ra', 're',
    'ri', 'ro', 'ru', 'sa', 'se', 'si', 'so', 'su', 'ta', 'te',
    'ti', 'to', 'tu', 'va', 've', 'vi', 'vo', 'vu', 'wa', 'we',
    'wi', 'wo', 'wu', 'xa', 'xe', 'xi', 'xo', 'xu', 'ya', 'ye',
    'yi', 'yo', 'yu', 'za', 'ze', 'zi', 'zo', 'zu',
    
    # Suffix c√¥ng ty (kh√¥ng ph·∫£i nh√≥m nh·∫°c)
    'n.v', 'n.v.', 'inc', 'inc.', 'ltd', 'ltd.', 'corp', 'corp.',
    'llc', 'llc.', 'co', 'co.', 'plc', 'plc.',
    
    # T·ª´ chung kh√°c
    'always', 'back', 'best', 'big', 'new', 'old', 'good', 'bad',
    'first', 'last', 'next', 'top', 'hit', 'hot', 'cool', 'nice',
    'love', 'like', 'want', 'need', 'know', 'think', 'feel',
    'day', 'night', 'time', 'year', 'week', 'month',
    'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten',
    'beautiful', 'because of you', 'bo peep',
    
    # T·ª´ t·ªïng qu√°t v·ªÅ media/technology (kh√¥ng ph·∫£i t√™n ngh·ªá sƒ©/album/b√†i h√°t)
    'video', 'audio', 'music', 'clip', 'film', 'movie', 'photo', 'picture',
    'image', 'graphic', 'media', 'content', 'file', 'download', 'stream',
    'playback', 'recording', 'broadcast', 'television', 'tv', 'radio',
    
    # Ch∆∞∆°ng tr√¨nh th·ª±c t·∫ø/Show (kh√¥ng ph·∫£i ngh·ªá sƒ©)
    'contest', 'season', 'episode', 'show', 'program', 'programme',
    'dictation contest', 'singing contest', 'dance contest',
    'audition', 'survival', 'competition', 'challenge',
    'talk tv', 'idol room', 'idol world', 'idol room', 'idol world',
    'team b', 'team a', 'team c', 'team d', 'team 8',  # C√°c team chung chung
    'mbc ep', 'radio', 'school class', 'idol maknae rebellion',
    'ost', 'producer idol producer', 'new storm',
    'to the beautiful you',  # Phim
    'hits mr',  # Node sai
    'idol intern king', 'idol maknae rebellion',  # Ch∆∞∆°ng tr√¨nh c√≥ ch·ªØ Idol
    'intern king', 'maknae rebellion',  # T√™n ch∆∞∆°ng tr√¨nh (kh√¥ng c·∫ßn ch·ªØ idol ·ªü ƒë·∫ßu)
    'debut countdown',  # Ch∆∞∆°ng tr√¨nh ƒë·∫øm ng∆∞·ª£c
    'dream team',  # Ch∆∞∆°ng tr√¨nh Let's Go Dream Team
}

# =====================================================
# ƒê·ªäA DANH (KH√îNG PH·∫¢I NGH·ªÜ Sƒ®/NH√ìM)
# =====================================================
LOCATION_NAMES = {
    'seoul', 'san francisco', 'busan', 'tokyo', 'osaka',
    'new york', 'los angeles', 'london', 'paris', 'berlin',
    'sydney', 'melbourne', 'bangkok', 'singapore', 'hong kong',
    'taipei', 'beijing', 'shanghai', 'mumbai', 'delhi',
    'manila', 'jakarta', 'kuala lumpur', 'ho chi minh',
    # Qu·∫≠n/huy·ªán H√†n Qu·ªëc th∆∞·ªùng xu·∫•t hi·ªán trong ph·∫ßn n∆°i sinh
    'dongdaemun-gu', 'dongdaemun gu',
}

# =====================================================
# T·ª™ KH√ìA QU·ªêC GIA KH√îNG PH·∫¢I H√ÄN QU·ªêC
# =====================================================
NON_KOREAN_COUNTRIES = {
    # T√™n qu·ªëc gia ti·∫øng Anh
    'malaysia', 'malaysian', 'thailand', 'thai', 'vietnam', 'vietnamese',
    'indonesia', 'indonesian', 'philippines', 'filipino', 'filipina',
    'singapore', 'singaporean', 'china', 'chinese', 'taiwan', 'taiwanese',
    'japan', 'japanese', 'india', 'indian', 'usa', 'american', 'america',
    'uk', 'british', 'england', 'english', 'australia', 'australian',
    'canada', 'canadian', 'france', 'french', 'germany', 'german',
    'brazil', 'brazilian', 'mexico', 'mexican', 'spain', 'spanish',
    'italy', 'italian', 'russia', 'russian', 'hong kong',
    'puerto rico', 'puerto rican',
    
    # T√™n qu·ªëc gia ti·∫øng Vi·ªát  
    'm·ªπ', 'nh·∫≠t b·∫£n', 'trung qu·ªëc', 'ƒë√†i loan', 'th√°i lan', 'malaysia',
    'indonesia', 'philippines', 'singapore', '·∫•n ƒë·ªô', '√∫c', 'anh',
    'ph√°p', 'ƒë·ª©c', '√Ω', 'nga', 'brazil', 'canada',
}

# =====================================================
# T·ª™ KH√ìA CH·ªà CH∆Ø∆†NG TR√åNH/SHOW (KH√îNG PH·∫¢I NGH·ªÜ Sƒ®)
# =====================================================
SHOW_KEYWORDS = {
    'contest', 'season', 'episode', 'show', 'program', 'programme',
    'audition', 'survival', 'competition', 'challenge', 'festival',
    'awards', 'award', 'ceremony', 'gala', 'concert tour',
    'dictation', 'singing', 'dance', 'talent', 'reality',
    'championship', 'tournament', 'battle', 'game', 'quiz',
    'talk tv', 'idol room', 'idol world', 'room', 'world',
    'tv', 'television', 'broadcast', 'variety',
    'radio', 'school class', 'idol maknae rebellion',
    'mbc ep', 'ep 347', 'ep ', ' ep',  # Pattern ch∆∞∆°ng tr√¨nh truy·ªÅn h√¨nh
    'ost', 'producer idol producer',  # OST v√† Producer
    'intern king', 'maknae rebellion',  # T√™n ch∆∞∆°ng tr√¨nh (kh√¥ng c·∫ßn ch·ªØ idol ·ªü ƒë·∫ßu)
}

# =====================================================
# BLACKLIST CA Sƒ® N∆Ø·ªöC NGO√ÄI (KH√îNG PH·∫¢I K-POP)
# =====================================================
FOREIGN_ARTIST_BLACKLIST = {
    # Ca sƒ© Vi·ªát Nam
    'thu minh', 'm·ªπ t√¢m', 'h·ªìng nhung', 'thanh lam', 'h√† tr·∫ßn',
    'ƒë√†m vƒ©nh h∆∞ng', 'lam tr∆∞·ªùng', 'ƒëan tr∆∞·ªùng', 's∆°n t√πng m-tp',
    'soobin ho√†ng s∆°n', 's∆°n t√πng', 'ƒë·ª©c ph√∫c', 'minh h·∫±ng',
    'h∆∞∆°ng tr√†m', 'hoa minzy', 'minh h·∫±ng', 'chi pu',
    
    # Ca sƒ© M·ªπ/Qu·ªëc t·∫ø
    'nicki minaj', 'cardi b', 'ariana grande', 'taylor swift',
    'beyonc√©', 'rihanna', 'lady gaga', 'katy perry', 'selena gomez',
    'justin bieber', 'ed sheeran', 'bruno mars', 'the weeknd',
    'drake', 'post malone', 'billie eilish', 'dua lipa',
    'adele', 'shakira', 'jennifer lopez', 'madonna',
    'mariah carey', 'arnold', 'lionel richie',
    'britney spears', 'hilary duff', 'michael jackson',
    
    # Ca sƒ© Nh·∫≠t B·∫£n
    'utada hikaru', 'ayumi hamasaki', 'namie amuro', 'boa',  # BoA l√† K-pop nh∆∞ng c·∫ßn ki·ªÉm tra context
    
    # Ca sƒ© Trung Qu·ªëc
    'wang lee hom', 'jay chou', 'jolin tsai', 'g.e.m',
    
    # Ca sƒ© Th√°i Lan
    'lisa',  # C·∫ßn ki·ªÉm tra context (c√≥ th·ªÉ l√† Lisa c·ªßa BLACKPINK)
    
    # Ca sƒ© Malaysia
    'mizz nina', 'yuna',
}

# =====================================================
# T·ª™ TH·ª™A C·∫¶N LO·∫†I B·ªé ·ªû CU·ªêI T√äN
# =====================================================
SUFFIX_WORDS_TO_REMOVE = {
    'rapping', 'singing', 'dancing', 'performing', 'performer',
    'singer', 'rapper', 'dancer', 'idol', 'artist', 'vocalist',
    'producer', 'composer', 'songwriter', 'musician',
    'ca sƒ©', 'ngh·ªá sƒ©', 'th·∫ßn t∆∞·ª£ng', 'rapper', 'dancer',
}

# =====================================================
# TH·ªÇ LO·∫†I NH·∫†C (KH√îNG PH·∫¢I NGH·ªÜ Sƒ®)
# =====================================================
MUSIC_GENRES = {
    'hip-hop', 'hip hop', 'hiphop', 'rap', 'r&b', 'rnb',
    'pop', 'rock', 'jazz', 'blues', 'country', 'folk',
    'electronic', 'edm', 'house', 'techno', 'trance',
    'classical', 'opera', 'reggae', 'salsa', 'latin',
    'k-pop', 'kpop', 'j-pop', 'jpop', 'c-pop', 'cpop',
    'ballad', 'dance', 'trot', 'indie', 'alternative',
    'metal', 'punk', 'grunge', 'soul', 'funk', 'disco',
    'gospel', 'christian', 'gospel', 'world music',
}

# =====================================================
# T√äN NH√ìM NH·∫†C K-POP ƒê√É BI·∫æT (ƒë·ªÉ ph√°t hi·ªán pattern "Group + Member")
# =====================================================
KNOWN_KPOP_GROUPS = {
    'exo', 'girls generation', "girls' generation", 'snsd',
    'bts', 'blackpink', 'twice', 'nct', 'aespa', 'ive',
    'newjeans', 'stray kids', 'seventeen', 'txt', 'enhypen',
    'le sserafim', 'itzy', 'red velvet', 'super junior',
    'shinee', 'got7', 'monsta x', 'ateez', 'the boyz',
    'treasure', 'bigbang', '2ne1', 'wonder girls', 'f(x)',
    'mamamoo', 'gfriend', 'apink', 'oh my girl', 'loona',
    'fromis_9', 'wjsn', 'everglow', 'dreamcatcher',
    'block b', 't-ara', 'kara', 'sistar', 'miss a',
    '4minute', '2pm', '2am', 'shinee', 'infinite',
    'beast', 'highlight', 'b1a4', 'cnblue', 'ftisland',
    'kara', 'after school', 'orange caramel', 'rainbow',
    'nine muses', 'girls day', 'aoa', 'exid', 'crayon pop',
    'ladies code', 'bestie', 'stellar', 'sonamoo',
    # Th√™m c√°c nh√≥m nh·∫°c ƒë√£ bi·∫øt
    'one day', 'onetwo', 'pentagon', 'rania', 'sm rookies',
    'seeya', 'shinhwa', 'the ark', 'vixx', 'wanna one',
    'up10tion', 'bonus baby',
    'hello venus', 'cosmic girls',
    # B·ªï sung th√™m c√°c nh√≥m m·ªõi ƒë·ªÉ tr√°nh pattern "Group + Member" b·ªã gi·ªØ l√†m Artist
    'x1',
}

# =====================================================
# T·ª™ KH√ìA X√ÅC ƒê·ªäNH L√Ä NGH·ªÜ Sƒ® √ÇM NH·∫†C (Artist ph·∫£i c√≥)
# =====================================================
MUSIC_ROLE_KEYWORDS = {
    'ca sƒ©', 'ngh·ªá sƒ©', 'rapper', 'dancer', 'idol', 'th·∫ßn t∆∞·ª£ng',
    'vocalist', 'main vocal', 'lead vocal', 'sub vocal',
    'main rapper', 'lead rapper', 'main dancer', 'lead dancer',
    'th√†nh vi√™n', 'c·ª±u th√†nh vi√™n', 'leader', 'tr∆∞·ªüng nh√≥m', 'maknae',
    'visual', 'center', 'all-rounder', 'producer', 'nh√† s·∫£n xu·∫•t',
    's√°ng t√°c', 'vi·∫øt nh·∫°c', 'composer', 'songwriter',
}

# =====================================================
# T·ª™ KH√ìA LO·∫†I TR·ª™ (KH√îNG PH·∫¢I NGH·ªÜ Sƒ® √ÇM NH·∫†C)
# =====================================================
EXCLUDE_KEYWORDS = {
    'di·ªÖn vi√™n', 'actor', 'actress', 'ƒë·∫°o di·ªÖn', 'director',
    'nh√† vƒÉn', 't√°c gi·∫£', 'writer', 'author', 'ti·ªÉu thuy·∫øt',
    'mc', 'ng∆∞·ªùi d·∫´n ch∆∞∆°ng tr√¨nh', 'host', 'Âè∏‰ºö',
    'v·∫≠n ƒë·ªông vi√™n', 'c·∫ßu th·ªß', 'athlete', 'player', 'football',
    'ch√≠nh tr·ªã gia', 'politician', 't·ªïng th·ªëng', 'president', 'b·ªô tr∆∞·ªüng',
    'doanh nh√¢n', 'businessman', 'ceo', 'gi√°m ƒë·ªëc',
    'gi√°o s∆∞', 'professor', 'b√°c sƒ©', 'doctor', 'lu·∫≠t s∆∞',
    'youtuber', 'streamer', 'influencer', 'tiktoker',
    'ng∆∞·ªùi m·∫´u', 'model', 'si√™u m·∫´u',
}

# =====================================================
# C√îNG TY K-POP ƒê√É BI·∫æT
# =====================================================
KNOWN_COMPANIES = {
    'SM Entertainment', 'JYP Entertainment', 'YG Entertainment', 'HYBE',
    'Cube Entertainment', 'Starship Entertainment', 'Pledis Entertainment',
    'FNC Entertainment', 'Woollim Entertainment', 'RBW Entertainment',
    'WM Entertainment', 'DSP Media', 'MBK Entertainment',
    'Jellyfish Entertainment', 'Stone Music Entertainment',
    'Kakao Entertainment', 'CJ ENM', 'Big Hit Entertainment',
    'Source Music', 'KQ Entertainment', 'IST Entertainment',
    'Fantagio', 'Brand New Music', 'P Nation', 'AOMG',
    'H1GHR MUSIC', 'Antenna', 'TOP Media', 'Mystic Story',
    'ADOR', 'Belift Lab', 'Play M Entertainment',
}

# =====================================================
# H·ªå H√ÄN QU·ªêC
# =====================================================
KOREAN_SURNAMES = {
    'Kim', 'Lee', 'Park', 'Choi', 'Jung', 'Jang', 'Cho', 'Kang', 'Yoon',
    'Shin', 'Han', 'Oh', 'Seo', 'Kwon', 'Hwang', 'Ahn', 'Song', 'Jeon',
    'Moon', 'Yang', 'Hong', 'Bae', 'Baek', 'Lim', 'Im', 'Ryu', 'Yoo',
    'Nam', 'Sim', 'Ha', 'Woo', 'Ji', 'Min', 'Cha', 'Jo', 'Noh', 'Ko',
}

# =====================================================
# H√ÄM CHU·∫®N H√ìA T√äN (PH·∫¢I ƒê·ªäNH NGHƒ®A TR∆Ø·ªöC KHI S·ª¨ D·ª§NG)
# =====================================================
def clean_text(text):
    """L√†m s·∫°ch text v√† lo·∫°i b·ªè t·ª´ th·ª´a ·ªü cu·ªëi"""
    text = text.strip()
    
    # X·ª≠ l√Ω d·∫•u ngo·∫∑c ƒë∆°n ch∆∞a ƒë√≥ng (v√≠ d·ª•: "Euiwoong (Lew" -> "Euiwoong Lew")
    # T√¨m c√°c pattern c√≥ d·∫•u m·ªü ngo·∫∑c nh∆∞ng kh√¥ng c√≥ d·∫•u ƒë√≥ng ngo·∫∑c
    if '(' in text and text.count('(') > text.count(')'):
        # C√≥ d·∫•u m·ªü ngo·∫∑c nh∆∞ng kh√¥ng ƒë√≥ng -> chuy·ªÉn ph·∫ßn trong ngo·∫∑c th√†nh text b√¨nh th∆∞·ªùng
        # Pattern: "Name (Incomplete" -> "Name Incomplete"
        # T√¨m v·ªã tr√≠ d·∫•u m·ªü ngo·∫∑c cu·ªëi c√πng kh√¥ng c√≥ d·∫•u ƒë√≥ng
        last_open = text.rfind('(')
        if last_open != -1:
            # L·∫•y ph·∫ßn tr∆∞·ªõc d·∫•u m·ªü ngo·∫∑c v√† ph·∫ßn sau (b·ªè d·∫•u m·ªü ngo·∫∑c)
            before = text[:last_open].strip()
            after = text[last_open+1:].strip()
            # G·ªôp l·∫°i v·ªõi kho·∫£ng tr·∫Øng
            text = f"{before} {after}".strip()
    
    # Lo·∫°i b·ªè c√°c pattern trong ngo·∫∑c ƒë∆°n ·ªü cu·ªëi (nh∆∞ "(ca sƒ©)", "(nh√≥m nh·∫°c)")
    # NH∆ØNG gi·ªØ l·∫°i n·∫øu l√† (album), (b√†i h√°t), (EP) - v√¨ ƒë√≥ l√† th√¥ng tin quan tr·ªçng
    text = re.sub(r'\s*\([^)]*(?:ca sƒ©|nh√≥m nh·∫°c|ban nh·∫°c|ngh·ªá sƒ©|singer|group|band)[^)]*\)\s*$', '', text, flags=re.IGNORECASE)
    
    # Chu·∫©n h√≥a kho·∫£ng tr·∫Øng
    text = re.sub(r'\s+', ' ', text)
    # Chu·∫©n h√≥a d·∫•u g·∫°ch n·ªëi gi·ªØa ch·ªØ c√°i th√†nh kho·∫£ng tr·∫Øng (Ahn Ji-young -> Ahn Ji young)
    text = re.sub(r'(?<=\w)-(?!\s)(?=\w)', ' ', text)
    # Lo·∫°i b·ªè k√Ω t·ª± th·ª´a ·ªü ƒë·∫ßu/cu·ªëi
    text = text.strip('.,;:!?"\'-()[]{}')
    
    # Lo·∫°i b·ªè t·ª´ th·ª´a ·ªü cu·ªëi t√™n (nh∆∞ "rapping", "singing", "dancing")
    words = text.split()
    if len(words) > 1:
        last_word = words[-1].lower()
        if last_word in SUFFIX_WORDS_TO_REMOVE:
            text = ' '.join(words[:-1])
    
    return text

# =====================================================
# LOAD D·ªÆ LI·ªÜU
# =====================================================
print("\nüìÇ ƒêang load d·ªØ li·ªáu...")
with open('enrichment_text_data.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

records = data.get('data', [])
print(f"‚úì ƒê√£ load {len(records)} records")

# T·∫°o mapping node_id -> text (lowercase) ƒë·ªÉ ki·ªÉm tra context
node_texts = {}
existing_lower = set()
for record in records:
    node_id = record.get('node_id', '')
    node_name = record.get('node_name', '')
    text = record.get('text', '')
    node_texts[node_id] = text.lower()
    if node_name:
        # CHU·∫®N H√ìA t√™n node g·ªëc ƒë·ªÉ lo·∫°i b·ªè suffix nh∆∞ "(ca sƒ©)", "(nh√≥m nh·∫°c)"
        normalized_name = clean_text(node_name)
        normalized_lower = normalized_name.lower()
        # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng ƒë·ªÉ check tr√πng v·ªõi node g·ªëc (Big Bang = BIGBANG)
        # D√πng ƒë·ªÉ LO·∫†I B·ªé node m·ªõi n·∫øu tr√πng v·ªõi node g·ªëc
        key_without_spaces = normalized_lower.replace(' ', '')
        existing_lower.add(key_without_spaces)

print(f"‚úì C√≥ {len(existing_lower)} entities trong ƒë·ªì th·ªã")

# =====================================================
# LOAD TH√îNG TIN TH√ÄNH VI√äN T·ª™ INFOBOX (ƒê√É CRAWL S·∫¥N)
# =====================================================
try:
    with open('infobox_members.json', 'r', encoding='utf-8') as f:
        INFOBOX_MEMBERS = json.load(f)
except Exception:
    INFOBOX_MEMBERS = {"groups": {}, "artists": {}}


# =====================================================
# H√ÄM KI·ªÇM TRA CONTEXT K-POP
# =====================================================
def has_kpop_context(source_nodes, min_keywords=3):
    """
    Ki·ªÉm tra entity c√≥ trong context K-pop kh√¥ng
    
    Args:
        source_nodes: Danh s√°ch node IDs ngu·ªìn
        min_keywords: S·ªë t·ª´ kh√≥a K-pop t·ªëi thi·ªÉu (m·∫∑c ƒë·ªãnh 3)
    """
    if isinstance(source_nodes, str):
        source_nodes = [source_nodes]
    
    for source in source_nodes:
        text = node_texts.get(source, '')
        if text:
            text_lower = text.lower()
            kpop_count = sum(1 for kw in KPOP_KEYWORDS if kw.lower() in text_lower)
            if kpop_count >= min_keywords:
                return True
    return False

def is_music_artist(entity_text, source_nodes):
    """
    Ki·ªÉm tra xem entity c√≥ ph·∫£i l√† ngh·ªá sƒ© √¢m nh·∫°c kh√¥ng
    - Ph·∫£i c√≥ t·ª´ kh√≥a vai tr√≤ √¢m nh·∫°c trong context g·∫ßn
    - Kh√¥ng ƒë∆∞·ª£c c√≥ t·ª´ kh√≥a lo·∫°i tr·ª´ (di·ªÖn vi√™n, MC, etc.)
    """
    if isinstance(source_nodes, str):
        source_nodes = [source_nodes]
    
    entity_lower = entity_text.lower()
    
    for source in source_nodes:
        full_text = node_texts.get(source, '')
        if not full_text:
            continue
        
        # T√¨m v·ªã tr√≠ entity trong text
        idx = full_text.find(entity_lower)
        if idx == -1:
            continue
        
        # L·∫•y context g·∫ßn (200 k√Ω t·ª± xung quanh)
        start = max(0, idx - 100)
        end = min(len(full_text), idx + len(entity_text) + 100)
        context = full_text[start:end]
        
        # Ki·ªÉm tra c√≥ t·ª´ kh√≥a lo·∫°i tr·ª´ kh√¥ng
        has_exclude = any(kw in context for kw in EXCLUDE_KEYWORDS)
        if has_exclude:
            return False
        
        # Ki·ªÉm tra c√≥ t·ª´ kh√≥a vai tr√≤ √¢m nh·∫°c kh√¥ng
        has_music_role = any(kw in context for kw in MUSIC_ROLE_KEYWORDS)
        if has_music_role:
            return True
    
    # N·∫øu kh√¥ng t√¨m th·∫•y context r√µ r√†ng, ki·ªÉm tra to√†n b·ªô text
    for source in source_nodes:
        full_text = node_texts.get(source, '')
        # N·∫øu c√≥ t·ª´ kh√≥a lo·∫°i tr·ª´ trong to√†n b·ªô text -> lo·∫°i
        if any(kw in full_text for kw in EXCLUDE_KEYWORDS):
            # Nh∆∞ng n·∫øu c√≥ nhi·ªÅu t·ª´ kh√≥a √¢m nh·∫°c h∆°n -> c√≥ th·ªÉ l√† ngh·ªá sƒ© ki√™m di·ªÖn vi√™n
            music_count = sum(1 for kw in MUSIC_ROLE_KEYWORDS if kw in full_text)
            exclude_count = sum(1 for kw in EXCLUDE_KEYWORDS if kw in full_text)
            if music_count > exclude_count * 2:  # T·ª´ kh√≥a √¢m nh·∫°c ph·∫£i g·∫•p ƒë√¥i
                return True
            return False
    
    return False  # M·∫∑c ƒë·ªãnh kh√¥ng ph·∫£i ngh·ªá sƒ© n·∫øu kh√¥ng c√≥ context r√µ r√†ng

def is_related_to_existing_nodes(entity_text, source_nodes, existing_names, min_mentioned=2):
    """
    Ki·ªÉm tra entity c√≥ li√™n quan ƒë·∫øn c√°c node hi·ªán c√≥ trong m·∫°ng kh√¥ng
    - Xu·∫•t hi·ªán c√πng v·ªõi c√°c ngh·ªá sƒ©/nh√≥m nh·∫°c ƒë√£ c√≥
    """
    if isinstance(source_nodes, str):
        source_nodes = [source_nodes]
    
    for source in source_nodes:
        # source_node ch√≠nh l√† m·ªôt node trong m·∫°ng
        if source.lower() in existing_names:
            return True
        
        full_text = node_texts.get(source, '')
        if not full_text:
            continue
        
        # Ki·ªÉm tra c√≥ nh·∫Øc ƒë·∫øn c√°c node hi·ªán c√≥ kh√¥ng
        mentioned_count = sum(1 for name in existing_names if name in full_text)
        if mentioned_count >= min_mentioned:  # Ph·∫£i nh·∫Øc ƒë·∫øn √≠t nh·∫•t min_mentioned node hi·ªán c√≥
            return True
    
    return False

def is_valid_entity(text, entity_type):
    """Ki·ªÉm tra entity c√≥ h·ª£p l·ªá kh√¥ng"""
    # ƒê·ªô d√†i c∆° b·∫£n
    if not text or len(text) > 50:
        return False
    
    # Lo·∫°i b·ªè entities qu√° ng·∫Øn (tr·ª´ m·ªôt s·ªë t√™n ngh·ªá sƒ© h·ª£p l·ªá nh∆∞ RM, IU, CL)
    valid_short_names = {'rm', 'iu', 'cl', 'bm', 'jb', 'jj', 'jo', 'im', 'do'}
    if len(text) < 3 and text.lower() not in valid_short_names:
        return False
    # Kh√¥ng ch·∫•p nh·∫≠n ngh·ªá sƒ© ch·ªâ 1 k√Ω t·ª± (tr√°nh c√°c t√™n b·ªã c·∫Øt c·ª•t nh∆∞ "B", "K")
    if entity_type == 'Artist' and len(text) == 1:
        return False
    
    # Ki·ªÉm tra t·ª´ kh√¥ng h·ª£p l·ªá
    if text.lower() in INVALID_WORDS:
        return False
    
    text_lower = text.lower()
    words = text_lower.split()
    
    # ============================================
    # LO·∫†I B·ªé CA Sƒ® N∆Ø·ªöC NGO√ÄI (BLACKLIST)
    # ============================================
    if text_lower in FOREIGN_ARTIST_BLACKLIST:
        return False
    # Ki·ªÉm tra t√™n c√≥ ch·ª©a t√™n trong blacklist kh√¥ng
    for blacklisted in FOREIGN_ARTIST_BLACKLIST:
        if blacklisted in text_lower or text_lower in blacklisted:
            return False
    
    # ============================================
    # LO·∫†I B·ªé NGH·ªÜ Sƒ® T·ª™ QU·ªêC GIA KH√ÅC (kh√¥ng ph·∫£i H√†n Qu·ªëc)
    # ============================================
    for country in NON_KOREAN_COUNTRIES:
        if country in text_lower:
            return False
    # Ki·ªÉm tra t·ª´ng t·ª´ c√≥ ph·∫£i t√™n qu·ªëc gia kh√¥ng
    if any(w in NON_KOREAN_COUNTRIES for w in words):
        return False
    
    # ============================================
    # LO·∫†I B·ªé CH∆Ø∆†NG TR√åNH/SHOW (kh√¥ng ph·∫£i ngh·ªá sƒ©/nh√≥m)
    # ============================================
    # N·∫øu entity ch·ª©a t·ª´ kh√≥a show/contest v√† entity_type l√† Artist/Group -> lo·∫°i
    if entity_type in ['Artist', 'Group']:
        for show_kw in SHOW_KEYWORDS:
            if show_kw in text_lower:
                return False
    
    # Lo·∫°i b·ªè c√°c pattern nh∆∞ "... Season X", "... Contest", "... Show"
    show_patterns = [
        r'season\s*\d+', r'episode\s*\d+', r'part\s*\d+',
        r'contest$', r'show$', r'program$', r'competition$',
        r'audition', r'survival', r'challenge$', r'festival$',
        r'awards?$', r'ceremony$', r'gala$',
        r'talk\s*tv', r'idol\s*room', r'idol\s*world',  # Ch∆∞∆°ng tr√¨nh th·ª±c t·∫ø
        r'^team\s+[a-z]$', r'^team\s+[a-z]\s*$',  # Team A, Team B, Team C...
        r'countdown$', r'debut\s+countdown',  # Ch∆∞∆°ng tr√¨nh ƒë·∫øm ng∆∞·ª£c
    ]
    for pattern in show_patterns:
        if re.search(pattern, text_lower):
            return False
    
    # Lo·∫°i b·ªè c√°c node chung chung nh∆∞ "Team B", "Team A", "Team 8"
    if re.match(r'^team\s+[a-z]$', text_lower) or re.match(r'^team\s+\d+$', text_lower):
        return False
    if text_lower in ['team a', 'team b', 'team c', 'team d', 'team 8']:
        return False
    
    # Ph·∫£i b·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ in hoa, s·ªë, ho·∫∑c k√Ω t·ª± ƒë·∫∑c bi·ªát
    if not re.match(r'^[A-Z0-9Í∞Ä-Ìû£("\']', text):
        return False
    
    # Kh√¥ng ch·ª©a ch·ªâ s·ªë ho·∫∑c k√Ω t·ª± ƒë·∫∑c bi·ªát
    if re.match(r'^[\d\.\-\s]+$', text):
        return False
    
    # ============================================
    # LO·∫†I B·ªé TH·ªÇ LO·∫†I NH·∫†C (KH√îNG PH·∫¢I NGH·ªÜ Sƒ®)
    # ============================================
    if entity_type == 'Artist':
        if text_lower in MUSIC_GENRES:
            return False
        # Ki·ªÉm tra t·ª´ng t·ª´ c√≥ ph·∫£i th·ªÉ lo·∫°i nh·∫°c kh√¥ng
        if any(w in MUSIC_GENRES for w in words):
            return False
    
    # ============================================
    # LO·∫†I B·ªé T·ª™ T·ªîNG QU√ÅT V·ªÄ MEDIA/TECHNOLOGY (KH√îNG PH·∫¢I NGH·ªÜ Sƒ®)
    # ============================================
    if entity_type == 'Artist':
        generic_media_words = {
            'video', 'audio', 'music', 'clip', 'film', 'movie', 'photo', 'picture',
            'image', 'graphic', 'media', 'content', 'file', 'download', 'stream',
            'playback', 'recording', 'broadcast', 'television', 'tv', 'radio',
            'track', 'album', 'single', 'ep', 'mv', 'teaser', 'trailer',
        }
        if text_lower in generic_media_words:
            return False
    
    # ============================================
    # LO·∫†I B·ªé C√ÅC NH√ìM NH·∫†C ƒê√É BI·∫æT (KH√îNG PH·∫¢I ARTIST)
    # ============================================
    if entity_type == 'Artist':
        if text_lower in KNOWN_KPOP_GROUPS:
            return False
    
    # ============================================
    # LO·∫†I B·ªé PATTERN "SOLO + T√äN NGH·ªÜ Sƒ®"
    # ============================================
    if entity_type == 'Artist':
        # Lo·∫°i b·ªè pattern "Solo Somi Zion" (n√™n t√°ch th√†nh 2 ngh·ªá sƒ© ri√™ng)
        if text_lower.startswith('solo '):
            return False
    
    # ============================================
    # LO·∫†I B·ªé PATTERN "EP" HO·∫∂C "EPISODE" TRONG T√äN
    # ============================================
    if entity_type == 'Artist':
        # Lo·∫°i b·ªè pattern nh∆∞ "MBC Ep 347", "UP10TION Ep"
        if re.search(r'\bep\s*\d+', text_lower) or re.search(r'\bepisode\s*\d+', text_lower):
            return False
        # Lo·∫°i b·ªè n·∫øu k·∫øt th√∫c b·∫±ng " Ep" ho·∫∑c " Episode"
        if text_lower.endswith(' ep') or text_lower.endswith(' episode'):
            return False
    
    # ============================================
    # LO·∫†I B·ªé PHIM
    # ============================================
    if entity_type == 'Artist':
        # Lo·∫°i b·ªè phim nh∆∞ "To The Beautiful You"
        if 'phim' in text_lower or 'film' in text_lower or 'movie' in text_lower:
            return False
        # Lo·∫°i b·ªè c√°c phim ƒë√£ bi·∫øt
        if text_lower in ['to the beautiful you']:
            return False
    
    # ============================================
    # LO·∫†I B·ªé CH∆Ø∆†NG TR√åNH RADIO
    # ============================================
    if entity_type == 'Artist':
        # Lo·∫°i b·ªè pattern nh∆∞ "Radio' The Boyz Younghoon"
        if text_lower.startswith("radio'") or text_lower.startswith("radio "):
            return False
        # Lo·∫°i b·ªè n·∫øu ch·ª©a "radio" v√† t√™n nh√≥m
        for group in KNOWN_KPOP_GROUPS:
            if f"radio" in text_lower and group in text_lower:
                return False
    
    # ============================================
    # LO·∫†I B·ªé PATTERN "ALBUM + NƒÇM + S·ªê" HO·∫∂C "ALBUM + S·ªê"
    # ============================================
    if entity_type in ['Artist', 'Album', 'Song']:
        # Lo·∫°i b·ªè pattern nh∆∞ "Album 2011 05"
        if re.match(r'^album\s+\d{4}\s+\d+', text_lower):
            return False
        if re.match(r'^album\s+\d+', text_lower):
            return False
    
    # ============================================
    # LO·∫†I B·ªé PATTERN "IDOL + T√äN CH∆Ø∆†NG TR√åNH" HO·∫∂C CH·ªà T√äN CH∆Ø∆†NG TR√åNH
    # ============================================
    if entity_type == 'Artist':
        # Lo·∫°i b·ªè pattern nh∆∞ "Idol Intern King", "Idol Maknae Rebellion"
        if text_lower.startswith('idol '):
            # Ki·ªÉm tra xem c√≥ ph·∫£i ch∆∞∆°ng tr√¨nh kh√¥ng
            remaining = text_lower[5:].strip()  # B·ªè "idol "
            # N·∫øu ph·∫ßn c√≤n l·∫°i c√≥ t·ª´ kh√≥a ch∆∞∆°ng tr√¨nh -> lo·∫°i b·ªè
            show_keywords = ['intern', 'maknae', 'rebellion', 'king', 'show', 'program']
            if any(kw in remaining for kw in show_keywords):
                return False
        
        # Lo·∫°i b·ªè c√°c t√™n ch∆∞∆°ng tr√¨nh ngay c·∫£ khi kh√¥ng c√≥ ch·ªØ "idol" ·ªü ƒë·∫ßu
        show_names = ['intern king', 'maknae rebellion']
        if text_lower in show_names:
            return False
        # Ki·ªÉm tra xem c√≥ ch·ª©a t√™n ch∆∞∆°ng tr√¨nh kh√¥ng
        for show_name in show_names:
            if show_name in text_lower:
                return False
    
    # ============================================
    # LO·∫†I B·ªé ƒê·ªäA DANH CHUNG CHUNG
    # ============================================
    if entity_type in ['Artist', 'Group']:
        # Lo·∫°i b·ªè ƒë·ªãa danh nh∆∞ "Seoul", "San Francisco"
        if text_lower in LOCATION_NAMES:
            return False
        # Ki·ªÉm tra t·ª´ng t·ª´ c√≥ ph·∫£i ƒë·ªãa danh kh√¥ng
        if any(w in LOCATION_NAMES for w in words):
            return False
        # Lo·∫°i b·ªè pattern ƒë·ªãa danh H√†n Qu·ªëc d·∫°ng "X-gu", "X si", "X-do"
        if re.search(r'\b(?:gu|si|do)\b$', text_lower.replace('-', ' ')):
            return False
    
    # ============================================
    # LO·∫†I B·ªé PATTERN "HITS MR" HO·∫∂C T∆Ø∆†NG T·ª∞
    # ============================================
    if entity_type == 'Artist':
        # Lo·∫°i b·ªè pattern nh∆∞ "Hits Mr"
        if text_lower.startswith('hits ') or text_lower == 'hits mr':
            return False
    
    # ============================================
    # LO·∫†I B·ªé T√äN B·ªä C·∫ÆT C·ª§T TR√ôNG V·ªöI NODE G·ªêC
    # ============================================
    if entity_type == 'Artist':
        # Ki·ªÉm tra xem c√≥ ph·∫£i t√™n b·ªã c·∫Øt c·ª•t kh√¥ng (v√≠ d·ª•: "Shin Hye" vs "Park Shin-hye")
        # CHU·∫®N H√ìA entity text tr∆∞·ªõc khi check
        normalized_entity = clean_text(text)
        normalized_entity_lower = normalized_entity.lower()
        # N·∫øu entity l√† ph·∫ßn cu·ªëi c·ªßa m·ªôt node hi·ªán c√≥ -> lo·∫°i b·ªè
        for existing_name in existing_lower:
            # N·∫øu entity l√† ph·∫ßn cu·ªëi c·ªßa t√™n hi·ªán c√≥ (√≠t nh·∫•t 3 k√Ω t·ª±)
            if len(normalized_entity_lower) >= 3 and existing_name.endswith(normalized_entity_lower):
                # Ki·ªÉm tra xem c√≥ ph·∫£i t√™n b·ªã c·∫Øt c·ª•t kh√¥ng (kh√¥ng ph·∫£i tr√πng ho√†n to√†n)
                if existing_name != normalized_entity_lower and len(existing_name) > len(normalized_entity_lower):
                    # C√≥ th·ªÉ l√† t√™n b·ªã c·∫Øt c·ª•t -> lo·∫°i b·ªè
                    return False
    
    # ============================================
    # LO·∫†I B·ªé PATTERN "T√äN NH√ìM + T√äN TH√ÄNH VI√äN"
    # ============================================
    if entity_type == 'Artist':
        # Ki·ªÉm tra xem c√≥ ph·∫£i pattern "Group Name + Member Name" kh√¥ng
        # V√≠ d·ª•: "EXO Xiumin", "Girls' Generation Tiffany"
        for group_name in KNOWN_KPOP_GROUPS:
            if text_lower.startswith(group_name + ' '):
                # C√≥ th·ªÉ l√† "Group Name + Member Name"
                remaining = text_lower[len(group_name):].strip()
                if remaining and len(remaining) > 1:
                    # N·∫øu ph·∫ßn c√≤n l·∫°i l√† t√™n th√†nh vi√™n -> lo·∫°i b·ªè
                    return False
    
    # ============================================
    # LO·∫†I B·ªé T√äN B·ªä C·∫ÆT C·ª§T (CH·ªà C√ì 1 CH·ªÆ C√ÅI CU·ªêI)
    # ============================================
    if entity_type == 'Artist':
        # Ki·ªÉm tra pattern nh∆∞ "Block B P" (ch·ªâ c√≥ 1 ch·ªØ c√°i cu·ªëi)
        # Ho·∫∑c "Dani T-ara N4" (c√≥ th·ªÉ l√† t√™n b·ªã nh·∫ßm)
        words = text.split()
        if len(words) >= 2:
            last_word = words[-1]
            # N·∫øu t·ª´ cu·ªëi ch·ªâ c√≥ 1 ch·ªØ c√°i ho·∫∑c 1 ch·ªØ c√°i + s·ªë -> c√≥ th·ªÉ b·ªã c·∫Øt c·ª•t
            if len(last_word) == 1 or (len(last_word) == 2 and last_word[1].isdigit()):
                # Ki·ªÉm tra xem c√≥ ph·∫£i t√™n nh√≥m kh√¥ng
                prefix = ' '.join(words[:-1]).lower()
                if prefix in KNOWN_KPOP_GROUPS:
                    return False
            # Ki·ªÉm tra pattern "Name Group N4" ho·∫∑c t∆∞∆°ng t·ª±
            if len(words) >= 3:
                # V√≠ d·ª•: "Dani T-ara N4"
                if any(w.lower() in KNOWN_KPOP_GROUPS for w in words):
                    return False
    
    # Ki·ªÉm tra theo lo·∫°i
    if entity_type == 'Artist':
        if len(words) > 4:
            return False
        if any(w in INVALID_WORDS for w in words):
            return False
        # Lo·∫°i b·ªè pattern X.Y (2 ch·ªØ c√°i + d·∫•u ch·∫•m) nh∆∞ "T.O"
        if re.match(r'^[A-Z]\.[A-Z]\.?$', text):
            return False
        # Lo·∫°i b·ªè t√™n b·ªã c·∫Øt t·ª´ t√™n nh√≥m, v√≠ d·ª• "T ara" t·ª´ "T-ara"
        normalized = re.sub(r'[^a-z0-9]', '', text_lower)
        for group_name in KNOWN_KPOP_GROUPS:
            g_norm = re.sub(r'[^a-z0-9]', '', group_name)
            if normalized == g_norm and normalized != group_name:
                return False
        # T√™n ngh·ªá sƒ© th∆∞·ªùng c√≥ √≠t nh·∫•t 3 k√Ω t·ª± (tr·ª´ ngo·∫°i l·ªá)
        if len(text) < 3 and text.lower() not in valid_short_names:
            return False
            
    elif entity_type == 'Group':
        # Lo·∫°i b·ªè prefix l√† th·ªÉ lo·∫°i nh·∫°c ƒë·ª©ng tr∆∞·ªõc t√™n nh√≥m (v√≠ d·ª•: "Indie OKDAL", "K-pop Big Bang")
        # D√πng MUSIC_GENRES ƒë·ªÉ c·∫Øt b·ªè 1 ho·∫∑c nhi·ªÅu th·ªÉ lo·∫°i ·ªü ƒë·∫ßu, mi·ªÖn l√† c√≤n l·∫°i >= 1 t·ª´
        original_text = text
        while True:
            lowered = text.lower()
            stripped = lowered.lstrip()
            if stripped != lowered:
                # ƒê·ªìng b·ªô l·∫°i text n·∫øu c√≥ kho·∫£ng tr·∫Øng ƒë·∫ßu
                text = text[len(text) - len(stripped):]
                lowered = stripped
            # T√¨m genre prefix d√†i nh·∫•t kh·ªõp ·ªü ƒë·∫ßu
            genre_prefix = None
            for genre in sorted(MUSIC_GENRES, key=lambda g: -len(g)):
                if lowered.startswith(genre + ' ') and len(text.split()) > len(genre.split()):
                    genre_prefix = genre
                    break
            if not genre_prefix:
                break
            # C·∫Øt b·ªè genre prefix + kho·∫£ng tr·∫Øng
            cut_len = len(genre_prefix)
            text = text[cut_len:].lstrip()
        text_lower = text.lower()
        words = text_lower.split()

        if len(text) > 30 or text.count(' ') > 5:
            return False
        # T√™n nh√≥m th∆∞·ªùng c√≥ √≠t nh·∫•t 3 k√Ω t·ª±
        if len(text) < 3:
            return False
        # Kh√¥ng ph·∫£i thu·∫≠t ng·ªØ K-pop
        kpop_terms = {'k-pop', 'kpop', 'idol', 'chart', 'gaon', 'billboard'}
        if text_lower in kpop_terms:
            return False
        
        # ============================================
        # LO·∫†I B·ªé T√äN C√îNG TY (KH√îNG PH·∫¢I NH√ìM NH·∫†C)
        # ============================================
        company_names = {
            'warner bros', 'warner music', 'warner bros.', 'warner brothers',
            'sony music', 'sony entertainment', 'sony bmg',
            'universal music', 'universal music group', 'umg',
            'emi', 'emi music', 'capitol records',
            'atlantic records', 'columbia records', 'rca records',
            'interscope', 'def jam', 'republic records',
            'geffen records', 'virgin records', 'island records',
        }
        if text_lower in company_names:
            return False
        # Ki·ªÉm tra t·ª´ng ph·∫ßn c·ªßa t√™n c√≥ ph·∫£i c√¥ng ty kh√¥ng
        for company in company_names:
            if company in text_lower:
                return False
        
        # ============================================
        # LO·∫†I B·ªé C√ÇU M√î T·∫¢ (KH√îNG PH·∫¢I T√äN NH√ìM)
        # ============================================
        # C√°c ƒë·ªông t·ª´ th∆∞·ªùng c√≥ trong c√¢u m√¥ t·∫£
        sentence_verbs = [
            'drops', 'releases', 'announces', 'reveals', 'launches',
            'taps', 'hires', 'appoints', 'names', 'promotes',
            'signs', 'debuts', 'debut', 'debuting',
            'performs', 'sings', 'dances',
            'returns', 'confirms', 'denies', 'shares', 'posts',
            'being', 'breezes', 'bringing', 'hits',
        ]
        for verb in sentence_verbs:
            if f' {verb} ' in text_lower or text_lower.startswith(f'{verb} '):
                return False
        
        # Lo·∫°i b·ªè c√¢u b·∫Øt ƒë·∫ßu b·∫±ng ƒë·ªông t·ª´ (kh√¥ng ph·∫£i t√™n nh√≥m)
        first_word = words[0] if words else ''
        if first_word in sentence_verbs:
            return False

        # Lo·∫°i b·ªè c·ª•m t·ª´ ti·∫øng Vi·ªát th√¥ng d·ª•ng (kh√¥ng ph·∫£i t√™n ri√™ng), v√≠ d·ª•: "Sau khi", "Tr∆∞·ªõc khi"
        # N·∫øu t·∫•t c·∫£ c√°c t·ª´ ƒë·ªÅu n·∫±m trong INVALID_WORDS (t·ª´ ch·ª©c nƒÉng) th√¨ kh√¥ng ph·∫£i t√™n nh√≥m
        if len(words) >= 2 and all(w in INVALID_WORDS for w in words):
            return False
        
        # ============================================
        # LO·∫†I B·ªé C√ÇU C√ì D·∫§U NH√ÅY M·ªû KH√îNG ƒê√ìNG
        # ============================================
        # V√≠ d·ª•: "NewJeans drops 'Hype Boy" - c√≥ d·∫•u ' m·ªü nh∆∞ng kh√¥ng ƒë√≥ng
        if "'" in text and text.count("'") == 1:
            # C√≥ 1 d·∫•u nh√°y ƒë∆°n - c√≥ th·ªÉ l√† c√¢u b·ªã c·∫Øt c·ª•t
            return False
        if '"' in text and text.count('"') == 1:
            # C√≥ 1 d·∫•u nh√°y k√©p - c√≥ th·ªÉ l√† c√¢u b·ªã c·∫Øt c·ª•t
            return False
        
        # ============================================
        # LO·∫†I B·ªé SUFFIX C√îNG TY
        # ============================================
        company_suffixes = ['n.v', 'n.v.', 'inc', 'inc.', 'ltd', 'ltd.', 
                           'corp', 'corp.', 'llc', 'llc.', 'co.', 'plc']
        if text_lower in company_suffixes:
            return False
        # Lo·∫°i b·ªè n·∫øu k·∫øt th√∫c b·∫±ng suffix c√¥ng ty
        for suffix in company_suffixes:
            if text_lower.endswith(f' {suffix}'):
                return False
        
        # ============================================
        # LO·∫†I B·ªé T√äN NG∆Ø·ªúI (KH√îNG PH·∫¢I NH√ìM)
        # ============================================
        # Pattern "Taps David Blackman" ho·∫∑c "Firstname Lastname"
        # N·∫øu c√≥ t·ª´ "David", "Scott", "Michael"... c√≥ th·ªÉ l√† t√™n ng∆∞·ªùi
        common_western_names = {
            'david', 'scott', 'michael', 'john', 'james', 'robert', 'william',
            'richard', 'joseph', 'thomas', 'chris', 'daniel', 'mark', 'paul',
            'steven', 'kevin', 'brian', 'george', 'edward', 'ronald', 'anthony',
        }
        if any(name in text_lower for name in common_western_names):
            # C√≥ th·ªÉ l√† t√™n ng∆∞·ªùi ph∆∞∆°ng T√¢y, kh√¥ng ph·∫£i nh√≥m K-pop
            return False
        
        # ============================================
        # LO·∫†I B·ªé C√ÅC T√äN GROUP SAI / ROMANIZATION K·ª≤ L·∫† / C√ÇU VƒÇN
        # (T·ªêI ∆ØU CHO B·ªò D·ªÆ LI·ªÜU HI·ªÜN T·∫†I)
        # ============================================
        bad_group_texts = {
            # Nh√≥m n∆∞·ªõc ngo√†i / J-pop / non K-pop ho·∫∑c c√¢u vƒÉn
            'a.k.b. forty-eight', 'akb48 breezes through d',
            'beatles', 'being in hiatus right now',
            'girl next door', 'girl next',
            'daisokaku matsuri', 'declares debut in 2025',
            'doping panda', 'drippin on first full album',
            'exo-cbx hits no', 'garfunkel. sg wannabe',
            'kard talk tour', 'kep1er to debut on january 3rd',
            'k-pop blackpink', 'k-pop m3', 'kpop bts',
            'los angeles. txt', 'mbc chorus',
            'mum48',
            
            # Romanization/phi√™n √¢m ti·∫øng H√†n c·ªßa nh√≥m ƒë√£ c√≥ node chu·∫©n
            'aideul', 'akdong myujisyeon', 'aseuteuro',
            'beu-ah-geol', 'beureibeu geolseu',
            'bolbbalgan sachungi', 'bolbbalgan sachungi ',
            'hacheutuhacheu', 'hacheutuhacheu ',
            'pipeuti pipeuti', 'pipeuti pipeuti ',
            'geullaem ', 'reddo berubetto ',
            'aseuteuro ', 'aideul ',
            'tee -eks-tee',
            
            # M·∫£nh t√™n / t·ª´ chung chung / b·ªã c·∫Øt c·ª•t
            'btob (2012', 'berhad', 'bernad',
            'boram . t-ara', 'gen4', 'gb9 b',
            'honeydew', 'jebewon ', 'junsu',
            'labelle', 'lesserafim', 'mio', 'muses ',
            'ne1', 'next year', 'note', 'one ',
            'oh won bin', 'rd ', 'rglow ', 'record',
            'seung-hyun', 'shabet hay dalshabet',
            'take over the u', 'syupeo junieo', 'teurejeo', 'yeoja chingu',
            'ensiti', 'jebewon', 'reddo berubetto', 'shoo',
            # Vi·∫øt t·∫Øt kh√¥ng ƒë·∫ßy ƒë·ªß / t·ª´ b·ªã c·∫Øt
            'one', 'rd', 'rglow', 'muses', 'tpst',
            # T·ª´ chung chung
            # Nh√≥m nh·∫°c n∆∞·ªõc ngo√†i
            'the beatles', 'beatles',
            # B·ªï sung c√°c phi√™n √¢m / m·∫£ng t√™n sai m·ªõi ph√°t hi·ªán
            'k pop big bang',
            'a.k.b. forty eight', 'a.k.b. forty eight ',  # bi·∫øn th·ªÉ spacing
            'beu ah geol', 'beu ah geol ',
            'boram . t ara', 'boram . t-ara',
            # Soloist / ngh·ªá sƒ© kh√¥ng ph·∫£i nh√≥m
            'g-dragon', 'g dragon',
            # M·∫£nh t√™n nh√≥m b·ªã c·∫Øt c·ª•t
            'f ve',  # t·ª´ "F-ve Dolls" nh∆∞ng ch·ªâ c√≤n "F ve"
            # C√°c th·ª±c th·ªÉ kh√¥ng ph·∫£i group trong ƒë·ªì th·ªã c·ªßa b·∫°n
            'indie okdal y', 'indie okdal',  # c·ª•m "Indie OKDAL (Y.BIRD from Jellyfish...)"
            'jewelry 2001',                  # t√™n nh√≥m k√®m nƒÉm debut -> kh√¥ng ph·∫£i t√™n group ri√™ng
            'produce 101', 'produce 48',     # show tuy·ªÉn ch·ªçn, kh√¥ng ph·∫£i nh√≥m nh·∫°c
            'unchanging',                    # album "Unchanging", kh√¥ng ph·∫£i nh√≥m
        }
        if text_lower.strip() in bad_group_texts:
            return False
        
        # Lo·∫°i b·ªè t√™n group c√≥ ƒë√≠nh k√®m nƒÉm 19xx/20xx (Jewelry 2001, Fin.K.L 1998, ...)
        # Trong m·∫°ng l∆∞·ªõi c·ªßa b·∫°n, nƒÉm debut kh√¥ng ph·∫£i m·ªôt ph·∫ßn c·ªßa t√™n node group
        if re.search(r'\b(19|20)\d{2}\b', text_lower):
            return False
        
        # Lo·∫°i b·ªè c·ª•m c√≥ t·ª´ kh√≥a mang t√≠nh m√¥ t·∫£, kh√¥ng ph·∫£i t√™n ri√™ng group
        if any(kw in text_lower for kw in ['indie okdal', ' y.bird', ' y bird ']):
            return False
        
        # ============================================
        # LO·∫†I B·ªé GROUP B·∫ÆT ƒê·∫¶U B·∫∞NG "K POP" / "K-POP" / "KPOP"
        # ============================================
        # V√≠ d·ª•: "K pop Big Bang", "K-pop BTS", "Kpop Blackpink"
        if re.match(r'^k[\s\-]?pop\s+', text_lower):
            return False
        
        # ============================================
        # LO·∫†I B·ªé PHI√äN √ÇM TI·∫æNG ANH C·ª¶A T√äN NH√ìM (A.K.B. Forty Eight, etc.)
        # ============================================
        # Pattern: T√™n vi·∫øt t·∫Øt c√≥ d·∫•u ch·∫•m + t·ª´ ti·∫øng Anh (Forty, Eight, etc.)
        english_number_words = {'one', 'two', 'three', 'four', 'five', 'six', 'seven', 
                                'eight', 'nine', 'ten', 'eleven', 'twelve', 'thirteen',
                                'fourteen', 'fifteen', 'sixteen', 'seventeen', 'eighteen',
                                'nineteen', 'twenty', 'thirty', 'forty', 'fifty', 'sixty',
                                'seventy', 'eighty', 'ninety', 'hundred', 'thousand'}
        words_list = text_lower.split()
        if any(w in english_number_words for w in words_list):
            # C√≥ t·ª´ s·ªë ti·∫øng Anh -> c√≥ th·ªÉ l√† phi√™n √¢m nh∆∞ "A.K.B. Forty Eight"
            if '.' in text or len(words_list) >= 2:
                return False
        
        # ============================================
        # LO·∫†I B·ªé PATTERN "T√äN . T√äN NH√ìM" (Boram . T ara)
        # ============================================
        # Pattern: "T√™n ng∆∞·ªùi . T√™n nh√≥m" ho·∫∑c c√≥ d·∫•u ch·∫•m l·∫ª gi·ªØa c√°c t·ª´
        if re.search(r'\s+\.\s+', text):
            # C√≥ d·∫•u ch·∫•m ƒë∆∞·ª£c bao quanh b·ªüi kho·∫£ng tr·∫Øng -> kh√¥ng ph·∫£i t√™n nh√≥m h·ª£p l·ªá
            return False
        
        # ============================================
        # LO·∫†I B·ªé PHI√äN √ÇM TI·∫æNG H√ÄN D·∫†NG "BEU AH GEOL" (vi·∫øt hoa t·ª´ng √¢m ti·∫øt)
        # ============================================
        # Pattern: Nhi·ªÅu t·ª´ ng·∫Øn (2-4 k√Ω t·ª±), vi·∫øt hoa ƒë·∫ßu, c√≥ nguy√™n √¢m H√†n
        korean_syllable_vowels = ('eu', 'eo', 'ae', 'ui', 'eui', 'yeo', 'weo', 'oe', 'wo', 'wa', 'ya', 'ye', 'yo', 'yu')
        if len(words_list) >= 2:
            short_syllable_count = 0
            korean_vowel_count = 0
            for w in words_list:
                w_lower = w.lower()
                if len(w) <= 5:  # √Çm ti·∫øt ng·∫Øn
                    short_syllable_count += 1
                if any(v in w_lower for v in korean_syllable_vowels):
                    korean_vowel_count += 1
            # N·∫øu h·∫ßu h·∫øt c√°c t·ª´ ƒë·ªÅu ng·∫Øn v√† c√≥ nguy√™n √¢m H√†n -> phi√™n √¢m
            if short_syllable_count >= len(words_list) * 0.6 and korean_vowel_count >= 1:
                # Ki·ªÉm tra kh√¥ng ph·∫£i nh√≥m K-pop th·∫≠t
                if text_lower not in KNOWN_KPOP_GROUPS:
                    return False
        
        # Lo·∫°i th√™m c√°c phi√™n √¢m d·∫°ng "tee -eks-tee", "dee -ei-en" (ch·ªâ to√†n ch·ªØ th∆∞·ªùng + d·∫•u g·∫°ch)
        if re.search(r'\b[a-z]+\s*-\s*[a-z]+', text_lower):
            return False
        
        # ============================================
        # LO·∫†I B·ªé PHI√äN √ÇM TI·∫æNG H√ÄN (ROMAJA/LATINH H√ìA)
        # ============================================
        # Pattern ph·ªï bi·∫øn c·ªßa phi√™n √¢m H√†n Qu·ªëc:
        # - K·∫øt th√∫c b·∫±ng -eo, -eu, -ae, -ui, -eun, -eon
        # - C√≥ c√°c c·ª•m nguy√™n √¢m ƒë·∫∑c tr∆∞ng: eu, eo, ae, ui, eui
        # - Th∆∞·ªùng vi·∫øt li·ªÅn ho·∫∑c c√≥ kho·∫£ng c√°ch gi·ªØa c√°c √¢m ti·∫øt
        korean_romanization_patterns = [
            r'^[A-Z]?[a-z]*(?:eu|eo|ae|ui|eui)[a-z]*$',  # M·ªôt t·ª´ c√≥ nguy√™n √¢m H√†n
            r'^[A-Z]?[a-z]+(?:eo|eu)$',  # K·∫øt th√∫c b·∫±ng -eo ho·∫∑c -eu
            r'^[A-Z]?[a-z]+(?:eun|eon|eul)$',  # K·∫øt th√∫c b·∫±ng -eun, -eon, -eul
        ]
        # C√°c h·∫≠u t·ªë phi√™n √¢m H√†n ph·ªï bi·∫øn
        korean_suffixes = ('eo', 'eu', 'eun', 'eon', 'eul', 'eung')
        # N·∫øu l√† m·ªôt t·ª´ ƒë∆°n (kh√¥ng c√≥ kho·∫£ng tr·∫Øng) v√† k·∫øt th√∫c b·∫±ng suffix H√†n
        if ' ' not in text and text_lower.endswith(korean_suffixes):
            # Lo·∫°i tr·ª´ c√°c t·ª´ ti·∫øng Anh h·ª£p l·ªá
            english_exceptions = {'neo', 'stereo', 'romeo', 'video', 'cameo'}
            if text_lower not in english_exceptions:
                return False
        
        # Ph√°t hi·ªán pattern phi√™n √¢m 2+ √¢m ti·∫øt vi·∫øt hoa ƒë·∫ßu (Syupeo Junieo, Teurejeo)
        # N·∫øu c√≥ nhi·ªÅu t·ª´ v√† m·ªói t·ª´ ƒë·ªÅu c√≥ pattern nguy√™n √¢m H√†n
        words_in_text = text.split()
        if len(words_in_text) >= 1:
            korean_vowel_combos = ('eu', 'eo', 'ae', 'ui', 'eui', 'yeo', 'weo')
            romanization_word_count = 0
            for word in words_in_text:
                word_lower = word.lower()
                if any(combo in word_lower for combo in korean_vowel_combos):
                    romanization_word_count += 1
            # N·∫øu t·∫•t c·∫£ c√°c t·ª´ ƒë·ªÅu c√≥ nguy√™n √¢m H√†n -> c√≥ th·ªÉ l√† phi√™n √¢m
            if romanization_word_count == len(words_in_text) and len(words_in_text) <= 3:
                # Ki·ªÉm tra th√™m: kh√¥ng ph·∫£i c√°c nh√≥m K-pop th·ª±c s·ª± vi·∫øt theo ki·ªÉu n√†y
                known_valid = {'aespa', 'neo', 'exo'}  
                if text_lower not in known_valid:
                    return False
        
        # ============================================
        # LO·∫†I B·ªé PATTERN "NH√ìM + TH√ÄNH VI√äN"
        # ============================================
        # V√≠ d·ª•: "Blackpink Jennie" kh√¥ng ph·∫£i l√† t√™n nh√≥m
        for group_name in KNOWN_KPOP_GROUPS:
            if text_lower.startswith(group_name + ' '):
                # C√≥ th·ªÉ l√† "Group Name + Member Name"
                remaining = text_lower[len(group_name):].strip()
                if remaining and len(remaining) > 1:
                    return False
        
        # ============================================
        # LO·∫†I B·ªé NH√ìM NH·∫†C N∆Ø·ªöC NGO√ÄI (KH√îNG PH·∫¢I K-POP)
        # ============================================
        non_kpop_groups = {
            'chopstick brothers',  # Nh√≥m Trung Qu·ªëc
            'jonas brothers',      # Nh√≥m M·ªπ
            'backstreet boys',     # Nh√≥m M·ªπ
            'one direction',       # Nh√≥m Anh
            'westlife',            # Nh√≥m Ireland
            'nsync', "n'sync",     # Nh√≥m M·ªπ
        }
        if text_lower in non_kpop_groups:
            return False
        
        # ============================================
        # LO·∫†I B·ªé T√äN B·ªä C·∫ÆT C·ª§T (VI·∫æT T·∫ÆT KH√îNG ƒê·∫¶Y ƒê·ª¶)
        # ============================================
        # V√≠ d·ª•: "S.E" (t·ª´ S.E.S.), "T.O" (t·ª´ T.O.P)
        # Pattern: 1-2 ch·ªØ c√°i + d·∫•u ch·∫•m, nh∆∞ng kh√¥ng ph·∫£i t√™n ƒë·∫ßy ƒë·ªß
        if re.match(r'^[A-Z]\.[A-Z]$', text) and len(text) == 3:
            # Ki·ªÉm tra xem c√≥ ph·∫£i t√™n ƒë·∫ßy ƒë·ªß kh√¥ng
            valid_short_groups = {'s.e.s', 'h.o.t', 'n.r.g'}
            if text_lower not in valid_short_groups:
                return False
        # Lo·∫°i b·ªè pattern X.Y (2 ch·ªØ c√°i + 1 d·∫•u ch·∫•m ·ªü gi·ªØa)
        if re.match(r'^[A-Z]\.[A-Z]\.?$', text):
            return False
            
    elif entity_type in ['Album', 'Song']:
        if len(text) > 40:
            return False
        # Album/Song th∆∞·ªùng c√≥ √≠t nh·∫•t 4 k√Ω t·ª± (lo·∫°i b·ªè t·ª´ qu√° ng·∫Øn nh∆∞ "Act", "Again")
        if len(text) < 4:
            return False
        
        # ============================================
        # LO·∫†I B·ªé THU·∫¨T NG·ªÆ CHUNG / T·ª™ LI√äN QUAN B·∫¢NG X·∫æP H·∫†NG / KH√îNG PH·∫¢I ALBUM
        # ============================================
        chart_terms = {
            'chart', 'gaon', 'oricon', 'billboard', 'sales', 'vol', 'mr',
            'cover', 'remix', 'intro', 'outro', 'interlude',
            # T·ªï ch·ª©c/b·∫£ng x·∫øp h·∫°ng li√™n quan K-pop
            'miak',  # Music Industry Association of Korea
        }
        if text_lower in chart_terms:
            return False
        
        # Lo·∫°i b·ªè pattern "Chart + nƒÉm/s·ªë" nh∆∞ "Chart 2022", "Chart 20"
        if re.match(r'^chart\s*\d+', text_lower):
            return False
        
        # Lo·∫°i b·ªè pattern b·∫Øt ƒë·∫ßu b·∫±ng "Top + s·ªë" (Top 40, Top 100...)
        if re.match(r'^top\s+\d+', text_lower):
            return False
        
        # Lo·∫°i b·ªè t√™n c√≥ c·∫£ "miak" v√† "kpop/k-pop/k pop" (MIAK K-pop chart)
        if 'miak' in text_lower and ('k pop' in text_lower or 'k-pop' in text_lower or 'kpop' in text_lower):
            return False

        # Lo·∫°i b·ªè c√°c album t·ªïng h·ª£p/best-of chung chung (Best of, Best Selection, Best Album, Compilation)
        # v√≠ d·ª•: "BEST OF CNBLUE", "Best Selection 2010", "Best of Album"
        compilation_phrases = [
            'best of ', ' best of', 'best selection', 'greatest hits',
            'best album', 'best single', 'best collection',
        ]
        if any(phrase in text_lower for phrase in compilation_phrases):
            # Tuy nhi√™n v·∫´n cho qua n·∫øu t√™n qu√° c·ª• th·ªÉ (c√≥ t√™n nh√≥m r√µ r√†ng v√† b·∫°n mu·ªën gi·ªØ)
            # ·ªû ƒë√¢y ∆∞u ti√™n an to√†n: lo·∫°i b·ªè ƒë·ªÉ tr√°nh nh·∫ßm v·ªõi danh m·ª•c/playlist/gi·∫£i th∆∞·ªüng
            return False
        
        # Lo·∫°i b·ªè t√™n b·ªã c·∫Øt c·ª•t ki·ªÉu "U KISS cho" (c·ª•m ti·∫øng Vi·ªát "cho" ·ªü cu·ªëi)
        if text_lower.endswith(' cho'):
            return False
        
        # Lo·∫°i b·ªè c√°c c·ª•m r√µ r√†ng l√† m√¥ t·∫£ J-pop / nh√≥m Nh·∫≠t, kh√¥ng ph·∫£i album K-pop
        jpop_keywords_in_album = ['akb48', 'morning musume', 'musume']
        if any(kw in text_lower for kw in jpop_keywords_in_album):
            return False
        
        # ============================================
        # LO·∫†I B·ªé T·ª™ ƒê∆†N CHUNG CHUNG (KH√îNG ƒê·ª¶ ƒê·∫∂C TR∆ØNG ƒê·ªÇ L√Ä T√äN ALBUM)
        # ============================================
        # CH√ö √ù: M·ªôt s·ªë t·ª´ nh∆∞ "Tonight", "Always", "Alive", "Blue" l√† t√™n album K-pop th·∫≠t
        # Ch√∫ng ƒë√£ ƒë∆∞·ª£c l·ªçc b·ªüi pattern matching context-aware, n√™n b·ªè kh·ªèi blacklist
        generic_single_words = {
            'act', 'again', 'chain', 'cover', 'dreaming', 'sorry', 'love', 'heart',
            'step', 'dance', 'night', 'day', 'fire', 'water', 'star', 'moon', 'sun',
            'world', 'life', 'time', 'dream', 'hope', 'light', 'dark',  # B·ªè: blue, red, black, white, pink
            'gold', 'silver', 'sweet', 'crazy', 'happy',
            'sad', 'bad', 'good', 'new', 'old', 'young', 'wild', 'free',  # B·ªè: alive
            'forever', 'never', 'maybe', 'baby', 'honey', 'angel', 'devil',  # B·ªè: always
            'hero', 'power', 'magic', 'fantasy', 'miracle', 'secret', 'mystery',
            'story', 'memory', 'moment', 'feeling', 'emotion', 'passion', 'desire',
            'title', 'song', 'track', 'album', 'single', 'debut', 'comeback',
            'returns', 'youth', 'access', 'wings',  # B·ªè: tonight, solar
            'solo', 'champion', 'crown',  # C√°c t·ª´ ƒë√£ th√™m tr∆∞·ªõc ƒë√≥
        }
        if text_lower in generic_single_words:
            return False
        
        # ============================================
        # CHO PH√âP C√ÅC T√äN ALBUM/SONG K-POP ƒê√É BI·∫æT (1 T·ª™)
        # ============================================
        # Nh·ªØng t√™n album/b√†i h√°t K-pop n·ªïi ti·∫øng ch·ªâ c√≥ 1 t·ª´
        known_kpop_album_song_names = {
            # Big Bang albums
            'tonight', 'alive', 'always', 'remember', 'made',
            # BTS albums
            'wings', 'proof',
            # BLACKPINK songs/albums
            'pink', 'born',
            # Other common K-pop album/song names (1 word, vi·∫øt hoa)
            'blue', 'red', 'noir', 'neon', 'fever', 'bloom', 
            'lilac', 'palette', 'yellow', 'violet',
            # Th√™m c√°c t√™n ƒë·∫∑c bi·ªát
            'solar',  # MAMAMOO member nh∆∞ng c≈©ng l√† album name pattern
        }
        # N·∫øu l√† t√™n ƒë√£ bi·∫øt c·ªßa K-pop, CHO PH√âP
        if text_lower in known_kpop_album_song_names:
            return True  # Bypass c√°c filter c√≤n l·∫°i
        
        # ============================================
        # LO·∫†I B·ªé T√äN NGH·ªÜ Sƒ® B·ªä NH·∫¶M L√Ä ALBUM
        # ============================================
        # M·ªôt s·ªë t√™n ngh·ªá sƒ© K-pop c√≥ th·ªÉ b·ªã nh·∫ßm l√† album
        artist_names_not_album = {
            'solar', 'moonbyul', 'wheein', 'hwasa',  # MAMAMOO members
            'irene', 'seulgi', 'wendy', 'joy', 'yeri',  # Red Velvet members
            'taeyeon', 'tiffany', 'jessica', 'sunny', 'yoona', 'sooyoung', 'yuri', 'hyoyeon', 'seohyun',  # SNSD
        }
        if text_lower in artist_names_not_album:
            return False
        
        # ============================================
        # LO·∫†I B·ªé PATTERN B·ªä C·∫ÆT C·ª§T / C√ÇU VƒÇN
        # ============================================
        # Pattern "By Step", "Your Head Down" - b·ªã c·∫Øt t·ª´ t√™n d√†i h∆°n
        truncated_patterns = [
            r'^by\s+',               # "By Step" t·ª´ "Step By Step"
            r'^your\s+',             # "Your Head Down" t·ª´ "Keep Your Head Down"
            r'^the\s+\w+$',          # "The End" qu√° ng·∫Øn (ch·ªâ 2 t·ª´)
            r'^my\s+\w+$',           # "My Love" qu√° ng·∫Øn
            r'^our\s+\w+$',          # "Our Story" qu√° ng·∫Øn
            r'\s+pt\.?$',            # K·∫øt th√∫c b·∫±ng "Pt" ho·∫∑c "Pt." - b·ªã c·∫Øt
        ]
        for pattern in truncated_patterns:
            if re.match(pattern, text_lower):
                return False
        # Lo·∫°i b·ªè n·∫øu k·∫øt th√∫c b·∫±ng "Pt" (b·ªã c·∫Øt t·ª´ "Pt. 1", "Pt. 2")
        if text_lower.endswith(' pt') or text_lower.endswith(' pt.'):
            return False
        
        # ============================================
        # LO·∫†I B·ªé C√ÇU VƒÇN / M√î T·∫¢ (KH√îNG PH·∫¢I T√äN ALBUM)
        # ============================================
        # Pattern c√≥ ƒë·ªông t·ª´ ho·∫∑c c·∫•u tr√∫c c√¢u
        sentence_indicators = [
            r"exceeds\s+\d+",        # "Fearless' exceeds 380"
            r"has\s+now\s+hit",      # "Has Now Hit No"
            r"hits?\s+no\.?\s*\d*",  # "Hits No 1"
            r"reaches?\s+\d+",       # "Reaches 100"
            r"sells?\s+\d+",         # "Sells 1 Million"
            r"debuts?\s+at",         # "Debuts At No"
            r"peaks?\s+at",          # "Peaks At No"
            r"chart\s*\d+",          # "Chart 2022"
            r"kor\s+down",           # "KOR Down"
            r"title\s+song",         # "Title Song"
            r"love\s+day\s+\d+",     # "Love Day 2012 Jung Eunji"
            r"miak\s+k-?pop",        # "MIAK K-pop"
            r"ranking[s]?\s+\w+\s+\d+",  # "Ranking February 19", "Rankings April 10"
            r"sales\s+chart",        # "Sales Chart", "Sales Chart as Tom Petty"
            r"as\s+tom\s+petty",     # "... as Tom Petty"
            r"already\s+at\s+\d+",   # "Already at 150"
            r"award\s+for",          # "Award for 5 Consecutive Years"
            r"consecutive\s+years",  # "... Consecutive Years"
            r"authentic.*takes",     # "BE 'authentic' but takes 'few risks"
            r"but\s+takes",          # "... but takes ..."
            r"few\s+risks",          # "... few risks"
            r"preview\s+released",   # "Beam of Prism' preview released"
            r"surpasses?\s+\d+",     # "Blue Hour' surpasses 300"
            r"chart\s*-\s*\w+",      # "Chart - Annual", "Chart - Week 13"
            r"chart\s*-\s*week",     # "Chart - Week XX"
            r"charts?\s*-\s*\w+",    # "Charts - July", "Charts - September"
            r"chart\s+dated",        # "Chart dated February 1"
            r"chart\s+for\s+week",   # "Chart for Week ending November 23"
            r"chart\s+from",         # "Chart from September 6-12"
            r"chart\s+in\s+\w+",     # "Chart in November"
            r"to\s+be\s+released",   # "Chat-shire' to be released on October 23"
            r"released\s+on\s+\w+",  # "... released on October 23"
            r"pre-?order\s+begins",  # "IM HERO' pre-order begins"
            r"kicks\s+off",          # "Kicks Off With 'Freal Luv' Video ft"
            r"in\s+sales\s+with",    # "King in Sales with 400"
            r"ranking\s+as\s+of",    # "Ranking as of November 20"
            r"ranking\s+for\s+\w+",  # "Ranking for February 21"
            r"ranking\s+on\s+\w+",   # "Ranking on January 30"
            r"ranks?\s+no",          # "Ranks No"
            r"on\s+march\s+\d+",     # "Ruby on March 7"
            r"on\s+\w+\s+\d+",       # "... on October 23"
            r"top-?\d+\s+uge",       # "Top-40 Uge 38"
            r"label\s+notes?\s+ref", # "Label Notes Ref"
            r"up-?and-?coming",      # "Up-and-coming girls..."
            r"kpop\s+week\s+\d+",    # "KPOP Week 25"
            r"chart\s+week\s+\d+",   # "Chart Week 24"
            r"sold\s+more\s+than",   # "DYE' Sold More Than 280"
            r"\s+sau\s+khi",         # "Dear Santa sau khi" - c√≥ t·ª´ ti·∫øng Vi·ªát
            r"tracklist\s+\d+",      # "Hear Things tracklist 1"
            r"is\s+an?\s+\w+ing",    # "Is an Inviting"
            r"k-?pop\s+miak",        # "K-pop MIAK"
            r"releases?\s+today",     # "Producer releases today"
            r"releases?\s+tomorrow",  # "... releases tomorrow"
            r"releases?\s+on\s+\w+", # "... releases on ..."
            r"producer\s+releases?",  # "Producer releases ..."
            r"on\s+why",              # "... on Why New 'Holler' EP Represents..."
            r"represents?\s+their",    # "... Represents Their 'Mind, Body and Soul'"
            r"represents?\s+",        # "... Represents ..."
        ]
        for pattern in sentence_indicators:
            if re.search(pattern, text_lower):
                return False
        
        # ============================================
        # LO·∫†I B·ªé C√ÇU VƒÇN B·∫ÆT ƒê·∫¶U B·∫∞NG DANH T·ª™ + ƒê·ªòNG T·ª™
        # ============================================
        # Pattern: "Producer releases today", "Album drops tomorrow"
        sentence_starters = ['producer', 'album', 'single', 'ep', 'song', 'track']
        if text_lower.split()[0] in sentence_starters:
            # Ki·ªÉm tra xem c√≥ ƒë·ªông t·ª´ kh√¥ng
            if any(verb in text_lower for verb in ['releases', 'release', 'drops', 'drop', 'comes', 'come', 'arrives', 'arrive']):
                return False
        
        # ============================================
        # LO·∫†I B·ªé T√äN B·ªä C·∫ÆT C·ª§T (K·∫æT TH√öC B·∫∞NG "VOL", "FIN", ETC.)
        # ============================================
        truncated_suffixes = [' vol', ' fin', ' pt', ' cmb', ' ver', ' o', ' d', " don", " don'"]
        for suffix in truncated_suffixes:
            if text_lower.endswith(suffix):
                return False
        
        # Lo·∫°i b·ªè pattern b·ªã c·∫Øt c·ª•t ph·ªï bi·∫øn
        # "I Don" t·ª´ "I Don't...", "As If It" t·ª´ "As If It's Your Last", "Yes I" t·ª´ "Yes I Am"
        truncated_patterns = [
            r"^i don$",              # "I Don" t·ª´ "I Don't..."
            r"^baby don$",           # "Baby don" t·ª´ "Baby don't..."
            r"^as if it$",           # "As If It" t·ª´ "As If It's Your Last"
            r"^yes i$",              # "Yes I" t·ª´ "Yes I Am"
            r"^coup d$",             # "Coup d" t·ª´ "Coup d'Etat"
            r"\w+ don$",             # B·∫•t k·ª≥ t·ª´ n√†o k·∫øt th√∫c b·∫±ng " don"
        ]
        for pattern in truncated_patterns:
            if re.match(pattern, text_lower):
                return False
        
        # ============================================
        # LO·∫†I B·ªé PATTERN "VERSE + S·ªê"
        # ============================================
        # "Verse 2" - kh√¥ng ph·∫£i album, l√† ph·∫ßn c·ªßa album
        if re.match(r'^verse\s+\d+$', text_lower):
            return False
        
        # ============================================
        # LO·∫†I B·ªé T√äN C√ì D·∫§U NH√ÅY L·∫∫ + T√äN TRANG WEB
        # ============================================
        # "Red Light' Allkpop" - c√≥ d·∫•u nh√°y l·∫ª + t√™n trang web
        website_names = ['allkpop', 'soompi', 'koreaboo', 'billboard', 'genius']
        if "'" in text:
            # C√≥ d·∫•u nh√°y ƒë∆°n
            for website in website_names:
                if website in text_lower:
                    return False
        
        # ============================================
        # LO·∫†I B·ªé T√äN N·ªÄN T·∫¢NG / D·ªäCH V·ª§
        # ============================================
        platform_names = {'itunes', 'spotify', 'melon', 'genie', 'bugs', 'flo'}
        if text_lower in platform_names:
            return False
        
        # ============================================
        # LO·∫†I B·ªé VI·∫æT T·∫ÆT KH√îNG R√ï R√ÄNG
        # ============================================
        abbreviation_patterns = [
            r'^jpn\s+\w+$',          # "JPN Cmb"
            r'^kor\s+\w+$',          # "KOR ..."
            r'^eng\s+\w+$',          # "ENG ..."
        ]
        for pattern in abbreviation_patterns:
            if re.search(pattern, text_lower):
                return False
        
        # ============================================
        # LO·∫†I B·ªé T√äN TH√ÄNH VI√äN K-POP B·ªä NH·∫¶M L√Ä ALBUM
        # ============================================
        kpop_member_names = {
            'jeonghan', 'wonwoo', 'mingyu', 'seungkwan', 'vernon', 'dino',  # Seventeen
            'gigi', 'bella',  # T√™n ng∆∞·ªùi n·ªïi ti·∫øng kh√°c
            'minkyeung', 'nayoung', 'kyulkyung', 'eunwoo', 'roa', 'yuha', 'rena', 'kyla', 'sungyeon',  # Pristin
        }
        if text_lower in kpop_member_names:
            return False
        
        # ============================================
        # LO·∫†I B·ªé T·ª™ CHUNG CHUNG KH√ÅC (ch·ªâ nh·ªØng t·ª´ r√µ r√†ng kh√¥ng ph·∫£i album)
        # ============================================
        generic_album_words = {
            'group note', 'notes ref',
            'makestar',  # T√™n n·ªÅn t·∫£ng crowdfunding
        }
        if text_lower in generic_album_words:
            return False
        
        # ============================================
        # LO·∫†I B·ªé PATTERN C√ì D·∫§U NH√ÅY L·∫∫ + NƒÇM
        # ============================================
        # "CRUSH' 2014" - c√≥ d·∫•u nh√°y l·∫ª
        if re.search(r"'\s*\d{4}$", text):
            return False
        
        # ============================================
        # LO·∫†I B·ªé T√äN CH∆Ø∆†NG TR√åNH / LIVE
        # ============================================
        if 'countdown live' in text_lower or 'live concert' in text_lower:
            return False
        
        # ============================================
        # LO·∫†I B·ªé TH√îNG TIN CHART (ORICON + S·ªê)
        # ============================================
        if re.search(r'^oricon\s+\d+', text_lower):
            return False
        
        # ============================================
        # LO·∫†I B·ªé PATTERN "T√äN + S·ªê TH·ª® H·∫†NG" (chart positions)
        # ============================================
        # Pattern nh∆∞ "Crayon 16 1", "DDARA 12 1", "Feel me 17 1"
        # Th∆∞·ªùng l√†: T√™n b√†i + v·ªã tr√≠ chart + tu·∫ßn
        if re.search(r'\s+\d+\s+\d+$', text):
            return False
        # Pattern k·∫øt th√∫c b·∫±ng "s·ªë 1" ho·∫∑c "s·ªë s·ªë"
        if re.search(r'\s+\d{1,3}\s+1$', text):
            return False
        
        # ============================================
        # LO·∫†I B·ªé PATTERN VI·∫æT T·∫ÆT CHART
        # ============================================
        chart_abbreviations = [
            r'^gaon\s+',             # "Gaon 151", "Gaon khi"
            r'^hq\s+',               # "HQ Down", "HQ Gaon TQ Baidu"
            r'\s+hq\s+',             # "... HQ ..."
            r'^tq\s+',               # "TQ Baidu"
            r'\s+tq\s+',             # "... TQ ..."
            r'baidu',                # "... Baidu"
        ]
        for pattern in chart_abbreviations:
            if re.search(pattern, text_lower):
                return False
        
        # ============================================
        # LO·∫†I B·ªé T√äN C√îNG TY B·ªä NH·∫¶M L√Ä ALBUM
        # ============================================
        company_patterns = [
            r's\.?m\.?\s+entertainment',  # "S.M Entertainment Co"
            r'entertainment\s+co',
            r'yg\s+entertainment',
            r'jyp\s+entertainment',
            r'hybe\s+',
        ]
        for pattern in company_patterns:
            if re.search(pattern, text_lower):
                return False
        
        # ============================================
        # LO·∫†I B·ªé T√äN NH√ìM + T·ª™ L·∫∫
        # ============================================
        # Pattern "U-KISS cho", "BTS v√†", "EXO v·ªõi"
        group_plus_word = [
            r'^u-kiss\s+\w{1,4}$',    # "U-KISS cho"
            r'^bts\s+\w{1,4}$',
            r'^exo\s+\w{1,4}$',
            r'^nct\s+\w{1,4}$',
        ]
        for pattern in group_plus_word:
            if re.search(pattern, text_lower):
                return False
        
        # ============================================
        # LO·∫†I B·ªé PATTERN UNLOCK/EP L·∫™N L·ªòN
        # ============================================
        # "Unlock UNIQ EP Falling In Love" - nhi·ªÅu album g·ªôp l·∫°i
        if 'unlock' in text_lower and 'ep' in text_lower:
            return False
        if text.count(' ') >= 4 and ('EP' in text or 'Album' in text):
            # Qu√° nhi·ªÅu t·ª´ v√† c√≥ EP/Album trong t√™n -> c√≥ th·ªÉ l√† l·ªói
            return False
        
        # ============================================
        # LO·∫†I B·ªé T√äN C√ì CH·ª®A T√äN NGH·ªÜ Sƒ®/NH√ìM NH·∫†C L·∫™N L·ªòN
        # ============================================
        # Pattern "Album Name + Artist Name" nh∆∞ "Beep BTOB Yoojin"
        kpop_group_names_in_album = ['btob', 'exo', 'bts', 'nct', 'got7', 'ikon', 'winner', 'ateez', 'stray kids']
        for group in kpop_group_names_in_album:
            if group in text_lower and len(text.split()) >= 2:
                # C√≥ t√™n nh√≥m trong t√™n album v√† c√≥ nhi·ªÅu t·ª´ -> c√≥ th·ªÉ l√† l·ªói
                words_after_group = text_lower.split(group)[-1].strip()
                if words_after_group and len(words_after_group) > 2:
                    return False
        
        # ============================================
        # LO·∫†I B·ªé T√äN NH√ìM NH·∫†C B·ªä NH·∫¶M L√Ä ALBUM
        # ============================================
        group_names_not_album = {
            'april', 'twice', 'blackpink', 'bts', 'exo', 'nct', 'red velvet',
            'mamamoo', 'itzy', 'aespa', 'ive', 'newjeans', 'le sserafim',
            'stayc', 'nmixx', 'kep1er', 'gidle', 'everglow', 'loona',
        }
        if text_lower in group_names_not_album:
            return False
        
        # ============================================
        # LO·∫†I B·ªé T√äN NG∆Ø·ªúI (KH√îNG PH·∫¢I ALBUM)
        # ============================================
        # Pattern "Firstname Lastname" v·ªõi t√™n ph∆∞∆°ng T√¢y
        western_names = {
            'danny', 'chung', 'david', 'scott', 'michael', 'john', 'james', 
            'robert', 'william', 'richard', 'joseph', 'thomas', 'chris', 
            'daniel', 'mark', 'paul', 'steven', 'kevin', 'brian', 'george',
            'jung', 'eunji', 'kim', 'lee', 'park', 'choi', 'kang',
        }
        words_in_album = text_lower.split()
        # N·∫øu t·∫•t c·∫£ c√°c t·ª´ ƒë·ªÅu l√† t√™n ng∆∞·ªùi -> kh√¥ng ph·∫£i album
        if len(words_in_album) >= 2 and all(w in western_names for w in words_in_album):
            return False
        # N·∫øu c√≥ t√™n + nƒÉm -> c√≥ th·ªÉ l√† l·ªói
        if re.search(r'\b\d{4}\b.*[A-Z][a-z]+', text) or re.search(r'[A-Z][a-z]+.*\b\d{4}\b', text):
            # C√≥ nƒÉm trong t√™n album -> ki·ªÉm tra th√™m
            if any(name in text_lower for name in ['jung', 'eunji', 'kim', 'lee', 'park']):
                return False
        
        # ============================================
        # LO·∫†I B·ªé T·ª™ VI·∫æT T·∫ÆT / THU·∫¨T NG·ªÆ √ÇM NH·∫†C
        # ============================================
        music_abbreviations = {
            'all out', 'kor down', 'jpn', 'usa', 'uk', 'eng', 'chn', 'twn',
            'mv', 'pv', 'ost', 'bgm', 'inst', 'ver', 'version',
        }
        if text_lower in music_abbreviations:
            return False
            
    elif entity_type == 'Company':
        company_kw = ['entertainment', 'music', 'media', 'records', 'label']
        if not any(kw in text_lower for kw in company_kw):
            if len(text) > 20 or not text[0].isupper():
                return False
    
    return True

# =====================================================
# PATTERNS NER (M·ªû R·ªòNG ƒê·ªÇ B·∫ÆT NHI·ªÄU TH·ª∞C TH·ªÇ H∆†N)
# =====================================================
patterns = {
    'Artist': [
        # Pattern c∆° b·∫£n
        r'(?:ca sƒ©|ngh·ªá sƒ©|rapper|idol|th·∫ßn t∆∞·ª£ng|th√†nh vi√™n)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s+(?:l√†|sinh|ƒë√£|ƒë∆∞·ª£c|c√≥)|\,|\.|$)',
        r'([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s+(?:l√† m·ªôt|l√†)\s+(?:ca sƒ©|ngh·ªá sƒ©|rapper|idol)',
        # Th√†nh vi√™n nh√≥m: "th√†nh vi√™n G-Dragon v√† T.O.P"
        r'th√†nh vi√™n\s+([A-Z][a-zA-Z0-9\-\.]+)(?:\s+v√†|\s*,)',
        # Solo artist: "G-Dragon ph√°t h√†nh album solo"
        r'([A-Z][a-zA-Z0-9\-\.]+)\s+ph√°t h√†nh\s+(?:album|EP|single)\s+solo',
        # "do X vi·∫øt l·ªùi" - nh·∫°c sƒ©
        r'do\s+(?:ch√≠nh\s+)?([A-Z][a-zA-Z0-9\-\.]+)\s+(?:vi·∫øt|s√°ng t√°c|s·∫£n xu·∫•t)',
        # "X tham gia" - ngh·ªá sƒ©
        r'([A-Z][a-zA-Z0-9\-\.]+)\s+(?:tham gia|h·ª£p t√°c|g√≥p m·∫∑t|vi·∫øt l·ªùi)',
        # "th√†nh vi√™n Verbal c·ªßa M-Flo" pattern
        r'th√†nh vi√™n\s+([A-Z][a-zA-Z0-9\-\.]+)\s+c·ªßa',
    ],
    'Group': [
        r'(?:nh√≥m nh·∫°c|ban nh·∫°c|group|boyband|girlgroup)\s+([A-Z][a-zA-Z0-9\s\-\'\.()]+?)(?:\s+(?:l√†|g·ªìm|c√≥|ƒë∆∞·ª£c|ra m·∫Øt)|\,|\.|$)',
        r'([A-Z][a-zA-Z0-9\s\-\'\.()]+?)\s+(?:l√† m·ªôt|l√†)\s+(?:nh√≥m nh·∫°c|ban nh·∫°c)',
        # "nh√≥m X tr·ªü l·∫°i", "nh√≥m X ph√°t h√†nh"
        r'nh√≥m\s+([A-Z][a-zA-Z0-9\s\-\'\.()]+?)\s+(?:tr·ªü l·∫°i|ph√°t h√†nh|ra m·∫Øt|bi·ªÉu di·ªÖn)',
        # "c·ªßa nh√≥m nh·∫°c nam H√†n Qu·ªëc Big Bang" - r·∫•t ph·ªï bi·∫øn trong Wikipedia
        r'c·ªßa\s+nh√≥m\s+nh·∫°c\s+(?:nam|n·ªØ)?\s*(?:H√†n\s+Qu·ªëc|H√†n‚ÄìTrung\s+Qu·ªëc)?\s*([A-Z][a-zA-Z0-9\s\-\'\.()]+?)(?:\s*[,\.]|\s+(?:ƒë∆∞·ª£c|do|l√†|bao g·ªìm))',
        # "c·ªßa ban nh·∫°c H√†n Qu·ªëc Big Bang"
        r'c·ªßa\s+ban\s+nh·∫°c\s+(?:H√†n\s+Qu·ªëc)?\s*([A-Z][a-zA-Z0-9\s\-\'\.()]+?)(?:\s*[,\.]|\s+(?:ƒë∆∞·ª£c|do|l√†))',
        # "nh√≥m nh·∫°c nam H√†n Qu·ªëc X" - ngay sau ƒë·ªãnh nghƒ©a
        r'nh√≥m\s+nh·∫°c\s+(?:nam|n·ªØ)?\s*(?:H√†n\s+Qu·ªëc|H√†n‚ÄìTrung\s+Qu·ªëc)?\s+([A-Z][a-zA-Z0-9\s\-\'\.()]+?)(?:\s*[,\.]|\s+(?:ƒë∆∞·ª£c|do|l√†|g·ªìm|bao g·ªìm|th√†nh l·∫≠p))',
        # "nh√≥m nh·ªè X c·ªßa" - subgroup
        r'nh√≥m\s+nh·ªè\s+(?:ch√≠nh\s+th·ª©c)?\s*([A-Z][a-zA-Z0-9\s\-\'\.()]+?)\s+c·ªßa',
        # "b·ªô ƒë√¥i X" - duo group
        r'b·ªô\s+ƒë√¥i\s+([A-Z][a-zA-Z0-9\s\-\'\.()]+?)(?:\s*[,\.]|\s+(?:ƒë∆∞·ª£c|do|l√†|g·ªìm))',
    ],
    'Album': [
        # === PATTERNS C∆† B·∫¢N ===
        r'(?:album|mini[- ]?album|EP)\s+["\']?([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']?(?:\s+(?:l√†|ƒë∆∞·ª£c|ph√°t h√†nh)|\,|\.|$)',
        # Album v·ªõi d·∫•u ngo·∫∑c k√©p ƒë·∫∑c bi·ªát (Wikipedia th∆∞·ªùng d√πng)
        r'(?:album|mini[- ]?album|EP)\s+["""]([A-Z][a-zA-Z0-9\s\-\'\.]+?)["""]',
        
        # === PATTERNS THEO NG·ªÆ C·∫¢NH TI·∫æNG VI·ªÜT ===
        # "EP Always ƒë∆∞·ª£c ph√°t h√†nh v√†o nƒÉm 2007"
        r'EP\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s+(?:ƒë∆∞·ª£c ph√°t h√†nh|ra m·∫Øt|b√°n ƒë∆∞·ª£c)',
        # "mini album ƒë·∫ßu ti√™n Always"
        r'mini album\s+(?:ƒë·∫ßu ti√™n|th·ª© \w+|ti·∫øp theo|m·ªõi)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:ƒë∆∞·ª£c|b√°n|ra|ƒë·∫°t|gi√†nh))',
        # "album ƒë·∫ßu tay Since 2007"
        r'album\s+(?:ƒë·∫ßu tay|ƒë·∫ßu ti√™n|th·ª© \w+|ti·∫øp theo|m·ªõi nh·∫•t|phi√™n b·∫£n ƒë·∫∑c bi·ªát)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:ƒë∆∞·ª£c|b√°n|ra|t·ªïng h·ª£p))',
        # "ph√°t h√†nh album Tonight"
        r'ph√°t h√†nh\s+(?:album|EP|mini album)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:v√†o|v·ªõi|bao g·ªìm))',
        # "ra m·∫Øt album Alive"
        r'ra m·∫Øt\s+(?:album|EP|mini album)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:v√†o|v·ªõi|d∆∞·ªõi))',
        # "tr·ªü l·∫°i v·ªõi album Tonight"
        r'tr·ªü l·∫°i\s+(?:v·ªõi|b·∫±ng|c√πng)\s+(?:album|EP)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:v√†o|v·ªõi))',
        # "album th√†nh c√¥ng nh·∫•t c·ªßa m√¨nh, Alive"
        r'album\s+(?:th√†nh c√¥ng nh·∫•t|n·ªïi ti·∫øng nh·∫•t|hay nh·∫•t)[^,]*,\s*([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:ƒë∆∞·ª£c|l√†))',
        
        # === PATTERNS TI·∫æNG ANH (PH·ªî BI·∫æN TRONG WIKIPEDIA TI·∫æNG VI·ªÜT) ===
        # "album ti·∫øng Nh·∫≠t ƒë·∫ßu ti√™n mang t√™n Big Bang"
        r'album\s+(?:ti·∫øng\s+\w+)?\s*(?:ƒë·∫ßu ti√™n|th·ª© \w+)?\s*(?:mang t√™n|c√≥ t√™n|t√™n l√†)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.])',
        # "album Remember, v·ªõi ca kh√∫c"
        r'album\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s*,\s*v·ªõi\s+(?:ca kh√∫c|b√†i h√°t)',
        # "EP Stand Up - k·∫øt h·ª£p v·ªõi"
        r'(?:EP|album)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s*-\s*(?:k·∫øt h·ª£p|bao g·ªìm|v·ªõi)',
        
        # === PATTERNS M·ªöI - PH·ªî BI·∫æN TRONG WIKIPEDIA ===
        # "l√† album ph√≤ng thu ƒë·∫ßu tay c·ªßa X" - b·∫Øt album t·ª´ ƒë·∫ßu c√¢u
        r'([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s+l√†\s+(?:album|mini-album|EP)\s+(?:ph√≤ng thu|studio)?\s*(?:ƒë·∫ßu tay|ƒë·∫ßu ti√™n|th·ª© \w+)',
        # "album X ƒë∆∞·ª£c ph√°t h√†nh" - album + t√™n + ƒë·ªông t·ª´
        r'album\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s+(?:ƒë∆∞·ª£c ph√°t h√†nh|ra m·∫Øt|ph√°t h√†nh|b√°n ƒë∆∞·ª£c)',
        # "t·ª´ album X" - tr√≠ch t·ª´ album
        r't·ª´\s+(?:album|EP)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:ph√°t h√†nh|c·ªßa))',
        # "trong album X" - b√†i h√°t trong album
        r'(?:trong|n·∫±m trong)\s+(?:album|EP)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:ph√°t h√†nh|c·ªßa))',
        # "phi√™n b·∫£n ti·∫øng Nh·∫≠t c·ªßa X"
        r'phi√™n b·∫£n\s+ti·∫øng\s+\w+\s+c·ªßa\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.])',
        # "ƒëƒ©a ƒë∆°n tr√≠ch t·ª´ album X"
        r'tr√≠ch\s+t·ª´\s+album\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)(?:\s*[,\.]|\s+(?:ph√°t h√†nh))',
    ],
    'Song': [
        # === PATTERNS C∆† B·∫¢N ===
        # D·∫°ng c√≥ d·∫•u ngo·∫∑c k√©p chu·∫©n
        r'(?:b√†i h√°t|ca kh√∫c|single|ƒëƒ©a ƒë∆°n)\s+["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']',
        # D·∫°ng c√≥ d·∫•u ngo·∫∑c k√©p ƒë·∫∑c bi·ªát (Wikipedia)
        r'(?:b√†i h√°t|ca kh√∫c|single|ƒëƒ©a ƒë∆°n)\s+["""]([A-Z][a-zA-Z0-9\s\-\'\.]+?)["""]',
        # Ca kh√∫c ch·ªß ƒë·ªÅ
        r'ca kh√∫c ch·ªß ƒë·ªÅ\s+["\']?([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']?',
        # D·∫°ng kh√¥ng d·∫•u ngo·∫∑c k√©p + ƒë·ªông t·ª´
        r'(?:b√†i h√°t|ca kh√∫c|single|ƒëƒ©a ƒë∆°n)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s+(?:ƒë∆∞·ª£c|do|c·ªßa|ra m·∫Øt|ph√°t h√†nh|trong|l√†|ƒë·ª©ng ƒë·∫ßu|gi√†nh|tr·ªü th√†nh)\b',
        # D·∫°ng "c√≥ t√™n"/"mang t√™n"
        r'(?:b√†i h√°t|ca kh√∫c|single|ƒëƒ©a ƒë∆°n)\s+(?:c√≥ t√™n|mang t√™n)\s+["\']?([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']?',
        
        # === PATTERNS THEO NG·ªÆ C·∫¢NH TI·∫æNG VI·ªÜT ===
        # "ƒëƒ©a ƒë∆°n s·ªë m·ªôt c·ªßa h·ªç l√† \"Lies\""
        r'ƒëƒ©a ƒë∆°n\s+(?:s·ªë m·ªôt|ƒë·∫ßu ti√™n|th·ª© \w+)[^"]*["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']',
        # "ca kh√∫c hit ƒë·ªôt ph√° ƒë·∫ßu ti√™n c·ªßa nh√≥m" - th∆∞·ªùng theo sau l√† t√™n b√†i
        r'ca kh√∫c\s+(?:hit|n·ªïi ti·∫øng|ƒë·ªôt ph√°)[^,]*,?\s*["\']?([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']?(?:\s*[,\.]|\s+(?:tr·ªü th√†nh|ƒë·ª©ng ƒë·∫ßu|gi√†nh))',
        # "single ti·∫øng Nh·∫≠t ƒë·∫ßu ti√™n \"My Heaven\""
        r'single\s+(?:ti·∫øng\s+\w+)?\s*(?:ƒë·∫ßu ti√™n|th·ª© \w+|m·ªõi)?\s*["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']',
        # "b√†i h√°t ch·ªß ƒë·ªÅ \"Monster\""
        r'b√†i h√°t\s+ch·ªß ƒë·ªÅ\s+["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']',
        # "ca kh√∫c \"Lies\" (Ti·∫øng Tri·ªÅu Ti√™n: ...)"
        r'ca kh√∫c\s+["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\'](?:\s*\()',
        # "B√†i h√°t \" Flower Road \" ƒë∆∞·ª£c ph√°t h√†nh" (c√≥ kho·∫£ng tr·∫Øng trong ngo·∫∑c k√©p)
        r'[Bb]√†i h√°t\s+["\"]\s*([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s*["\"]\s+(?:ƒë∆∞·ª£c|do|l√†|ƒë·ª©ng)',
        
        # === PATTERNS DANH S√ÅCH CA KH√öC ===
        # "c√°c ca kh√∫c \"Lies\", \"Last Farewell\""
        r'(?:c√°c\s+)?ca kh√∫c\s+["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\'](?:\s*,|\s+v√†)',
        # "bao g·ªìm c√°c ca kh√∫c \"We Belong Together\""
        r'bao g·ªìm\s+(?:c√°c\s+)?ca kh√∫c\s+["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']',
        
        # === PATTERNS CHO HIT/SINGLE PH·ªî BI·∫æN ===
        # "hit X c·ªßa nh√≥m"
        r'hit\s+["\']?([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']?\s+(?:c·ªßa|gi√∫p|ƒë∆∞a)',
        # "single X ƒë·∫°t ƒë∆∞·ª£c"
        r'single\s+["\']?([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']?\s+(?:ƒë·∫°t ƒë∆∞·ª£c|ƒë·ª©ng|v∆∞∆°n)',
        # "C√∫ h√≠t \"Lies\" ƒë√£ ƒë∆∞a Big Bang"
        r'[Cc]√∫ h√≠t\s+["\']([A-Z][a-zA-Z0-9\s\-\'\.]+?)["\']',
        
        # === PATTERNS M·ªöI - ESCAPED QUOTES TRONG JSON ===
        # Pattern cho d·∫•u ngo·∫∑c k√©p escaped: \"X\"
        r'(?:b√†i h√°t|ca kh√∫c|single|ƒëƒ©a ƒë∆°n)\s+\\"([A-Z][a-zA-Z0-9\s\-\'\.]+?)\\"',
        # "ƒëƒ©a ƒë∆°n \"Blue\", \"Fantastic Baby\""
        r'ƒëƒ©a ƒë∆°n\s*,?\s*\\"([A-Z][a-zA-Z0-9\s\-\'\.]+?)\\"',
        # "v·ªõi ca kh√∫c \"X\""
        r'v·ªõi\s+ca\s+kh√∫c\s+\\"([A-Z][a-zA-Z0-9\s\-\'\.]+?)\\"',
        # "b√†i h√°t \"X\" c·ªßa"
        r'b√†i\s+h√°t\s+\\"([A-Z][a-zA-Z0-9\s\-\'\.]+?)\\"\s+(?:c·ªßa|trong|l√†)',
        # Pattern cho ƒëƒ©a ƒë∆°n ch√≠nh
        r'ƒëƒ©a\s+ƒë∆°n\s+(?:ch√≠nh|m·ªõi)?\s*(?:mang t√™n)?\s*\\"([A-Z][a-zA-Z0-9\s\-\'\.]+?)\\"',
        # "\" X \"l√†" pattern - t√™n b√†i ·ªü ƒë·∫ßu ƒëo·∫°n text
        r'\\"\s*([A-Z][a-zA-Z0-9\s\-\'\.]+?)\s*\\"\s*(?:l√† ƒëƒ©a ƒë∆°n|l√† ca kh√∫c|l√† b√†i h√°t)',
    ],
    'Company': [
        r'(?:c√¥ng ty|agency|label)\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?(?:Entertainment|Music|Media)?)',
        # "ƒë∆∞·ª£c th√†nh l·∫≠p b·ªüi YG Entertainment"
        r'(?:ƒë∆∞·ª£c th√†nh l·∫≠p|thu·ªôc|qu·∫£n l√Ω)\s+b·ªüi\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?(?:Entertainment|Music|Media))',
        # "d∆∞·ªõi s·ª± d·∫´n d·∫Øt c·ªßa YG Entertainment"
        r'(?:d∆∞·ªõi s·ª±|thu·ªôc)\s+(?:d·∫´n d·∫Øt|qu·∫£n l√Ω)\s+(?:c·ªßa\s+)?([A-Z][a-zA-Z0-9\s\-\'\.]+?(?:Entertainment|Music|Media))',
        # "th√¥ng qua h√£ng thu √¢m X Entertainment"
        r'(?:th√¥ng qua|b·ªüi)\s+(?:h√£ng\s+thu\s+√¢m|c√¥ng ty)?\s*([A-Z][a-zA-Z0-9\s\-\'\.]+?(?:Entertainment|Music|Media))',
        # "ƒë∆∞·ª£c X Entertainment ph√°t h√†nh"
        r'ƒë∆∞·ª£c\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?(?:Entertainment|Music|Media))\s+(?:ph√°t h√†nh|ph√¢n ph·ªëi)',
        # "k√Ω h·ª£p ƒë·ªìng v·ªõi X Entertainment"
        r'k√Ω\s+h·ª£p\s+ƒë·ªìng\s+v·ªõi\s+([A-Z][a-zA-Z0-9\s\-\'\.]+?(?:Entertainment|Music|Media))',
    ],
}

# =====================================================
# TR√çCH XU·∫§T ENTITIES
# =====================================================
def extract_entities(text, entity_type, pattern_list):
    """Tr√≠ch xu·∫•t entities b·∫±ng regex"""
    entities = []
    seen = set()
    
    for pattern in pattern_list:
        try:
            for match in re.finditer(pattern, text, re.IGNORECASE | re.MULTILINE):
                entity_text = match.group(1) if match.lastindex else match.group(0)
                entity_text = clean_text(entity_text)
                
                if not entity_text or entity_text.lower() in seen:
                    continue
                # CHU·∫®N H√ìA entity text tr∆∞·ªõc khi check v·ªõi existing_lower
                normalized_entity = clean_text(entity_text)
                # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng ƒë·ªÉ so s√°nh v·ªõi existing_lower (ƒë√£ lo·∫°i b·ªè kho·∫£ng tr·∫Øng)
                entity_key = normalized_entity.lower().replace(' ', '')
                if entity_key in existing_lower:
                    continue
                if not is_valid_entity(entity_text, entity_type):
                    continue
                
                seen.add(entity_text.lower())
                entities.append({
                    'text': entity_text,
                    'type': entity_type,
                    'method': 'rule-based',
                    'confidence': 0.7
                })
        except:
            continue
    return entities

def extract_members_from_list(text):
    """Tr√≠ch xu·∫•t th√†nh vi√™n t·ª´ pattern li·ªát k√™ nh∆∞ 'bao g·ªìm X th√†nh vi√™n: A, B, C v√† D'"""
    entities = []
    seen = set()
    name_list_pattern = r'([A-Za-z\-\'\.\s,&/]+?)'
    
    role_keywords_vi = [
        'th√†nh vi√™n', 'c√°c th√†nh vi√™n', 'th√†nh vi√™n g·ªìm', 'c√°c th√†nh vi√™n g·ªìm',
        'c·ª±u th√†nh vi√™n', 'th√†nh vi√™n hi·ªán t·∫°i', 'th√†nh vi√™n c≈©', 'th√†nh vi√™n m·ªõi',
        'ca sƒ©', 'c√°c ca sƒ©', 'ngh·ªá sƒ©', 'c√°c ngh·ªá sƒ©', 'rapper', 'c√°c rapper',
        'idol', 'c√°c idol', 'gi·ªçng ca', 'gi·ªçng h√°t', 'vocal', 'vocal line',
        'rap line', 'dance line', 'tr∆∞·ªüng nh√≥m', 'leader', 'maknae', 'visual', 'center'
    ]
    
    role_keywords_en = [
        'member', 'members', 'current members', 'former members', 'original members',
        'new members', 'lineup', 'line-up', 'line up', 'singer', 'singers',
        'artist', 'artists', 'rapper', 'rappers', 'idol', 'idols',
        'vocalist', 'vocalists', 'dancer', 'dancers', 'dance line', 'rap line',
        'vocal line', 'leader', 'leaders', 'maknae'
    ]
    
    # C√°c pattern li·ªát k√™ th√†nh vi√™n - s·ª≠ d·ª•ng greedy match ƒë·ªÉ l·∫•y ƒë·ªß danh s√°ch
    member_list_patterns = [
        # === TI·∫æNG VI·ªÜT (c·ªë ƒë·ªãnh) ===
        # "bao g·ªìm X th√†nh vi√™n: A, B, C v√† D"
        r'(?:bao g·ªìm|g·ªìm c√≥|g·ªìm)\s+\d+\s+th√†nh vi√™n\s*[:\s]\s*([A-Za-z\-\'\.\s,v√†]+?)(?:\s*,\s*h·ªç|\s*\.|$)',
        # "th√†nh vi√™n: A, B, C v√† D"
        r'th√†nh vi√™n\s*:\s*([A-Za-z\-\'\.\s,v√†]+?)(?:\s*\.|$)',
        # "X th√†nh vi√™n: list"
        r'\d+\s+th√†nh vi√™n\s*:\s*([A-Za-z\-\'\.\s,v√†]+?)(?:\s*,\s*h·ªç|\s*\.|$)',
        # "c√°c th√†nh vi√™n A, B, C v√† D"
        r'c√°c\s+th√†nh vi√™n\s+([A-Za-z\-\'\.\s,v√†]+?)(?:\s*\.|$)',
        # "th√†nh vi√™n g·ªìm A, B, C"
        r'th√†nh vi√™n\s+g·ªìm\s+([A-Za-z\-\'\.\s,v√†]+?)(?:\s*\.|$)',
        # "th√†nh vi√™n l√† A, B, C"
        r'th√†nh vi√™n\s+l√†\s+([A-Za-z\-\'\.\s,v√†]+?)(?:\s*\.|$)',
        # "nh√≥m c√≥ X ng∆∞·ªùi: A, B, C"
        r'nh√≥m\s+(?:c√≥|g·ªìm)\s+\d+\s+(?:ng∆∞·ªùi|th√†nh vi√™n)\s*[:\s]\s*([A-Za-z\-\'\.\s,v√†]+?)(?:\s*\.|$)',
        # "m·ªôt s·ªë th√†nh vi√™n, bao g·ªìm A, B, C"
        r'(?:m·ªôt s·ªë|nhi·ªÅu|v√†i)\s+th√†nh vi√™n\s*,?\s*(?:bao g·ªìm|g·ªìm|nh∆∞|l√†)\s+([A-Za-z\-\'\.\s,v√†]+?)(?:\s*\.|$)',
        # "c√°c ca sƒ© g·ªìm A, B, C"
        r'c√°c\s+ca sƒ©\s+(?:g·ªìm|bao g·ªìm|nh∆∞|l√†)\s+([A-Za-z\-\'\.\s,v√†]+?)(?:\s*\.|$)',
        # "c√°c ngh·ªá sƒ© nh∆∞ A, B, C"
        r'c√°c\s+ngh·ªá sƒ©\s+(?:nh∆∞|g·ªìm|bao g·ªìm|l√†)\s+([A-Za-z\-\'\.\s,v√†]+?)(?:\s*\.|$)',
        
        # === TI·∫æNG ANH (c·ªë ƒë·ªãnh) ===
        # "consists of X members: A, B, C and D"
        r'consists?\s+of\s+\d+\s+members?\s*[:\s]\s*([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "members: A, B, C and D"
        r'members?\s*:\s*([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "X members: A, B, C"
        r'\d+\s+members?\s*:\s*([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "the members are A, B, C"
        r'(?:the\s+)?members?\s+(?:are|include|including)\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "some members, including A, B, C"
        r'(?:some|several|many|various)\s+members?\s*,?\s*(?:including|such as|like)\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "singers such as A, B, C"
        r'singers?\s+(?:such as|like|including|include)\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "artists including A, B, C"
        r'artists?\s+(?:including|such as|like)\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "comprising A, B, C"
        r'comprising\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "composed of A, B, C"
        r'composed\s+of\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "formed by A, B, C"
        r'formed\s+by\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "featuring A, B, C"
        r'featuring\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "with members A, B, C"
        r'with\s+members?\s+([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "lineup: A, B, C" ho·∫∑c "line-up: A, B, C"
        r'line[\-\s]?up\s*:\s*([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        # "current members: A, B, C"
        r'(?:current|original|former)\s+members?\s*:\s*([A-Za-z\-\'\.\s,and]+?)(?:\s*\.|$)',
        
        # === PATTERN CHUNG ===
        # "(A, B, C, D)" - danh s√°ch trong ngo·∫∑c sau t√™n nh√≥m
        r'\(\s*([A-Z][a-z]+(?:\s*,\s*[A-Z][a-z]+){2,})\s*\)',
    ]
    
    # Dynamic patterns cho c√°c t·ª´ kh√≥a vai tr√≤ (ti·∫øng Vi·ªát)
    connectors_vi = r'(?:bao g·ªìm|g·ªìm|g·ªìm c√≥|g·ªìm c·∫£|bao g·ªìm c·∫£|bao g·ªìm nh·ªØng|bao g·ªìm c√°c|g·ªìm nh·ªØng|g·ªìm c√°c|l√†|l√† nh·ªØng|l√† c√°c)'
    for kw in role_keywords_vi:
        kw_pattern = re.escape(kw)
        member_list_patterns.append(
            rf'{kw_pattern}\s+{connectors_vi}\s*{name_list_pattern}(?:\s*\.|$)'
        )
        member_list_patterns.append(
            rf'{kw_pattern}\s*[:\-]\s*{name_list_pattern}(?:\s*\.|$)'
        )
    
    # Dynamic patterns cho t·ª´ kh√≥a ti·∫øng Anh
    connectors_en = r'(?:include|includes|including|consist of|consists of|consisting of|are|were|feature|featuring|with|comprise|comprises|comprised of)'
    for kw in role_keywords_en:
        kw_pattern = re.escape(kw)
        member_list_patterns.append(
            rf'(?:the\s+)?{kw_pattern}\s+{connectors_en}\s*{name_list_pattern}(?:\s*\.|$)'
        )
        member_list_patterns.append(
            rf'(?:the\s+)?{kw_pattern}\s*[:\-]\s*{name_list_pattern}(?:\s*\.|$)'
        )
    
    for pattern in member_list_patterns:
        try:
            for match in re.finditer(pattern, text, re.IGNORECASE):
                member_list_text = match.group(1)
                if not member_list_text:
                    continue
                
                # T√°ch c√°c th√†nh vi√™n b·∫±ng d·∫•u ph·∫©y ho·∫∑c "v√†"/"and"/"&"
                # Thay c√°c t·ª´ n·ªëi b·∫±ng d·∫•u ph·∫©y ƒë·ªÉ d·ªÖ t√°ch
                member_list_text = re.sub(r'\s+v√†\s+', ', ', member_list_text, flags=re.IGNORECASE)
                member_list_text = re.sub(r'\s+and\s+', ', ', member_list_text, flags=re.IGNORECASE)
                member_list_text = re.sub(r'\s*&\s*', ', ', member_list_text)
                member_list_text = re.sub(r'\s*;\s*', ', ', member_list_text)  # D·∫•u ch·∫•m ph·∫©y
                member_list_text = re.sub(r'\s*/\s*', ', ', member_list_text)  # D·∫•u g·∫°ch ch√©o
                
                # T√°ch b·∫±ng d·∫•u ph·∫©y
                members = [m.strip() for m in member_list_text.split(',')]
                
                for member in members:
                    member = clean_text(member)
                    
                    # B·ªè qua n·∫øu qu√° ng·∫Øn ho·∫∑c qu√° d√†i
                    if not member or len(member) < 1 or len(member) > 30:
                        continue
                    
                    # B·ªè qua n·∫øu ch·ª©a s·ªë (tr·ª´ khi l√† t√™n nh∆∞ "2PM")
                    if re.search(r'\d', member) and not re.match(r'^[0-9][A-Za-z]+', member):
                        continue
                    
                    # B·ªè qua n·∫øu l√† t·ª´ chung chung
                    if member.lower() in INVALID_WORDS:
                        continue
                    
                    # B·ªè qua n·∫øu ƒë√£ t·ªìn t·∫°i trong graph g·ªëc (existing_lower)
                    # CHU·∫®N H√ìA member tr∆∞·ªõc khi check
                    normalized_member = clean_text(member)
                    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng ƒë·ªÉ so s√°nh v·ªõi existing_lower
                    member_key = normalized_member.lower().replace(' ', '')
                    if member_key in existing_lower:
                        continue
                    
                    if member.lower() in seen:
                        continue
                    
                    # Ki·ªÉm tra t√≠nh h·ª£p l·ªá - nh∆∞ng v·∫´n n·ªõi l·ªèng cho t√™n th√†nh vi√™n
                    lower_member = member.lower()
                    # Whitelist t√™n ng·∫Øn h·ª£p l·ªá (tr√πng v·ªõi is_valid_entity)
                    valid_short_names = {'rm', 'iu', 'cl', 'bm', 'jb', 'jj', 'jo', 'im', 'do'}
                    
                    if len(member) <= 2:
                        # Ch·ªâ cho ph√©p n·∫øu l√† t√™n ng·∫Øn h·ª£p l·ªá trong whitelist
                        if lower_member not in valid_short_names:
                            continue
                    elif len(member) == 3:
                        # T√™n 3 k√Ω t·ª±: v·∫´n ph·∫£i b·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ hoa v√† qua is_valid_entity
                        if not member[0].isupper() and not member.isupper():
                            continue
                        if not is_valid_entity(member, 'Artist'):
                            continue
                    else:
                        if not is_valid_entity(member, 'Artist'):
                            continue
                    
                    seen.add(member.lower())
                    entities.append({
                        'text': member,
                        'type': 'Artist',
                        'method': 'rule-based',
                        'confidence': 0.8  # Confidence cao v√¨ ƒë∆∞·ª£c li·ªát k√™ r√µ r√†ng trong context th√†nh vi√™n
                    })
        except Exception as e:
            continue
    
    return entities

def extract_groups_from_list(text):
    """Tr√≠ch xu·∫•t nh√≥m nh·∫°c t·ª´ c√°c c√¢u li·ªát k√™ nh∆∞:
    - 'c√°c nh√≥m nh·∫°c ch√≠nh g·ªìm TVXQ, Super Junior, ...'
    - 'ƒë√£ t·ª´ng qu·∫£n l√Ω c√°c nh√≥m nh·∫°c H.O.T, S.E.S., Shinhwa, ...'
    """
    entities = []
    seen = set()
    
    # Cho ph√©p c·∫£ ch·ªØ, s·ªë, d·∫•u ch·∫•m, ngo·∫∑c, d·∫•u g·∫°ch, &, /
    name_list_pattern = r'([A-Za-z0-9\-\'\.\s&/()]+?)'
    
    group_list_patterns = [
        # === TI·∫æNG VI·ªÜT ===
        # "c√°c nh√≥m nh·∫°c ch√≠nh g·ªìm TVXQ, Super Junior, ..."
        r'(?:c√°c|nh·ªØng)\s+nh√≥m nh·∫°c(?:\s+\w+)*\s+(?:g·ªìm|bao g·ªìm|l√†|nh∆∞)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "c√°c nh√≥m nh·∫°c g·ªìm TVXQ, Super Junior, ..."
        r'c√°c\s+nh√≥m nh·∫°c\s+(?:g·ªìm|bao g·ªìm|nh∆∞|l√†)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "qu·∫£n l√Ω c√°c nh√≥m nh·∫°c TVXQ, Super Junior, ..."
        r'(?:ƒë√£\s+)?(?:t·ª´ng\s+)?qu·∫£n l√Ω\s+(?:c√°c\s+)?nh√≥m nh·∫°c\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "c√°c nh√≥m nh·∫°c TVXQ, Super Junior, ..."
        r'c√°c\s+nh√≥m nh·∫°c\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "c√°c nh√≥m nh·∫°c: TVXQ, Super Junior, ..." (c√≥ d·∫•u :)
        r'c√°c\s+nh√≥m nh·∫°c\s*:\s*' + name_list_pattern + r'(?:[.;]|$)',
        # "m·ªôt s·ªë nh√≥m nh·∫°c, bao g·ªìm A, B, C"
        r'(?:m·ªôt s·ªë|nhi·ªÅu|v√†i)\s+nh√≥m nh·∫°c\s*,?\s*(?:bao g·ªìm|g·ªìm|nh∆∞|l√†)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "nh√≥m nh·∫°c bao g·ªìm A, B, C"
        r'nh√≥m nh·∫°c\s+(?:bao g·ªìm|g·ªìm|nh∆∞|l√†)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "c√°c nh√≥m nh∆∞ A, B, C"
        r'(?:c√°c|nh·ªØng)\s+nh√≥m\s+(?:nh∆∞|bao g·ªìm|g·ªìm)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "bao g·ªìm c√°c nh√≥m A, B, C"
        r'bao g·ªìm\s+(?:c√°c|nh·ªØng)?\s*nh√≥m(?:\s*nh·∫°c)?\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "g·ªìm c√°c nh√≥m nh·∫°c A, B, C"
        r'g·ªìm\s+(?:c√°c|nh·ªØng)?\s*nh√≥m(?:\s*nh·∫°c)?\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "c√°c nh√≥m nh·∫°c nam/n·ªØ A, B, C"
        r'(?:c√°c|nh·ªØng)\s+nh√≥m(?:\s*nh·∫°c)?(?:\s+nam|\s+n·ªØ)?\s+(?:g·ªìm|bao g·ªìm|nh∆∞|l√†)\s+' + name_list_pattern + r'(?:[.;]|$)',
        
        # === TI·∫æNG ANH ===
        # "groups such as A, B, C"
        r'(?:idol\s+)?groups?\s+(?:such as|like|including|include)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "some groups, including A, B, C"
        r'(?:some|several|many|various)\s+groups?\s*,?\s*(?:including|such as|like)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "groups including A, B, C"
        r'groups?\s+(?:including|such as|like)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "managed groups A, B, C"
        r'(?:managed|manages|managing)\s+(?:the\s+)?groups?\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "former/current/active groups include A, B, C"
        r'(?:former|current|active)\s+groups?\s+(?:include|including|such as|like)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "K-pop groups such as A, B, C"
        r'(?:k-?pop|korean)\s+groups?\s+(?:such as|like|including|include)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "boy groups A, B, C"
        r'(?:boy|girl)\s+groups?\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "groups: TVXQ, Super Junior, ..." (c√≥ d·∫•u :)
        r'(?:idol\s+)?groups?\s*:\s*' + name_list_pattern + r'(?:[.;]|$)',
    ]
    
    for pattern in group_list_patterns:
        try:
            for match in re.finditer(pattern, text, re.IGNORECASE):
                group_list_text = match.group(1)
                if not group_list_text:
                    continue
                
                # Chu·∫©n h√≥a n·ªëi: 'v√†' / 'and' / '&'
                group_list_text = re.sub(r'\s+v√†\s+', ', ', group_list_text, flags=re.IGNORECASE)
                group_list_text = re.sub(r'\s+and\s+', ', ', group_list_text, flags=re.IGNORECASE)
                group_list_text = re.sub(r'\s*&\s*', ', ', group_list_text)
                group_list_text = re.sub(r'\s*;\s*', ', ', group_list_text)
                
                groups = [g.strip() for g in group_list_text.split(',')]
                
                for grp in groups:
                    grp = clean_text(grp)
                    if not grp:
                        continue
                    
                    # B·ªè c√°c m·∫£nh c√¢u ki·ªÉu 'v√† ƒë√£ t·ª´ng qu·∫£n l√Ω'
                    low = grp.lower()
                    if any(kw in low for kw in ['qu·∫£n l√Ω', 't·ª´ng qu·∫£n', 'ƒë√£ t·ª´ng', 'ƒë√£ qu·∫£n']):
                        continue
                    
                    if len(grp) < 2 or len(grp) > 40:
                        continue
                    
                    # B·ªè qua n·∫øu ƒë√£ c√≥ trong graph ho·∫∑c ƒë√£ th·∫•y
                    # CHU·∫®N H√ìA group name tr∆∞·ªõc khi check (grp ƒë√£ ƒë∆∞·ª£c clean_text ·ªü tr√™n)
                    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng ƒë·ªÉ so s√°nh v·ªõi existing_lower
                    group_key = grp.lower().replace(' ', '')
                    if group_key in existing_lower or group_key in seen:
                        continue
                    
                    # Ph·∫£i qua ki·ªÉm tra group h·ª£p l·ªá
                    if not is_valid_entity(grp, 'Group'):
                        continue
                    
                    seen.add(group_key)
                    entities.append({
                        'text': grp,
                        'type': 'Group',
                        'method': 'rule-based',
                        'confidence': 0.8,
                    })
        except Exception:
            continue
    
    return entities

def extract_companies_from_list(text):
    """Tr√≠ch xu·∫•t c√¥ng ty t·ª´ c√°c c√¢u li·ªát k√™, v√≠ d·ª•:
    - 'c√°c c√¥ng ty gi·∫£i tr√≠ H√†n Qu·ªëc l√† YG Entertainment, Pledis Entertainment v√† Starship Entertainment'
    - 'ng∆∞·ªùi t·ª´ng l√†m vi·ªác v·ªõi c√°c c√¥ng ty nh∆∞ JYP Entertainment, Woollim Entertainment, Sony Music Korea v√† Blockberry Creative'
    - 'c√°c c√¥ng ty bao g·ªìm Jin-ah Entertainment, Eru Entertainment v√† YMC Entertainment'
    """
    entities = []
    seen = set()
    
    # Cho ph√©p c·∫£ ch·ªØ, s·ªë, d·∫•u ch·∫•m, ngo·∫∑c, d·∫•u g·∫°ch, &, /
    name_list_pattern = r'([A-Za-z0-9\-\'\.\s&/()]+?)'
    
    company_list_patterns = [
        # === TI·∫æNG VI·ªÜT ===
        # "c√°c c√¥ng ty gi·∫£i tr√≠ H√†n Qu·ªëc l√† YG Entertainment, Pledis Entertainment..."
        r'c√°c\s+c√¥ng ty(?:\s+gi·∫£i tr√≠)?(?:\s+[A-Za-z√Ä-·ªπ]+)*\s+(?:l√†|g·ªìm|bao g·ªìm|nh∆∞)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "c√°c c√¥ng ty: YG Entertainment, ..."
        r'c√°c\s+c√¥ng ty(?:\s+gi·∫£i tr√≠)?\s*:\s*' + name_list_pattern + r'(?:[.;]|$)',
        # "c√°c c√¥ng ty nh∆∞ JYP Entertainment, Woollim Entertainment..."
        r'c√°c\s+c√¥ng ty(?:\s+gi·∫£i tr√≠)?\s+(?:nh∆∞|bao g·ªìm|g·ªìm)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "c√¥ng ty ... bao g·ªìm Jin-ah Entertainment, Eru Entertainment..."
        r'c√¥ng ty(?:\s+gi·∫£i tr√≠)?(?:\s+[A-Za-z√Ä-·ªπ]+)*\s+bao g·ªìm\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "c√¥ng ty ... nh∆∞ JYP Entertainment, ..."
        r'c√¥ng ty(?:\s+gi·∫£i tr√≠)?(?:\s+[A-Za-z√Ä-·ªπ]+)*\s+nh∆∞\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "c√°c c√¥ng ty bao g·ªìm Jin-ah Entertainment, ... "
        r'c√°c\s+c√¥ng ty(?:\s+gi·∫£i tr√≠)?\s+bao g·ªìm\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "ng∆∞·ªùi t·ª´ng l√†m vi·ªác v·ªõi c√°c c√¥ng ty nh∆∞ JYP Entertainment, ..."
        r'c√°c\s+c√¥ng ty\s+nh∆∞\s+' + name_list_pattern + r'(?:[.;]|$)',
        
        # === TI·∫æNG ANH ===
        # "companies such as JYP Entertainment, Woollim Entertainment..."
        r'companies?\s+(?:such as|like|including|include)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "entertainment companies such as YG Entertainment, ..."
        r'(?:entertainment\s+companies?|record\s+labels?|agencies)\s+(?:such as|like|including|include)\s+' + name_list_pattern + r'(?:[.;]|$)',
        # "labels: YG Entertainment, JYP Entertainment, ..."
        r'(?:labels?|companies?)\s*:\s*' + name_list_pattern + r'(?:[.;]|$)',
    ]
    
    for pattern in company_list_patterns:
        try:
            for match in re.finditer(pattern, text, re.IGNORECASE):
                company_list_text = match.group(1)
                if not company_list_text:
                    continue
                
                # Chu·∫©n h√≥a n·ªëi: 'v√†' / 'and' / '&' / ';' / '/'
                company_list_text = re.sub(r'\s+v√†\s+', ', ', company_list_text, flags=re.IGNORECASE)
                company_list_text = re.sub(r'\s+and\s+', ', ', company_list_text, flags=re.IGNORECASE)
                company_list_text = re.sub(r'\s*&\s*', ', ', company_list_text)
                company_list_text = re.sub(r'\s*;\s*', ', ', company_list_text)
                company_list_text = re.sub(r'\s*/\s*', ', ', company_list_text)
                
                # T√°ch theo d·∫•u ph·∫©y
                companies = [c.strip() for c in company_list_text.split(',')]
                
                for comp in companies:
                    comp = clean_text(comp)
                    if not comp:
                        continue
                    
                    low = comp.lower()
                    
                    # B·ªè c√°c m·∫£nh c√¢u c√≤n s√≥t ƒë·ªông t·ª´/m√¥ t·∫£
                    if any(kw in low for kw in ['ng∆∞·ªùi', 't·ª´ng', 'l√†m vi·ªác', 'h·ª£p t√°c', 'c√πng', 'v·ªõi']):
                        continue
                    
                    if len(comp) < 3 or len(comp) > 60:
                        continue
                    
                    # B·ªè qua n·∫øu ƒë√£ c√≥ trong graph ho·∫∑c ƒë√£ th·∫•y
                    # CHU·∫®N H√ìA company name tr∆∞·ªõc khi check
                    normalized_company = clean_text(comp)
                    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng ƒë·ªÉ so s√°nh v·ªõi existing_lower
                    company_key = normalized_company.lower().replace(' ', '')
                    if company_key in existing_lower or company_key in seen:
                        continue
                    
                    # Ph·∫£i qua ki·ªÉm tra company h·ª£p l·ªá
                    if not is_valid_entity(comp, 'Company'):
                        continue
                    
                    seen.add(normalized_company.lower())
                    entities.append({
                        'text': comp,
                        'type': 'Company',
                        'method': 'rule-based',
                        'confidence': 0.85,
                    })
        except Exception:
            continue
    
    return entities


def extract_artists_from_infobox_groups():
    """
    T·∫°o c√°c node Artist m·ªõi t·ª´ infobox members c·ªßa c√°c Group g·ªëc.
    - D√πng d·ªØ li·ªáu ƒë√£ crawl trong 'infobox_members.json' (INFOBOX_MEMBERS['groups'])
    - C√°c tr∆∞·ªùng s·ª≠ d·ª•ng: 'Current members', 'Past members', 'Th√†nh vi√™n', 'C·ª±u th√†nh vi√™n', etc.
    - Kh√¥ng tr√πng v·ªõi node g·ªëc (existing_lower) v√† c√°c node m·ªõi kh√°c
    """
    entities = []
    seen = set()

    groups = INFOBOX_MEMBERS.get('groups') or {}
    if not isinstance(groups, dict):
        return entities

    member_keys = [
        'Current members',
        'Past members',
        'Th√†nh vi√™n',
        'C·ª±u th√†nh vi√™n',
        'Th√†nh vi√™n hi·ªán t·∫°i',
        'Th√†nh vi√™n c≈©',
        'Former members',
    ]
    
    # C√°c t·ª´ chung chung c·∫ßn lo·∫°i b·ªè (kh√¥ng ph·∫£i t√™n th√†nh vi√™n)
    GENERIC_MEMBER_TERMS = {
        'th√†nh vi√™n', 'members', 'member', 'c·ª±u th√†nh vi√™n', 'former members',
        'past members', 'current members', 'th√†nh vi√™n hi·ªán t·∫°i', 'th√†nh vi√™n c≈©',
    }

    for group_name, data in groups.items():
        info = data.get('infobox') or {}
        if not isinstance(info, dict):
            continue

        for key in member_keys:
            raw = info.get(key)
            if not raw:
                continue

            # T√°ch danh s√°ch t√™n theo d·∫•u ph·∫©y
            parts = [p.strip() for p in raw.split(',') if p.strip()]
            for part in parts:
                member = clean_text(part)
                if not member:
                    continue

                low = member.lower()
                
                # Lo·∫°i b·ªè c√°c t·ª´ chung chung (kh√¥ng ph·∫£i t√™n th√†nh vi√™n)
                if low in GENERIC_MEMBER_TERMS:
                    continue
                
                # Lo·∫°i b·ªè n·∫øu ch·ªâ l√† m·ªôt t·ª´ chung chung (kh√¥ng ph·∫£i t√™n ng∆∞·ªùi)
                if low in ['th√†nh vi√™n', 'members', 'member', 'c·ª±u', 'former', 'past', 'current']:
                    continue

                # Kh√¥ng tr√πng node g·ªëc
                # CHU·∫®N H√ìA member tr∆∞·ªõc khi check
                normalized_member = clean_text(member)
                # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng ƒë·ªÉ so s√°nh v·ªõi existing_lower
                member_key = normalized_member.lower().replace(' ', '')
                if member_key in existing_lower:
                    continue
                # Kh√¥ng tr√πng trong danh s√°ch infobox ƒë√£ th√™m
                if member_key in seen:
                    continue

                # ƒê·ªô d√†i h·ª£p l√Ω cho Artist
                if len(member) < 2 or len(member) > 40:
                    continue

                # B·ªè t·ª´ v√¥ nghƒ©a
                if low in INVALID_WORDS:
                    continue

                # Kh√¥ng ch·ª©a s·ªë l·∫° (cho ph√©p t√™n ki·ªÉu 2AM, 2PM nh∆∞ng ƒë√≥ l√† nh√≥m, kh√¥ng ph·∫£i th√†nh vi√™n)
                if re.search(r'\d', member):
                    continue

                # Ch·ªâ ch·∫•p nh·∫≠n n·∫øu l√† Artist h·ª£p l·ªá
                if not is_valid_entity(member, 'Artist'):
                    continue

                seen.add(normalized_member.lower())
                entities.append({
                    'text': member,
                    'type': 'Artist',
                    'method': 'infobox_members',
                    'confidence': 0.9,
                    'source_node': group_name,
                })

    return entities


def extract_known_companies(text):
    """Tr√≠ch xu·∫•t c√¥ng ty ƒë√£ bi·∫øt"""
    entities = []
    text_lower = text.lower()
    for company in KNOWN_COMPANIES:
        # CHU·∫®N H√ìA company name tr∆∞·ªõc khi check
        normalized_company = clean_text(company)
        # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng ƒë·ªÉ so s√°nh v·ªõi existing_lower
        company_key = normalized_company.lower().replace(' ', '')
        if company.lower() in text_lower and company_key not in existing_lower:
            entities.append({
                'text': company,
                'type': 'Company',
                'method': 'known_list',
                'confidence': 0.95
            })
    return entities

# =====================================================
# X·ª¨ L√ù CH√çNH
# =====================================================
print("\nüìä B∆∞·ªõc 1: Nh·∫≠n d·∫°ng th·ª±c th·ªÉ...")
all_entities = []  # Rule-based entities
ml_all_entities = []  # ML-based entities (ri√™ng bi·ªát)

# Tr√≠ch xu·∫•t Artist m·ªõi t·ª´ infobox members c·ªßa Group g·ªëc (n·∫øu c√≥ file)
infobox_artists = extract_artists_from_infobox_groups()
if infobox_artists:
    print(f"  ‚úì Tr√≠ch xu·∫•t {len(infobox_artists)} artist t·ª´ infobox members (file infobox_members.json)")
    all_entities.extend(infobox_artists)

for i, record in enumerate(records, 1):
    if i % 200 == 0:
        print(f"  ƒê√£ x·ª≠ l√Ω: {i}/{len(records)} records...")
    
    text = record.get('text', '')
    node_id = record.get('node_id', '')
    
    # Tr√≠ch xu·∫•t theo t·ª´ng lo·∫°i (RULE-BASED)
    for entity_type, pattern_list in patterns.items():
        found = extract_entities(text, entity_type, pattern_list)
        for ent in found:
            ent['source_node'] = node_id
            all_entities.append(ent)
    
    # C√¥ng ty ƒë√£ bi·∫øt
    for ent in extract_known_companies(text):
        ent['source_node'] = node_id
        all_entities.append(ent)
    
    # Tr√≠ch xu·∫•t c√¥ng ty t·ª´ c√°c c√¢u li·ªát k√™
    for ent in extract_companies_from_list(text):
        ent['source_node'] = node_id
        all_entities.append(ent)
    
    # Tr√≠ch xu·∫•t th√†nh vi√™n t·ª´ danh s√°ch li·ªát k√™
    for ent in extract_members_from_list(text):
        ent['source_node'] = node_id
        all_entities.append(ent)
    
    # Tr√≠ch xu·∫•t nh√≥m nh·∫°c t·ª´ c√°c c√¢u li·ªát k√™ nh√≥m
    for ent in extract_groups_from_list(text):
        ent['source_node'] = node_id
        all_entities.append(ent)
    
    # Tr√≠ch xu·∫•t b·∫±ng ML model (ML-BASED) - L∆ØU RI√äNG
    if ML_NER_AVAILABLE:
        try:
            ml_entities = extract_ml_entities(text, node_id)
            if ml_entities:
                for ent in ml_entities:
                    # √ÅP D·ª§NG is_valid_entity CHO ML ENTITIES (gi·ªëng rule-based)
                    entity_text = ent.get('text', '')
                    entity_type = ent.get('type', '')
                    if not is_valid_entity(entity_text, entity_type):
                        # B·ªè qua entity kh√¥ng h·ª£p l·ªá
                        continue
                    
                    # CHECK TR√ôNG V·ªöI GRAPH G·ªêC (gi·ªëng rule-based)
                    normalized_entity = clean_text(entity_text)
                    entity_key = normalized_entity.lower().replace(' ', '')
                    if entity_key in existing_lower:
                        # Entity ƒë√£ t·ªìn t·∫°i trong graph g·ªëc -> b·ªè qua
                        continue
                    
                    # KH√îNG CHECK TR√ôNG V·ªöI RULE-BASED (s·∫Ω l∆∞u ri√™ng)
                    ml_all_entities.append(ent)
        except Exception as e:
            # Ch·ªâ in l·ªói n·∫øu debug (ƒë·ªÉ tr√°nh spam)
            # N·∫øu c√≥ l·ªói, b·ªè qua v√† ti·∫øp t·ª•c v·ªõi rule-based
            if i <= 5:  # Ch·ªâ in l·ªói cho 5 records ƒë·∫ßu ƒë·ªÉ debug
                print(f"  ‚ö†Ô∏è  L·ªói ML NER ·ªü record {i}: {type(e).__name__}")
            pass

rule_based_count = len(all_entities)
print(f"  ‚úì Nh·∫≠n d·∫°ng ƒë∆∞·ª£c {rule_based_count} entities th√¥ (rule-based)")
if ML_NER_AVAILABLE:
    ml_count = len(ml_all_entities)
    print(f"  ‚úì Nh·∫≠n d·∫°ng ƒë∆∞·ª£c {ml_count} entities th√¥ (ML-based)")

# =====================================================
# G·ªòP V√Ä LO·∫†I B·ªé TR√ôNG L·∫∂P (RULE-BASED)
# =====================================================
print("\nüìä B∆∞·ªõc 2a: G·ªôp v√† lo·∫°i b·ªè tr√πng l·∫∑p (Rule-based)...")
unique_rule = {}

for ent in all_entities:
    # Chu·∫©n h√≥a text ƒë·ªÉ tr√°nh tr√πng do kh√°c kho·∫£ng tr·∫Øng / hoa th∆∞·ªùng
    normalized_text = clean_text(ent['text'])
    ent['text'] = normalized_text
    
    # T·∫°o key ƒë·ªÉ g·ªôp: CH·ªà merge c√°c entity ho√†n to√†n gi·ªëng nhau (sau khi normalize)
    normalized_lower = normalized_text.lower()
    key = (normalized_lower, ent['type'])
    
    if key not in unique_rule:
        unique_rule[key] = {**ent, 'sources': [ent.get('source_node', '')]}
    else:
        # G·ªôp sources - ch·ªâ merge n·∫øu text ho√†n to√†n gi·ªëng nhau (sau normalize)
        existing = unique_rule[key]
        source_node = ent.get('source_node', '')
        if source_node and source_node not in existing.get('sources', []):
            existing['sources'].append(source_node)
        # Gi·ªØ confidence cao nh·∫•t
        existing['confidence'] = max(existing.get('confidence', 0), ent.get('confidence', 0))

merged_rule_entities = list(unique_rule.values())
print(f"  ‚úì C√≤n {len(merged_rule_entities)} entities (rule-based) sau khi g·ªôp")

# =====================================================
# G·ªòP V√Ä LO·∫†I B·ªé TR√ôNG L·∫∂P (ML-BASED)
# =====================================================
merged_ml_entities = []
if ML_NER_AVAILABLE and ml_all_entities:
    print("\nüìä B∆∞·ªõc 2b: G·ªôp v√† lo·∫°i b·ªè tr√πng l·∫∑p (ML-based)...")
    unique_ml = {}
    
    for ent in ml_all_entities:
        # Chu·∫©n h√≥a text ƒë·ªÉ tr√°nh tr√πng do kh√°c kho·∫£ng tr·∫Øng / hoa th∆∞·ªùng
        normalized_text = clean_text(ent['text'])
        ent['text'] = normalized_text
        
        # T·∫°o key ƒë·ªÉ g·ªôp: CH·ªà merge c√°c entity ho√†n to√†n gi·ªëng nhau (sau khi normalize)
        normalized_lower = normalized_text.lower()
        key = (normalized_lower, ent['type'])
        
        if key not in unique_ml:
            unique_ml[key] = {**ent, 'sources': [ent.get('source_node', '')]}
        else:
            # G·ªôp sources - ch·ªâ merge n·∫øu text ho√†n to√†n gi·ªëng nhau (sau normalize)
            existing = unique_ml[key]
            source_node = ent.get('source_node', '')
            if source_node and source_node not in existing.get('sources', []):
                existing['sources'].append(source_node)
            # Gi·ªØ confidence cao nh·∫•t
            existing['confidence'] = max(existing.get('confidence', 0), ent.get('confidence', 0))
    
    merged_ml_entities = list(unique_ml.values())
    print(f"  ‚úì C√≤n {len(merged_ml_entities)} entities (ML-based) sau khi g·ªôp")

# =====================================================
# L·ªåC THEO CONTEXT K-POP V√Ä PH√ô H·ª¢P V·ªöI M·∫†NG L∆Ø·ªöI (RULE-BASED)
# =====================================================
print("\nüìä B∆∞·ªõc 3a: L·ªçc theo context K-pop v√† ph√π h·ª£p m·∫°ng l∆∞·ªõi (Rule-based)...")
filtered_rule_entities = []
removed_count_rule = defaultdict(int)
removed_reason_rule = defaultdict(lambda: defaultdict(int))

for ent in merged_rule_entities:
    sources = ent.get('sources', [ent.get('source_node', '')])
    entity_type = ent['type']
    entity_text = ent['text']
    
    # Safety filter b·ªï sung cho Group ƒë·ªÉ lo·∫°i b·ªè c√°c m·∫£nh t√™n sai c√≤n s√≥t nh∆∞ "Indie OKDAL Y"
    if entity_type == 'Group':
        low = entity_text.lower()
        if any(kw in low for kw in ['indie okdal', 'f ve', 'girl next door', 'girl next']):
            removed_count_rule[entity_type] += 1
            removed_reason_rule[entity_type]['post_filter_bad_group'] += 1
            continue
    
    # Known list (c√¥ng ty ƒë√£ bi·∫øt) -> lu√¥n gi·ªØ
    if ent.get('method') == 'known_list':
        filtered_rule_entities.append(ent)
        continue
    
    # Ki·ªÉm tra 1: Ph·∫£i c√≥ context K-pop
    if not has_kpop_context(sources):
        removed_count_rule[entity_type] += 1
        removed_reason_rule[entity_type]['no_kpop_context'] += 1
        continue
    
    # Ki·ªÉm tra 2a: N·∫øu entity ƒë∆∞·ª£c nh·∫≠n d·∫°ng l√† Artist nh∆∞ng c√≥ "album th√†nh vi√™n" trong context -> lo·∫°i b·ªè (v√¨ l√† album)
    if entity_type == 'Artist':
        is_album_context = False
        for source in sources:
            full_text = node_texts.get(source, '')
            if full_text and ('album th√†nh vi√™n' in full_text or 'album c·ªßa th√†nh vi√™n' in full_text):
                entity_lower = entity_text.lower()
                idx = full_text.find(entity_lower)
                if idx != -1:
                    start = max(0, idx - 50)
                    end = min(len(full_text), idx + len(entity_text) + 50)
                    context = full_text[start:end]
                    if 'album' in context and 'th√†nh vi√™n' in context:
                        is_album_context = True
                        break
        if is_album_context:
            removed_count_rule[entity_type] += 1
            removed_reason_rule[entity_type]['is_album_not_artist'] += 1
            continue
    
    # Ki·ªÉm tra 2b: Artist ph·∫£i l√† ngh·ªá sƒ© √¢m nh·∫°c (kh√¥ng ph·∫£i di·ªÖn vi√™n, MC...)
    if entity_type == 'Artist':
        if not is_music_artist(entity_text, sources):
            removed_count_rule[entity_type] += 1
            removed_reason_rule[entity_type]['not_music_artist'] += 1
            continue
    
    # Ki·ªÉm tra 3: Ph·∫£i li√™n quan ƒë·∫øn m·∫°ng l∆∞·ªõi hi·ªán c√≥
    if not is_related_to_existing_nodes(entity_text, sources, existing_lower):
        removed_count_rule[entity_type] += 1
        removed_reason_rule[entity_type]['not_related_to_network'] += 1
        continue
    
    # T√≠nh confidence d·ª±a tr√™n s·ªë ngu·ªìn
    num_sources = len(set(sources))
    if num_sources >= 5:
        ent['confidence'] = min(0.95, ent['confidence'] + 0.2)
    elif num_sources >= 3:
        ent['confidence'] = min(0.9, ent['confidence'] + 0.15)
    elif num_sources >= 2:
        ent['confidence'] = min(0.85, ent['confidence'] + 0.1)
    
    filtered_rule_entities.append(ent)

# =====================================================
# L·ªåC THEO CONTEXT K-POP V√Ä PH√ô H·ª¢P V·ªöI M·∫†NG L∆Ø·ªöI (ML-BASED)
# =====================================================
filtered_ml_entities = []
removed_count_ml = defaultdict(int)
removed_reason_ml = defaultdict(lambda: defaultdict(int))

if ML_NER_AVAILABLE and merged_ml_entities:
    print("\nüìä B∆∞·ªõc 3b: L·ªçc theo context K-pop v√† ph√π h·ª£p m·∫°ng l∆∞·ªõi (ML-based)...")
    
    for ent in merged_ml_entities:
        sources = ent.get('sources', [ent.get('source_node', '')])
        entity_type = ent['type']
        entity_text = ent['text']
        
        # Ki·ªÉm tra 1: Ph·∫£i c√≥ context K-pop
        if not has_kpop_context(sources):
            removed_count_ml[entity_type] += 1
            removed_reason_ml[entity_type]['no_kpop_context'] += 1
            continue
        
        # Ki·ªÉm tra 2: Artist ph·∫£i l√† ngh·ªá sƒ© √¢m nh·∫°c
        if entity_type == 'Artist':
            if not is_music_artist(entity_text, sources):
                removed_count_ml[entity_type] += 1
                removed_reason_ml[entity_type]['not_music_artist'] += 1
                continue
        
        # Ki·ªÉm tra 3: Ph·∫£i li√™n quan ƒë·∫øn m·∫°ng l∆∞·ªõi hi·ªán c√≥
        if not is_related_to_existing_nodes(entity_text, sources, existing_lower):
            removed_count_ml[entity_type] += 1
            removed_reason_ml[entity_type]['not_related_to_network'] += 1
            continue
        
        # Ki·ªÉm tra 4: Lo·∫°i b·ªè entities c√≥ confidence qu√° th·∫•p (< 0.65)
        if ent.get('confidence', 0) < 0.65:
            removed_count_ml[entity_type] += 1
            removed_reason_ml[entity_type]['ml_low_confidence'] += 1
            continue
        
        # T√≠nh confidence d·ª±a tr√™n s·ªë ngu·ªìn
        num_sources = len(set(sources))
        if num_sources >= 5:
            ent['confidence'] = min(0.95, ent['confidence'] + 0.2)
        elif num_sources >= 3:
            ent['confidence'] = min(0.9, ent['confidence'] + 0.15)
        elif num_sources >= 2:
            ent['confidence'] = min(0.85, ent['confidence'] + 0.1)
        
        filtered_ml_entities.append(ent)

# =====================================================
# B∆Ø·ªöC 4: CHU·∫®N H√ìA & G·ªòP L·∫†I L·∫¶N CU·ªêI (RULE-BASED)
# =====================================================
final_unique_rule = {}
for ent in filtered_rule_entities:
    norm_text = clean_text(ent['text'])
    ent['text'] = norm_text
    
    normalized_lower = norm_text.lower()
    key = (normalized_lower, ent['type'])
    
    if key not in final_unique_rule:
        final_unique_rule[key] = {**ent}
    else:
        existing = final_unique_rule[key]
        existing_sources = set(existing.get('sources', []))
        new_sources = set(ent.get('sources', []))
        existing['sources'] = list(existing_sources | new_sources)
        existing['confidence'] = max(existing.get('confidence', 0), ent.get('confidence', 0))

filtered_rule_entities = list(final_unique_rule.values())
print(f"  ‚úì C√≤n {len(filtered_rule_entities)} entities (rule-based) sau khi l·ªçc")

# =====================================================
# B∆Ø·ªöC 4: CHU·∫®N H√ìA & G·ªòP L·∫†I L·∫¶N CU·ªêI (ML-BASED)
# =====================================================
final_unique_ml = {}
for ent in filtered_ml_entities:
    norm_text = clean_text(ent['text'])
    ent['text'] = norm_text
    
    normalized_lower = norm_text.lower()
    key = (normalized_lower, ent['type'])
    
    if key not in final_unique_ml:
        final_unique_ml[key] = {**ent}
    else:
        existing = final_unique_ml[key]
        existing_sources = set(existing.get('sources', []))
        new_sources = set(ent.get('sources', []))
        existing['sources'] = list(existing_sources | new_sources)
        existing['confidence'] = max(existing.get('confidence', 0), ent.get('confidence', 0))

filtered_ml_entities = list(final_unique_ml.values())
if ML_NER_AVAILABLE:
    print(f"  ‚úì C√≤n {len(filtered_ml_entities)} entities (ML-based) sau khi l·ªçc")

# S·∫Øp x·∫øp theo confidence gi·∫£m d·∫ßn
filtered_rule_entities.sort(key=lambda x: (-x['confidence'], x['type'], x['text']))
if ML_NER_AVAILABLE:
    filtered_ml_entities.sort(key=lambda x: (-x['confidence'], x['type'], x['text']))

# ƒê·∫øm theo type
counts_rule = defaultdict(int)
for ent in filtered_rule_entities:
    counts_rule[ent['type']] += 1

counts_ml = defaultdict(int)
if ML_NER_AVAILABLE:
    for ent in filtered_ml_entities:
        counts_ml[ent['type']] += 1

# =====================================================
# L∆ØU K·∫æT QU·∫¢ (RULE-BASED)
# =====================================================
output_rule = {
    'metadata': {
        'description': 'Th·ª±c th·ªÉ K-pop ƒë∆∞·ª£c nh·∫≠n d·∫°ng v√† l·ªçc (Rule-based)',
        'processed_at': datetime.now().isoformat(),
        'total_records': len(records),
        'raw_entities': len(all_entities),
        'merged_entities': len(merged_rule_entities),
        'final_entities': len(filtered_rule_entities),
        'entities_by_type': dict(counts_rule),
        'filter_criteria': [
            'Ph·∫£i c√≥ context K-pop (>=3 t·ª´ kh√≥a K-pop trong vƒÉn b·∫£n ngu·ªìn)',
            'Artist: Ph·∫£i c√≥ t·ª´ kh√≥a vai tr√≤ √¢m nh·∫°c (ca sƒ©, rapper, th√†nh vi√™n...)',
            'Artist: Lo·∫°i tr·ª´ di·ªÖn vi√™n, MC, v·∫≠n ƒë·ªông vi√™n, nh√† vƒÉn...',
            'Ph·∫£i li√™n quan ƒë·∫øn √≠t nh·∫•t 1 node hi·ªán c√≥ trong m·∫°ng l∆∞·ªõi',
            'T√™n ph·∫£i b·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ in hoa ho·∫∑c s·ªë',
            'Kh√¥ng ch·ª©a t·ª´ chung chung'
        ]
    },
    'entities': filtered_rule_entities
}

with open('kpop_ner_result.json', 'w', encoding='utf-8') as f:
    json.dump(output_rule, f, ensure_ascii=False, indent=2)

# =====================================================
# L∆ØU K·∫æT QU·∫¢ (ML-BASED)
# =====================================================
if ML_NER_AVAILABLE:
    output_ml = {
        'metadata': {
            'description': 'Th·ª±c th·ªÉ K-pop ƒë∆∞·ª£c nh·∫≠n d·∫°ng v√† l·ªçc (ML-based)',
            'processed_at': datetime.now().isoformat(),
            'total_records': len(records),
            'raw_entities': len(ml_all_entities),
            'merged_entities': len(merged_ml_entities),
            'final_entities': len(filtered_ml_entities),
            'entities_by_type': dict(counts_ml),
            'ml_model': 'NlpHUST/ner-vietnamese-electra-base',
            'filter_criteria': [
                'Ph·∫£i c√≥ context K-pop (>=3 t·ª´ kh√≥a K-pop trong vƒÉn b·∫£n ngu·ªìn)',
                'Artist: Ph·∫£i c√≥ t·ª´ kh√≥a vai tr√≤ √¢m nh·∫°c (ca sƒ©, rapper, th√†nh vi√™n...)',
                'Artist: Lo·∫°i tr·ª´ di·ªÖn vi√™n, MC, v·∫≠n ƒë·ªông vi√™n, nh√† vƒÉn...',
                'Ph·∫£i li√™n quan ƒë·∫øn √≠t nh·∫•t 1 node hi·ªán c√≥ trong m·∫°ng l∆∞·ªõi',
                'Confidence >= 0.65',
                'T√™n ph·∫£i b·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ in hoa ho·∫∑c s·ªë',
                'Kh√¥ng ch·ª©a t·ª´ chung chung'
            ]
        },
        'entities': filtered_ml_entities
    }
    
    with open('kpop_ner_ml_result.json', 'w', encoding='utf-8') as f:
        json.dump(output_ml, f, ensure_ascii=False, indent=2)

# =====================================================
# IN K·∫æT QU·∫¢
# =====================================================
print("\n" + "=" * 70)
print("K·∫æT QU·∫¢ NH·∫¨N D·∫†NG TH·ª∞C TH·ªÇ K-POP")
print("=" * 70)
print(f"‚úì ƒê√£ l∆∞u: kpop_ner_result.json (Rule-based)")
if ML_NER_AVAILABLE:
    print(f"‚úì ƒê√£ l∆∞u: kpop_ner_ml_result.json (ML-based)")

print(f"\nüìä TH·ªêNG K√ä RULE-BASED:")
print(f"   Records x·ª≠ l√Ω: {len(records)}")
print(f"   Entities th√¥: {len(all_entities)}")
print(f"   Sau khi g·ªôp: {len(merged_rule_entities)}")
print(f"   Sau khi l·ªçc K-pop: {len(filtered_rule_entities)}")

print(f"\n   Ph√¢n lo·∫°i cu·ªëi c√πng (Rule-based):")
for t in ['Company', 'Group', 'Artist', 'Album', 'Song']:
    print(f"     - {t}: {counts_rule.get(t, 0)}")

print(f"\n   S·ªë entities b·ªã lo·∫°i (Rule-based):")
for t in ['Company', 'Group', 'Artist', 'Album', 'Song']:
    total_removed = removed_count_rule.get(t, 0)
    if total_removed > 0:
        reasons = removed_reason_rule.get(t, {})
        print(f"     - {t}: {total_removed}")
        for reason, count in reasons.items():
            reason_text = {
                'no_kpop_context': 'Thi·∫øu context K-pop',
                'not_music_artist': 'Kh√¥ng ph·∫£i ngh·ªá sƒ© √¢m nh·∫°c',
                'not_related_to_network': 'Kh√¥ng li√™n quan m·∫°ng l∆∞·ªõi'
            }.get(reason, reason)
            print(f"         + {reason_text}: {count}")

if ML_NER_AVAILABLE:
    print(f"\nüìä TH·ªêNG K√ä ML-BASED:")
    print(f"   Entities th√¥: {len(ml_all_entities)}")
    print(f"   Sau khi g·ªôp: {len(merged_ml_entities)}")
    print(f"   Sau khi l·ªçc K-pop: {len(filtered_ml_entities)}")
    
    print(f"\n   Ph√¢n lo·∫°i cu·ªëi c√πng (ML-based):")
    for t in ['Company', 'Group', 'Artist', 'Album', 'Song']:
        print(f"     - {t}: {counts_ml.get(t, 0)}")
    
    print(f"\n   S·ªë entities b·ªã lo·∫°i (ML-based):")
    for t in ['Company', 'Group', 'Artist', 'Album', 'Song']:
        total_removed = removed_count_ml.get(t, 0)
        if total_removed > 0:
            reasons = removed_reason_ml.get(t, {})
            print(f"     - {t}: {total_removed}")
            for reason, count in reasons.items():
                reason_text = {
                    'no_kpop_context': 'Thi·∫øu context K-pop',
                    'not_music_artist': 'Kh√¥ng ph·∫£i ngh·ªá sƒ© √¢m nh·∫°c',
                    'not_related_to_network': 'Kh√¥ng li√™n quan m·∫°ng l∆∞·ªõi',
                    'ml_low_confidence': 'Confidence < 0.65'
                }.get(reason, reason)
                print(f"         + {reason_text}: {count}")

# Hi·ªÉn th·ªã top entities
print(f"\nüìù TOP ENTITIES THEO ƒê·ªò TIN C·∫¨Y (Rule-based):")
for t in ['Company', 'Group', 'Artist', 'Album', 'Song']:
    items = [e for e in filtered_rule_entities if e['type'] == t][:10]
    if items:
        print(f"\n   {t} (top 10):")
        for i, e in enumerate(items, 1):
            src = len(set(e.get('sources', [])))
            print(f"     {i}. {e['text']} (conf: {e['confidence']:.2f}, {src} ngu·ªìn)")

if ML_NER_AVAILABLE and filtered_ml_entities:
    print(f"\nüìù TOP ENTITIES THEO ƒê·ªò TIN C·∫¨Y (ML-based):")
    for t in ['Company', 'Group', 'Artist', 'Album', 'Song']:
        items = [e for e in filtered_ml_entities if e['type'] == t][:10]
        if items:
            print(f"\n   {t} (top 10):")
            for i, e in enumerate(items, 1):
                src = len(set(e.get('sources', [])))
                print(f"     {i}. {e['text']} (conf: {e['confidence']:.2f}, {src} ngu·ªìn)")

print("\n‚úÖ HO√ÄN T·∫§T!")
