{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ph√¢n t√≠ch M·∫°ng X√£ H·ªôi K-pop\n",
    "\n",
    "Notebook n√†y th·ª±c hi·ªán c√°c thu·∫≠t to√°n ph√¢n t√≠ch m·∫°ng x√£ h·ªôi:\n",
    "\n",
    "1. **Ch·ª©ng minh kh√°i ni·ªám th·∫ø gi·ªõi nh·ªè (Small World)**: T√≠nh Average Shortest Path Length v√† Clustering Coefficient\n",
    "2. **X·∫øp h·∫°ng c√°c node b·∫±ng PageRank**: X√°c ƒë·ªãnh c√°c node quan tr·ªçng nh·∫•t trong m·∫°ng\n",
    "3. **Ph√°t hi·ªán c·ªông ƒë·ªìng (Community Detection)**: T√¨m c√°c c·ªông ƒë·ªìng trong m·∫°ng K-pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import th∆∞ vi·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Import th∆∞ vi·ªán th√†nh c√¥ng\n",
      "NetworkX version: 3.3\n",
      "‚úì Matplotlib ƒë√£ s·∫µn s√†ng\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import io\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "# ƒê·ªïi working directory v·ªÅ root c·ªßa project (n·∫øu ƒëang ch·∫°y t·ª´ notebooks/)\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'notebooks':\n",
    "    os.chdir(current_dir.parent)\n",
    "    print(f\"‚úì ƒê√£ ƒë·ªïi working directory v·ªÅ: {os.getcwd()}\")\n",
    "\n",
    "# Robust UTF-8 console output on Windows\n",
    "if sys.platform == 'win32':\n",
    "    try:\n",
    "        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')\n",
    "        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "try:\n",
    "    import networkx as nx\n",
    "    print(\"‚úì Import th∆∞ vi·ªán th√†nh c√¥ng\")\n",
    "    print(f\"NetworkX version: {nx.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå NetworkX ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. Ch·∫°y: pip install networkx\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')  # Non-interactive backend\n",
    "    print(\"‚úì Matplotlib ƒë√£ s·∫µn s√†ng\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  Matplotlib ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. Ch·∫°y: pip install matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ƒê√£ load t·ª´ data/merged_kpop_data.json\n",
      "  - Nodes: 4597\n",
      "  - Edges: 6112\n",
      "\n",
      "üìä TH·ªêNG K√ä T·ª™ METADATA:\n",
      "  - T·ªïng nodes: 4597\n",
      "  - T·ªïng edges: 6112\n",
      "\n",
      "  üìã Nodes theo lo·∫°i:\n",
      "    - Song: 1637\n",
      "    - Artist: 1378\n",
      "    - Album: 745\n",
      "    - Company: 324\n",
      "    - Group: 246\n",
      "    - Genre: 175\n",
      "    - Occupation: 60\n",
      "    - Instrument: 32\n",
      "\n",
      "  üìã Edges theo lo·∫°i:\n",
      "    - MEMBER_OF: 1490\n",
      "    - IS_GENRE: 1072\n",
      "    - SINGS: 1017\n",
      "    - MANAGED_BY: 858\n",
      "    - HAS_OCCUPATION: 711\n",
      "    - RELEASED: 354\n",
      "    - WROTE: 169\n",
      "    - CONTAINS: 165\n",
      "    - PLAYS: 155\n",
      "    - PRODUCED_ALBUM: 43\n",
      "    - PRODUCED_SONG: 42\n",
      "    - SUBUNIT_OF: 36\n",
      "\n",
      "üìä T·ªïng c·ªông: 4597 nodes, 6112 edges\n"
     ]
    }
   ],
   "source": [
    "def load_graph_data(\n",
    "    merged_file: str = \"data/merged_kpop_data.json\"\n",
    ") -> Tuple[Dict, List]:\n",
    "    \"\"\"Load d·ªØ li·ªáu t·ª´ file merged\"\"\"\n",
    "    # T·ª± ƒë·ªông t√¨m ƒë√∫ng ƒë∆∞·ªùng d·∫´n n·∫øu file kh√¥ng t·ªìn t·∫°i ·ªü v·ªã tr√≠ hi·ªán t·∫°i\n",
    "    if not os.path.exists(merged_file):\n",
    "        # Th·ª≠ t√¨m t·ª´ root c·ªßa project\n",
    "        root_dir = Path.cwd()\n",
    "        if root_dir.name == 'notebooks':\n",
    "            root_dir = root_dir.parent\n",
    "        alt_path = root_dir / merged_file\n",
    "        if alt_path.exists():\n",
    "            merged_file = str(alt_path)\n",
    "        else:\n",
    "            # Th·ª≠ ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi t·ª´ notebooks/\n",
    "            alt_path = Path('..') / merged_file\n",
    "            if alt_path.exists():\n",
    "                merged_file = str(alt_path.resolve())\n",
    "    \n",
    "    try:\n",
    "        with open(merged_file, 'r', encoding='utf-8') as f:\n",
    "            merged_data = json.load(f)\n",
    "        \n",
    "        nodes = merged_data.get(\"nodes\", {})\n",
    "        edges = merged_data.get(\"edges\", [])\n",
    "        metadata = merged_data.get(\"metadata\", {})\n",
    "        \n",
    "        print(f\"‚úì ƒê√£ load t·ª´ {merged_file}\")\n",
    "        print(f\"  - Nodes: {len(nodes)}\")\n",
    "        print(f\"  - Edges: {len(edges)}\")\n",
    "        \n",
    "        if metadata:\n",
    "            print(f\"\\nüìä TH·ªêNG K√ä T·ª™ METADATA:\")\n",
    "            if \"total_nodes\" in metadata:\n",
    "                print(f\"  - T·ªïng nodes: {metadata['total_nodes']}\")\n",
    "            if \"total_edges\" in metadata:\n",
    "                print(f\"  - T·ªïng edges: {metadata['total_edges']}\")\n",
    "            if \"nodes_by_type\" in metadata:\n",
    "                print(f\"\\n  üìã Nodes theo lo·∫°i:\")\n",
    "                for node_type, count in sorted(metadata[\"nodes_by_type\"].items(), key=lambda x: -x[1]):\n",
    "                    print(f\"    - {node_type}: {count}\")\n",
    "            if \"edges_by_type\" in metadata:\n",
    "                print(f\"\\n  üìã Edges theo lo·∫°i:\")\n",
    "                for edge_type, count in sorted(metadata[\"edges_by_type\"].items(), key=lambda x: -x[1]):\n",
    "                    print(f\"    - {edge_type}: {count}\")\n",
    "        \n",
    "        print(f\"\\nüìä T·ªïng c·ªông: {len(nodes)} nodes, {len(edges)} edges\")\n",
    "        return nodes, edges\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y {merged_file}\")\n",
    "        print(\"   Vui l√≤ng ch·∫°y merge_and_import_neo4j.py ƒë·ªÉ t·∫°o file merged tr∆∞·ªõc\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi load file: {e}\")\n",
    "        raise\n",
    "\n",
    "# Load d·ªØ li·ªáu\n",
    "nodes, edges = load_graph_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. X√¢y d·ª±ng NetworkX Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Graph c√≥ 4597 nodes v√† 6069 edges\n",
      "\n",
      "üìä TH·ªêNG K√ä NODES THEO LABEL:\n",
      "  Song: 1637 (35.6%)\n",
      "  Artist: 1378 (30.0%)\n",
      "  Album: 745 (16.2%)\n",
      "  Company: 324 (7.0%)\n",
      "  Group: 246 (5.4%)\n",
      "  Genre: 175 (3.8%)\n",
      "  Occupation: 60 (1.3%)\n",
      "  Instrument: 32 (0.7%)\n"
     ]
    }
   ],
   "source": [
    "def build_networkx_graph(nodes: Dict, edges: List, undirected: bool = True) -> nx.Graph:\n",
    "    \"\"\"X√¢y d·ª±ng NetworkX graph t·ª´ nodes v√† edges\"\"\"\n",
    "    if undirected:\n",
    "        G = nx.Graph()\n",
    "    else:\n",
    "        G = nx.DiGraph()\n",
    "    \n",
    "    # Th√™m nodes\n",
    "    for node_id, node_data in nodes.items():\n",
    "        G.add_node(node_id, **{\n",
    "            'label': node_data.get('label', 'Entity'),\n",
    "            'title': node_data.get('title', node_id)\n",
    "        })\n",
    "    \n",
    "    # Th√™m edges\n",
    "    for edge in edges:\n",
    "        src = edge.get('source')\n",
    "        tgt = edge.get('target')\n",
    "        if src and tgt and src in nodes and tgt in nodes:\n",
    "            G.add_edge(src, tgt, type=edge.get('type', 'RELATED_TO'))\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Build graph\n",
    "G = build_networkx_graph(nodes, edges, undirected=True)\n",
    "print(f\"‚úì Graph c√≥ {G.number_of_nodes()} nodes v√† {G.number_of_edges()} edges\")\n",
    "\n",
    "# Th·ªëng k√™ nodes theo label\n",
    "label_counts = defaultdict(int)\n",
    "for node_id in G.nodes():\n",
    "    label = G.nodes[node_id].get('label', 'Unknown')\n",
    "    label_counts[label] += 1\n",
    "\n",
    "print(f\"\\nüìä TH·ªêNG K√ä NODES THEO LABEL:\")\n",
    "for label, count in sorted(label_counts.items(), key=lambda x: -x[1]):\n",
    "    percentage = 100 * count / G.number_of_nodes()\n",
    "    print(f\"  {label}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ph√¢n t√≠ch Kh√°i ni·ªám Th·∫ø gi·ªõi Nh·ªè (Small World)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "1. PH√ÇN T√çCH KH√ÅI NI·ªÜM TH·∫æ GI·ªöI NH·ªé (SMALL WORLD)\n",
      "======================================================================\n",
      "\n",
      "üìä Graph c√≥ 1801 connected components\n",
      "   Largest component: 2768 nodes (60.2%)\n",
      "\n",
      "üîç T√≠nh Average Shortest Path Length (APL)...\n",
      "   ‚úì Average Shortest Path Length: 4.4670\n",
      "\n",
      "üîç T√≠nh Clustering Coefficient...\n",
      "   ‚úì Average Clustering Coefficient: 0.0557\n",
      "\n",
      "üîç T√≠nh Diameter...\n",
      "   ‚úì Diameter: 11\n"
     ]
    }
   ],
   "source": [
    "def analyze_small_world(G: 'nx.Graph') -> Tuple[Dict[str, Any], 'nx.Graph']:\n",
    "    \"\"\"\n",
    "    Ph√¢n t√≠ch kh√°i ni·ªám Small World:\n",
    "    - T√≠nh Average Shortest Path Length (APL)\n",
    "    - T√≠nh Clustering Coefficient\n",
    "    - So s√°nh v·ªõi random graph c√πng k√≠ch th∆∞·ªõc\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"1. PH√ÇN T√çCH KH√ÅI NI·ªÜM TH·∫æ GI·ªöI NH·ªé (SMALL WORLD)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    results = {\n",
    "        \"total_nodes\": G.number_of_nodes(),\n",
    "        \"total_edges\": G.number_of_edges(),\n",
    "    }\n",
    "    \n",
    "    # Ki·ªÉm tra connected components\n",
    "    if nx.is_connected(G):\n",
    "        components = [G]\n",
    "        largest_cc = G\n",
    "        print(f\"\\nüìä Graph l√† connected v·ªõi {G.number_of_nodes()} nodes\")\n",
    "    else:\n",
    "        components = list(nx.connected_components(G))\n",
    "        largest_cc = G.subgraph(max(components, key=len)).copy()\n",
    "        print(f\"\\nüìä Graph c√≥ {len(components)} connected components\")\n",
    "        print(f\"   Largest component: {largest_cc.number_of_nodes()} nodes ({100*largest_cc.number_of_nodes()/G.number_of_nodes():.1f}%)\")\n",
    "    \n",
    "    results[\"num_components\"] = len(components) if not nx.is_connected(G) else 1\n",
    "    results[\"largest_component_size\"] = largest_cc.number_of_nodes()\n",
    "    results[\"largest_component_percentage\"] = 100 * largest_cc.number_of_nodes() / G.number_of_nodes()\n",
    "    \n",
    "    # T√≠nh Average Shortest Path Length tr√™n largest component\n",
    "    print(\"\\nüîç T√≠nh Average Shortest Path Length (APL)...\")\n",
    "    \n",
    "    n = largest_cc.number_of_nodes()\n",
    "    m = largest_cc.number_of_edges()\n",
    "    \n",
    "    if n > 5000:\n",
    "        # Sampling cho graph l·ªõn\n",
    "        print(f\"   Graph l·ªõn ({n} nodes), s·ª≠ d·ª•ng sampling...\")\n",
    "        sample_size = min(1000, n)\n",
    "        sample_nodes = random.sample(list(largest_cc.nodes()), sample_size)\n",
    "        \n",
    "        total_paths = 0\n",
    "        path_count = 0\n",
    "        \n",
    "        for i, source in enumerate(sample_nodes):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"   ƒêang x·ª≠ l√Ω node {i}/{sample_size}...\")\n",
    "            lengths = nx.single_source_shortest_path_length(largest_cc, source)\n",
    "            for target, length in lengths.items():\n",
    "                if source != target:\n",
    "                    total_paths += length\n",
    "                    path_count += 1\n",
    "        \n",
    "        if path_count > 0:\n",
    "            apl = total_paths / path_count\n",
    "        else:\n",
    "            apl = float('inf')\n",
    "        print(f\"   (∆Ø·ªõc l∆∞·ª£ng t·ª´ {sample_size} nodes)\")\n",
    "    else:\n",
    "        apl = nx.average_shortest_path_length(largest_cc)\n",
    "    \n",
    "    results[\"average_path_length\"] = apl\n",
    "    print(f\"   ‚úì Average Shortest Path Length: {apl:.4f}\")\n",
    "    \n",
    "    # T√≠nh Clustering Coefficient\n",
    "    print(\"\\nüîç T√≠nh Clustering Coefficient...\")\n",
    "    avg_clustering = nx.average_clustering(G)\n",
    "    results[\"clustering_coefficient\"] = avg_clustering\n",
    "    print(f\"   ‚úì Average Clustering Coefficient: {avg_clustering:.4f}\")\n",
    "    \n",
    "    # T√≠nh diameter (ƒë∆∞·ªùng k√≠nh)\n",
    "    print(\"\\nüîç T√≠nh Diameter...\")\n",
    "    if n <= 5000:\n",
    "        diameter = nx.diameter(largest_cc)\n",
    "    else:\n",
    "        # ∆Ø·ªõc l∆∞·ª£ng diameter b·∫±ng sampling\n",
    "        sample_nodes = random.sample(list(largest_cc.nodes()), min(100, n))\n",
    "        max_dist = 0\n",
    "        for node in sample_nodes:\n",
    "            eccentricity = nx.eccentricity(largest_cc, v=node)\n",
    "            max_dist = max(max_dist, eccentricity)\n",
    "        diameter = max_dist\n",
    "        print(f\"   (∆Ø·ªõc l∆∞·ª£ng t·ª´ sampling)\")\n",
    "    results[\"diameter\"] = diameter\n",
    "    print(f\"   ‚úì Diameter: {diameter}\")\n",
    "    \n",
    "    return results, largest_cc\n",
    "\n",
    "# Ch·∫°y ph√¢n t√≠ch Small World\n",
    "small_world_results, largest_cc = analyze_small_world(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç So s√°nh v·ªõi Random Graph (Erd≈ës‚ÄìR√©nyi)...\n",
      "   Average Degree: 4.36\n",
      "   Random Graph Expected APL: 5.3798\n",
      "   Random Graph Expected Clustering: 0.001576\n",
      "\n",
      "üìä Small World Sigma (œÉ): 42.5459\n",
      "   ‚úì œÉ > 1: M·∫°ng c√≥ t√≠nh ch·∫•t TH·∫æ GI·ªöI NH·ªé (Small World)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "üìã K·∫æT LU·∫¨N V·ªÄ KH√ÅI NI·ªÜM TH·∫æ GI·ªöI NH·ªé:\n",
      "----------------------------------------------------------------------\n",
      "   ‚úì APL = 4.47 kh√° th·∫•p (< 2*ln(n) = 15.85)\n",
      "   ‚úì Clustering = 0.0557 cao h∆°n random 35.3x\n",
      "   ‚úì APL ‚â§ 6: Tu√¢n theo 'Six Degrees of Separation'\n",
      "\n",
      "üéØ K·∫æT LU·∫¨N: M·∫°ng K-pop TH·ªéA M√ÉN t√≠nh ch·∫•t TH·∫æ GI·ªöI NH·ªé (Small World)\n",
      "   - B·∫•t k·ª≥ 2 node n√†o c≈©ng c√≥ th·ªÉ k·∫øt n·ªëi qua trung b√¨nh 4.5 b∆∞·ªõc\n",
      "   - C√°c node c√≥ xu h∆∞·ªõng t·∫°o th√†nh c√°c c·ª•m (cluster) c·ª•c b·ªô\n"
     ]
    }
   ],
   "source": [
    "# So s√°nh v·ªõi Random Graph (Erd≈ës‚ÄìR√©nyi)\n",
    "print(\"\\nüîç So s√°nh v·ªõi Random Graph (Erd≈ës‚ÄìR√©nyi)...\")\n",
    "\n",
    "n = largest_cc.number_of_nodes()\n",
    "m = largest_cc.number_of_edges()\n",
    "p = 2 * m / (n * (n - 1)) if n > 1 else 0  # Probability ƒë·ªÉ c√≥ c√πng s·ªë edges\n",
    "\n",
    "# L√Ω thuy·∫øt cho random graph:\n",
    "avg_degree = 2 * m / n if n > 0 else 0\n",
    "\n",
    "if avg_degree > 1:\n",
    "    expected_apl_random = math.log(n) / math.log(avg_degree) if avg_degree > 1 else float('inf')\n",
    "else:\n",
    "    expected_apl_random = float('inf')\n",
    "expected_clustering_random = avg_degree / n if n > 0 else 0\n",
    "\n",
    "small_world_results[\"random_graph_expected_apl\"] = expected_apl_random\n",
    "small_world_results[\"random_graph_expected_clustering\"] = expected_clustering_random\n",
    "small_world_results[\"average_degree\"] = avg_degree\n",
    "\n",
    "print(f\"   Average Degree: {avg_degree:.2f}\")\n",
    "print(f\"   Random Graph Expected APL: {expected_apl_random:.4f}\")\n",
    "print(f\"   Random Graph Expected Clustering: {expected_clustering_random:.6f}\")\n",
    "\n",
    "# Small World Index\n",
    "# œÉ = (C/C_random) / (L/L_random)\n",
    "# œÉ > 1 indicates small world property\n",
    "apl = small_world_results[\"average_path_length\"]\n",
    "avg_clustering = small_world_results[\"clustering_coefficient\"]\n",
    "\n",
    "if expected_clustering_random > 0 and expected_apl_random > 0 and expected_apl_random != float('inf'):\n",
    "    sigma = (avg_clustering / expected_clustering_random) / (apl / expected_apl_random)\n",
    "    small_world_results[\"small_world_sigma\"] = sigma\n",
    "    print(f\"\\nüìä Small World Sigma (œÉ): {sigma:.4f}\")\n",
    "    \n",
    "    if sigma > 1:\n",
    "        print(\"   ‚úì œÉ > 1: M·∫°ng c√≥ t√≠nh ch·∫•t TH·∫æ GI·ªöI NH·ªé (Small World)\")\n",
    "    else:\n",
    "        print(\"   ‚úó œÉ ‚â§ 1: M·∫°ng kh√¥ng th·ªÉ hi·ªán t√≠nh ch·∫•t Small World r√µ r√†ng\")\n",
    "else:\n",
    "    small_world_results[\"small_world_sigma\"] = None\n",
    "\n",
    "# K·∫øt lu·∫≠n\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"üìã K·∫æT LU·∫¨N V·ªÄ KH√ÅI NI·ªÜM TH·∫æ GI·ªöI NH·ªé:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "conclusions = []\n",
    "\n",
    "# APL th·∫•p?\n",
    "if apl < math.log(n) * 2:\n",
    "    conclusions.append(f\"‚úì APL = {apl:.2f} kh√° th·∫•p (< 2*ln(n) = {math.log(n)*2:.2f})\")\n",
    "    small_world_results[\"low_apl\"] = True\n",
    "else:\n",
    "    conclusions.append(f\"‚úó APL = {apl:.2f} kh√° cao\")\n",
    "    small_world_results[\"low_apl\"] = False\n",
    "\n",
    "# Clustering cao?\n",
    "if avg_clustering > expected_clustering_random * 10:\n",
    "    conclusions.append(f\"‚úì Clustering = {avg_clustering:.4f} cao h∆°n random {avg_clustering/expected_clustering_random:.1f}x\")\n",
    "    small_world_results[\"high_clustering\"] = True\n",
    "else:\n",
    "    conclusions.append(f\"‚úó Clustering = {avg_clustering:.4f} kh√¥ng cao h∆°n random ƒë√°ng k·ªÉ\")\n",
    "    small_world_results[\"high_clustering\"] = False\n",
    "\n",
    "# Six Degrees of Separation?\n",
    "if apl <= 6:\n",
    "    conclusions.append(f\"‚úì APL ‚â§ 6: Tu√¢n theo 'Six Degrees of Separation'\")\n",
    "    small_world_results[\"six_degrees\"] = True\n",
    "else:\n",
    "    conclusions.append(f\"‚úó APL > 6: Kh√¥ng tu√¢n theo 'Six Degrees of Separation' nghi√™m ng·∫∑t\")\n",
    "    small_world_results[\"six_degrees\"] = False\n",
    "\n",
    "for c in conclusions:\n",
    "    print(f\"   {c}\")\n",
    "\n",
    "if small_world_results.get(\"low_apl\") and small_world_results.get(\"high_clustering\"):\n",
    "    print(\"\\nüéØ K·∫æT LU·∫¨N: M·∫°ng K-pop TH·ªéA M√ÉN t√≠nh ch·∫•t TH·∫æ GI·ªöI NH·ªé (Small World)\")\n",
    "    print(f\"   - B·∫•t k·ª≥ 2 node n√†o c≈©ng c√≥ th·ªÉ k·∫øt n·ªëi qua trung b√¨nh {apl:.1f} b∆∞·ªõc\")\n",
    "    print(f\"   - C√°c node c√≥ xu h∆∞·ªõng t·∫°o th√†nh c√°c c·ª•m (cluster) c·ª•c b·ªô\")\n",
    "    small_world_results[\"is_small_world\"] = True\n",
    "else:\n",
    "    print(\"\\nüéØ K·∫æT LU·∫¨N: M·∫°ng c√≥ m·ªôt s·ªë ƒë·∫∑c ƒëi·ªÉm c·ªßa Small World nh∆∞ng ch∆∞a ho√†n to√†n\")\n",
    "    small_world_results[\"is_small_world\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä V·∫Ω bi·ªÉu ƒë·ªì ph√¢n b·ªë...\n",
      "‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì v√†o small_world_analysis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15472\\3164417652.py:39: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# V·∫Ω bi·ªÉu ƒë·ªì ph√¢n b·ªë\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    MATPLOTLIB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MATPLOTLIB_AVAILABLE = False\n",
    "\n",
    "if MATPLOTLIB_AVAILABLE:\n",
    "    print(\"\\nüìä V·∫Ω bi·ªÉu ƒë·ªì ph√¢n b·ªë...\")\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì ph√¢n b·ªë degree\n",
    "    degrees = [G.degree(n) for n in G.nodes()]\n",
    "    ax1.hist(degrees, bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax1.set_xlabel('Degree')\n",
    "    ax1.set_ylabel('S·ªë l∆∞·ª£ng nodes')\n",
    "    ax1.set_title('Ph√¢n b·ªë Degree')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Bi·ªÉu ƒë·ªì ph√¢n b·ªë shortest path length\n",
    "    if n <= 5000:\n",
    "        path_lengths = []\n",
    "        for source in list(largest_cc.nodes())[:100]:  # Sample ƒë·ªÉ nhanh h∆°n\n",
    "            lengths = nx.single_source_shortest_path_length(largest_cc, source)\n",
    "            for target, length in lengths.items():\n",
    "                if source != target:\n",
    "                    path_lengths.append(length)\n",
    "        \n",
    "        ax2.hist(path_lengths, bins=20, edgecolor='black', alpha=0.7, color='orange')\n",
    "        ax2.set_xlabel('Shortest Path Length')\n",
    "        ax2.set_ylabel('S·ªë l∆∞·ª£ng c·∫∑p nodes')\n",
    "        ax2.set_title('Ph√¢n b·ªë Shortest Path Length')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('small_world_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì v√†o small_world_analysis.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. X·∫øp h·∫°ng Node b·∫±ng PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "2. X·∫æP H·∫†NG NODE B·∫∞NG PAGERANK\n",
      "======================================================================\n",
      "\n",
      "üîç ƒêang t√≠nh PageRank...\n",
      "\n",
      "üìä TOP 30 NODES THEO PAGERANK:\n",
      "----------------------------------------------------------------------\n",
      "Rank   Node                                     PageRank     Label\n",
      "----------------------------------------------------------------------\n",
      "1      Occupation_Di·ªÖn vi√™n                     0.01277450   Occupation\n",
      "2      Genre_R&B                                0.01116291   Genre\n",
      "3      Genre_Dance-pop                          0.00708700   Genre\n",
      "4      Genre_Hip hop                            0.00674824   Genre\n",
      "5      BTS                                      0.00578399   Album\n",
      "6      Occupation_Nh·∫°c sƒ©                       0.00572859   Occupation\n",
      "7      Genre_Pop                                0.00550830   Genre\n",
      "8      Girls' Generation                        0.00520115   Album\n",
      "9      T-ara                                    0.00502654   Group\n",
      "10     EXO                                      0.00455042   Group\n",
      "11     Genre_Ballad                             0.00426848   Genre\n",
      "12     TWICE                                    0.00413477   Group\n",
      "13     Super Junior                             0.00404905   Group\n",
      "14     GFriend                                  0.00396815   Group\n",
      "15     BLACKPINK                                0.00387222   Group\n",
      "16     Genre_Dance                              0.00376071   Genre\n",
      "17     Occupation_Rapper                        0.00375184   Occupation\n",
      "18     Company_JYP Entertainment                0.00367229   Company\n",
      "19     G-Dragon                                 0.00353127   Artist\n",
      "20     Big Bang (nh√≥m nh·∫°c)                     0.00319265   Group\n",
      "21     Company_SM Entertainment                 0.00318105   Company\n",
      "22     Occupation_V≈© C√¥ng                       0.00310895   Occupation\n",
      "23     Genre_J-pop                              0.00299624   Genre\n",
      "24     Taeyeon                                  0.00289062   Artist\n",
      "25     IZ*ONE                                   0.00285076   Group\n",
      "26     Mnet                                     0.00284135   Group\n",
      "27     TVXQ                                     0.00281505   Group\n",
      "28     Apink                                    0.00275887   Group\n",
      "29     SM Entertainment                         0.00271852   Artist\n",
      "30     Instrument_Piano                         0.00247103   Instrument\n"
     ]
    }
   ],
   "source": [
    "def analyze_pagerank(G: 'nx.Graph', top_k: int = 50) -> Tuple[Dict[str, Any], Dict, List]:\n",
    "    \"\"\"\n",
    "    X·∫øp h·∫°ng nodes b·∫±ng thu·∫≠t to√°n PageRank\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"2. X·∫æP H·∫†NG NODE B·∫∞NG PAGERANK\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # T√≠nh PageRank\n",
    "    print(\"\\nüîç ƒêang t√≠nh PageRank...\")\n",
    "    pagerank = nx.pagerank(G, alpha=0.85, max_iter=100)\n",
    "    \n",
    "    # S·∫Øp x·∫øp theo PageRank gi·∫£m d·∫ßn\n",
    "    sorted_pagerank = sorted(pagerank.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    results[\"total_nodes\"] = len(pagerank)\n",
    "    results[\"top_nodes\"] = []\n",
    "    \n",
    "    print(f\"\\nüìä TOP {top_k} NODES THEO PAGERANK:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Rank':<6} {'Node':<40} {'PageRank':<12} {'Label'}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for i, (node, score) in enumerate(sorted_pagerank[:top_k], 1):\n",
    "        label = G.nodes[node].get('label', 'Unknown')\n",
    "        print(f\"{i:<6} {node[:38]:<40} {score:.8f}   {label}\")\n",
    "        results[\"top_nodes\"].append({\n",
    "            \"rank\": i,\n",
    "            \"node\": node,\n",
    "            \"pagerank\": score,\n",
    "            \"label\": label\n",
    "        })\n",
    "    \n",
    "    return results, pagerank, sorted_pagerank\n",
    "\n",
    "# Ch·∫°y ph√¢n t√≠ch PageRank\n",
    "pagerank_results, pagerank, sorted_pagerank = analyze_pagerank(G, top_k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä PAGERANK TRUNG B√åNH THEO LABEL:\n",
      "--------------------------------------------------\n",
      "  Group          : 0.00083653 (n=246)\n",
      "  Occupation     : 0.00067660 (n=60)\n",
      "  Genre          : 0.00038131 (n=175)\n",
      "  Instrument     : 0.00028318 (n=32)\n",
      "  Artist         : 0.00025601 (n=1378)\n",
      "  Company        : 0.00020686 (n=324)\n",
      "  Album          : 0.00011477 (n=745)\n",
      "  Song           : 0.00010538 (n=1637)\n",
      "\n",
      "   üèÜ Top node theo t·ª´ng lo·∫°i:\n",
      "      - Occupation: Occupation_Di·ªÖn vi√™n (0.012774)\n",
      "      - Genre: Genre_R&B (0.011163)\n",
      "      - Album: BTS (0.005784)\n",
      "      - Group: T-ara (0.005027)\n",
      "      - Company: Company_JYP Entertainment (0.003672)\n",
      "      - Artist: G-Dragon (0.003531)\n",
      "      - Instrument: Instrument_Piano (0.002471)\n",
      "      - Song: World Order (0.001965)\n"
     ]
    }
   ],
   "source": [
    "# Th·ªëng k√™ theo label\n",
    "print(\"\\nüìä PAGERANK TRUNG B√åNH THEO LABEL:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "label_scores = defaultdict(list)\n",
    "for node, score in pagerank.items():\n",
    "    label = G.nodes[node].get('label', 'Unknown')\n",
    "    label_scores[label].append(score)\n",
    "\n",
    "label_avg = {}\n",
    "for label, scores in label_scores.items():\n",
    "    avg = sum(scores) / len(scores)\n",
    "    label_avg[label] = avg\n",
    "\n",
    "pagerank_results[\"pagerank_by_label\"] = {}\n",
    "for label, avg in sorted(label_avg.items(), key=lambda x: x[1], reverse=True):\n",
    "    count = len(label_scores[label])\n",
    "    print(f\"  {label:<15}: {avg:.8f} (n={count})\")\n",
    "    pagerank_results[\"pagerank_by_label\"][label] = {\n",
    "        \"average\": avg,\n",
    "        \"count\": count\n",
    "    }\n",
    "\n",
    "# T√¨m top node theo t·ª´ng label\n",
    "top_by_label = {}\n",
    "for node, score in sorted_pagerank:\n",
    "    label = G.nodes[node].get('label', 'Unknown')\n",
    "    if label not in top_by_label:\n",
    "        top_by_label[label] = (node, score)\n",
    "\n",
    "print(\"\\n   üèÜ Top node theo t·ª´ng lo·∫°i:\")\n",
    "for label, (node, score) in sorted(top_by_label.items(), key=lambda x: x[1][1], reverse=True):\n",
    "    print(f\"      - {label}: {node} ({score:.6f})\")\n",
    "\n",
    "pagerank_results[\"top_by_label\"] = {label: {\"node\": node, \"pagerank\": score} for label, (node, score) in top_by_label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PageRank'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'PageRank'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m top_df = pd.DataFrame(pagerank_results[\u001b[33m\"\u001b[39m\u001b[33mtop_nodes\u001b[39m\u001b[33m\"\u001b[39m][:\u001b[32m30\u001b[39m])\n\u001b[32m      9\u001b[39m fig, ax = plt.subplots(figsize=(\u001b[32m12\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m ax.barh(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(top_df)), \u001b[43mtop_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPageRank\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, color=\u001b[33m'\u001b[39m\u001b[33msteelblue\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m ax.set_yticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(top_df)))\n\u001b[32m     12\u001b[39m ax.set_yticklabels([\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mRank\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mNode\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m40\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m top_df.iterrows()], fontsize=\u001b[32m9\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'PageRank'"
     ]
    }
   ],
   "source": [
    "# V·∫Ω bi·ªÉu ƒë·ªì PageRank\n",
    "if MATPLOTLIB_AVAILABLE:\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        \n",
    "        # T·∫°o DataFrame cho top nodes\n",
    "        top_df = pd.DataFrame(pagerank_results[\"top_nodes\"][:30])\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax.barh(range(len(top_df)), top_df['PageRank'], color='steelblue')\n",
    "        ax.set_yticks(range(len(top_df)))\n",
    "        ax.set_yticklabels([f\"{row['Rank']}. {row['Node'][:40]}\" for _, row in top_df.iterrows()], fontsize=9)\n",
    "        ax.set_xlabel('PageRank Score')\n",
    "        ax.set_title('TOP 30 NODES THEO PAGERANK')\n",
    "        ax.invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('pagerank_analysis.png', dpi=150, bbox_inches='tight')\n",
    "        print(\"‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì v√†o pagerank_analysis.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Hi·ªÉn th·ªã b·∫£ng\n",
    "        display(top_df[['Rank', 'Node', 'Label', 'PageRank']].head(30))\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è  Pandas ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t, b·ªè qua visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì v√†o outputs/pagerank_analysis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15472\\3438773613.py:21: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>label</th>\n",
       "      <th>pagerank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Occupation_Di·ªÖn vi√™n</td>\n",
       "      <td>Occupation</td>\n",
       "      <td>0.012774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Genre_R&amp;B</td>\n",
       "      <td>Genre</td>\n",
       "      <td>0.011163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Genre_Dance-pop</td>\n",
       "      <td>Genre</td>\n",
       "      <td>0.007087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Genre_Hip hop</td>\n",
       "      <td>Genre</td>\n",
       "      <td>0.006748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BTS</td>\n",
       "      <td>Album</td>\n",
       "      <td>0.005784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Occupation_Nh·∫°c sƒ©</td>\n",
       "      <td>Occupation</td>\n",
       "      <td>0.005729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Genre_Pop</td>\n",
       "      <td>Genre</td>\n",
       "      <td>0.005508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Girls' Generation</td>\n",
       "      <td>Album</td>\n",
       "      <td>0.005201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>T-ara</td>\n",
       "      <td>Group</td>\n",
       "      <td>0.005027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>EXO</td>\n",
       "      <td>Group</td>\n",
       "      <td>0.004550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Genre_Ballad</td>\n",
       "      <td>Genre</td>\n",
       "      <td>0.004268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>TWICE</td>\n",
       "      <td>Group</td>\n",
       "      <td>0.004135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Super Junior</td>\n",
       "      <td>Group</td>\n",
       "      <td>0.004049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>GFriend</td>\n",
       "      <td>Group</td>\n",
       "      <td>0.003968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>Group</td>\n",
       "      <td>0.003872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Genre_Dance</td>\n",
       "      <td>Genre</td>\n",
       "      <td>0.003761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Occupation_Rapper</td>\n",
       "      <td>Occupation</td>\n",
       "      <td>0.003752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Company_JYP Entertainment</td>\n",
       "      <td>Company</td>\n",
       "      <td>0.003672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>G-Dragon</td>\n",
       "      <td>Artist</td>\n",
       "      <td>0.003531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Big Bang (nh√≥m nh·∫°c)</td>\n",
       "      <td>Group</td>\n",
       "      <td>0.003193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Company_SM Entertainment</td>\n",
       "      <td>Company</td>\n",
       "      <td>0.003181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Occupation_V≈© C√¥ng</td>\n",
       "      <td>Occupation</td>\n",
       "      <td>0.003109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Genre_J-pop</td>\n",
       "      <td>Genre</td>\n",
       "      <td>0.002996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Taeyeon</td>\n",
       "      <td>Artist</td>\n",
       "      <td>0.002891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>IZ*ONE</td>\n",
       "      <td>Group</td>\n",
       "      <td>0.002851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Mnet</td>\n",
       "      <td>Group</td>\n",
       "      <td>0.002841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>TVXQ</td>\n",
       "      <td>Group</td>\n",
       "      <td>0.002815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Apink</td>\n",
       "      <td>Group</td>\n",
       "      <td>0.002759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>SM Entertainment</td>\n",
       "      <td>Artist</td>\n",
       "      <td>0.002719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Instrument_Piano</td>\n",
       "      <td>Instrument</td>\n",
       "      <td>0.002471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank                       node       label  pagerank\n",
       "0      1       Occupation_Di·ªÖn vi√™n  Occupation  0.012774\n",
       "1      2                  Genre_R&B       Genre  0.011163\n",
       "2      3            Genre_Dance-pop       Genre  0.007087\n",
       "3      4              Genre_Hip hop       Genre  0.006748\n",
       "4      5                        BTS       Album  0.005784\n",
       "5      6         Occupation_Nh·∫°c sƒ©  Occupation  0.005729\n",
       "6      7                  Genre_Pop       Genre  0.005508\n",
       "7      8          Girls' Generation       Album  0.005201\n",
       "8      9                      T-ara       Group  0.005027\n",
       "9     10                        EXO       Group  0.004550\n",
       "10    11               Genre_Ballad       Genre  0.004268\n",
       "11    12                      TWICE       Group  0.004135\n",
       "12    13               Super Junior       Group  0.004049\n",
       "13    14                    GFriend       Group  0.003968\n",
       "14    15                  BLACKPINK       Group  0.003872\n",
       "15    16                Genre_Dance       Genre  0.003761\n",
       "16    17          Occupation_Rapper  Occupation  0.003752\n",
       "17    18  Company_JYP Entertainment     Company  0.003672\n",
       "18    19                   G-Dragon      Artist  0.003531\n",
       "19    20       Big Bang (nh√≥m nh·∫°c)       Group  0.003193\n",
       "20    21   Company_SM Entertainment     Company  0.003181\n",
       "21    22         Occupation_V≈© C√¥ng  Occupation  0.003109\n",
       "22    23                Genre_J-pop       Genre  0.002996\n",
       "23    24                    Taeyeon      Artist  0.002891\n",
       "24    25                     IZ*ONE       Group  0.002851\n",
       "25    26                       Mnet       Group  0.002841\n",
       "26    27                       TVXQ       Group  0.002815\n",
       "27    28                      Apink       Group  0.002759\n",
       "28    29           SM Entertainment      Artist  0.002719\n",
       "29    30           Instrument_Piano  Instrument  0.002471"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# V·∫Ω bi·ªÉu ƒë·ªì PageRank (S·ª¨A L·ªñI KeyError)\n",
    "if MATPLOTLIB_AVAILABLE:\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        \n",
    "        # T·∫°o DataFrame cho top nodes\n",
    "        top_df = pd.DataFrame(pagerank_results[\"top_nodes\"][:30])\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        # S·ª¨A: D√πng 'pagerank' thay v√¨ 'PageRank'\n",
    "        ax.barh(range(len(top_df)), top_df['pagerank'], color='steelblue')\n",
    "        ax.set_yticks(range(len(top_df)))\n",
    "        # S·ª¨A: D√πng 'rank', 'node' thay v√¨ 'Rank', 'Node'\n",
    "        ax.set_yticklabels([f\"{row['rank']}. {row['node'][:40]}\" for _, row in top_df.iterrows()], fontsize=9)\n",
    "        ax.set_xlabel('PageRank Score')\n",
    "        ax.set_title('TOP 30 NODES THEO PAGERANK')\n",
    "        ax.invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('outputs/pagerank_analysis.png', dpi=150, bbox_inches='tight')\n",
    "        print(\"‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì v√†o outputs/pagerank_analysis.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Hi·ªÉn th·ªã b·∫£ng\n",
    "        # S·ª¨A: D√πng 'rank', 'node', 'label', 'pagerank' thay v√¨ 'Rank', 'Node', 'Label', 'PageRank'\n",
    "        display(top_df[['rank', 'node', 'label', 'pagerank']].head(30))\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è  Pandas ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t, b·ªè qua visualization\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  L·ªói: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä PAGERANK THEO T·ª™NG LO·∫†I NODE (TOP 5 M·ªñI LO·∫†I)\n",
      "======================================================================\n",
      "\n",
      "üè∑Ô∏è  Song (T·ªïng: 1637 nodes)\n",
      "----------------------------------------------------------------------\n",
      "Rank   Node                                          PageRank       \n",
      "----------------------------------------------------------------------\n",
      "1      World Order                                   0.00196499\n",
      "2      Girls                                         0.00074901\n",
      "3      Alive                                         0.00067060\n",
      "4      BEcause                                       0.00066765\n",
      "5      I Got a Boy                                   0.00059023\n",
      "\n",
      "üè∑Ô∏è  Artist (T·ªïng: 1378 nodes)\n",
      "----------------------------------------------------------------------\n",
      "Rank   Node                                          PageRank       \n",
      "----------------------------------------------------------------------\n",
      "1      G-Dragon                                      0.00353127\n",
      "2      Taeyeon                                       0.00289062\n",
      "3      SM Entertainment                              0.00271852\n",
      "4      IU (ca sƒ©)                                    0.00235343\n",
      "5      Yoo Young-jin                                 0.00228696\n",
      "\n",
      "üè∑Ô∏è  Album (T·ªïng: 745 nodes)\n",
      "----------------------------------------------------------------------\n",
      "Rank   Node                                          PageRank       \n",
      "----------------------------------------------------------------------\n",
      "1      BTS                                           0.00578399\n",
      "2      Girls' Generation                             0.00520115\n",
      "3      Taemin                                        0.00066583\n",
      "4      Kiss of Life                                  0.00057744\n",
      "5      Born Pink                                     0.00051376\n",
      "\n",
      "üè∑Ô∏è  Company (T·ªïng: 324 nodes)\n",
      "----------------------------------------------------------------------\n",
      "Rank   Node                                          PageRank       \n",
      "----------------------------------------------------------------------\n",
      "1      Company_JYP Entertainment                     0.00367229\n",
      "2      Company_SM Entertainment                      0.00318105\n",
      "3      Company_Kakao Entertainment                   0.00187939\n",
      "4      Company_Avex Trax                             0.00144690\n",
      "5      Company_Cube Entertainment                    0.00122847\n",
      "\n",
      "üè∑Ô∏è  Group (T·ªïng: 246 nodes)\n",
      "----------------------------------------------------------------------\n",
      "Rank   Node                                          PageRank       \n",
      "----------------------------------------------------------------------\n",
      "1      T-ara                                         0.00502654\n",
      "2      EXO                                           0.00455042\n",
      "3      TWICE                                         0.00413477\n",
      "4      Super Junior                                  0.00404905\n",
      "5      GFriend                                       0.00396815\n",
      "\n",
      "üè∑Ô∏è  Genre (T·ªïng: 175 nodes)\n",
      "----------------------------------------------------------------------\n",
      "Rank   Node                                          PageRank       \n",
      "----------------------------------------------------------------------\n",
      "1      Genre_R&B                                     0.01116291\n",
      "2      Genre_Dance-pop                               0.00708700\n",
      "3      Genre_Hip hop                                 0.00674824\n",
      "4      Genre_Pop                                     0.00550830\n",
      "5      Genre_Ballad                                  0.00426848\n",
      "\n",
      "üè∑Ô∏è  Occupation (T·ªïng: 60 nodes)\n",
      "----------------------------------------------------------------------\n",
      "Rank   Node                                          PageRank       \n",
      "----------------------------------------------------------------------\n",
      "1      Occupation_Di·ªÖn vi√™n                          0.01277450\n",
      "2      Occupation_Nh·∫°c sƒ©                            0.00572859\n",
      "3      Occupation_Rapper                             0.00375184\n",
      "4      Occupation_V≈© C√¥ng                            0.00310895\n",
      "5      Occupation_Ng∆∞·ªùi M·∫´u                          0.00237200\n",
      "\n",
      "üè∑Ô∏è  Instrument (T·ªïng: 32 nodes)\n",
      "----------------------------------------------------------------------\n",
      "Rank   Node                                          PageRank       \n",
      "----------------------------------------------------------------------\n",
      "1      Instrument_Piano                              0.00247103\n",
      "2      Instrument_Guitar                             0.00178601\n",
      "3      Instrument_Tr·ªëng                              0.00052868\n",
      "4      Instrument_Rap                                0.00044070\n",
      "5      Instrument_S√°o                                0.00028477\n",
      "\n",
      "‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì PageRank theo lo·∫°i v√†o outputs/pagerank_by_type.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15472\\1681500439.py:70: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Ph√¢n t√≠ch PageRank theo t·ª´ng lo·∫°i node (Top 5 m·ªói lo·∫°i)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä PAGERANK THEO T·ª™NG LO·∫†I NODE (TOP 5 M·ªñI LO·∫†I)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Nh√≥m nodes theo label\n",
    "nodes_by_label = defaultdict(list)\n",
    "for node, score in sorted_pagerank:\n",
    "    label = G.nodes[node].get('label', 'Unknown')\n",
    "    nodes_by_label[label].append((node, score))\n",
    "\n",
    "# S·∫Øp x·∫øp c√°c label theo s·ªë l∆∞·ª£ng nodes\n",
    "sorted_labels = sorted(nodes_by_label.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "# Hi·ªÉn th·ªã top 5 nodes cho m·ªói lo·∫°i\n",
    "pagerank_by_type = {}\n",
    "for label, nodes_list in sorted_labels:\n",
    "    top_5 = nodes_list[:5]\n",
    "    pagerank_by_type[label] = top_5\n",
    "    \n",
    "    print(f\"\\nüè∑Ô∏è  {label} (T·ªïng: {len(nodes_list)} nodes)\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Rank':<6} {'Node':<45} {'PageRank':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for i, (node, score) in enumerate(top_5, 1):\n",
    "        print(f\"{i:<6} {node[:43]:<45} {score:.8f}\")\n",
    "\n",
    "# L∆∞u v√†o results\n",
    "pagerank_results[\"top_by_type\"] = {\n",
    "    label: [{\"node\": node, \"pagerank\": score} for node, score in top_5]\n",
    "    for label, top_5 in pagerank_by_type.items()\n",
    "}\n",
    "\n",
    "# V·∫Ω bi·ªÉu ƒë·ªì PageRank theo t·ª´ng lo·∫°i (n·∫øu c√≥ matplotlib)\n",
    "if MATPLOTLIB_AVAILABLE:\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        \n",
    "        # T·∫°o subplot cho m·ªói lo·∫°i c√≥ nhi·ªÅu nodes nh·∫•t\n",
    "        top_labels = sorted_labels[:6]  # Top 6 lo·∫°i c√≥ nhi·ªÅu nodes nh·∫•t\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for idx, (label, nodes_list) in enumerate(top_labels):\n",
    "            if idx >= 6:\n",
    "                break\n",
    "                \n",
    "            top_5 = nodes_list[:5]\n",
    "            nodes_names = [n[0][:30] for n in top_5]\n",
    "            scores = [n[1] for n in top_5]\n",
    "            \n",
    "            ax = axes[idx]\n",
    "            ax.barh(range(len(nodes_names)), scores, color='steelblue', alpha=0.7)\n",
    "            ax.set_yticks(range(len(nodes_names)))\n",
    "            ax.set_yticklabels(nodes_names, fontsize=8)\n",
    "            ax.set_xlabel('PageRank Score', fontsize=9)\n",
    "            ax.set_title(f'{label}\\n(Top 5/{len(nodes_list)})', fontsize=10, fontweight='bold')\n",
    "            ax.invert_yaxis()\n",
    "            ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # ·∫®n c√°c subplot kh√¥ng d√πng\n",
    "        for idx in range(len(top_labels), 6):\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('outputs/pagerank_by_type.png', dpi=150, bbox_inches='tight')\n",
    "        print(\"\\n‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì PageRank theo lo·∫°i v√†o outputs/pagerank_by_type.png\")\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è  L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ph√°t hi·ªán C·ªông ƒë·ªìng (Community Detection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "3. PH√ÅT HI·ªÜN C·ªòNG ƒê·ªíNG (COMMUNITY DETECTION)\n",
      "======================================================================\n",
      "\n",
      "üîç S·ª≠ d·ª•ng thu·∫≠t to√°n Louvain...\n",
      "\n",
      "‚úì Ph√°t hi·ªán ƒë∆∞·ª£c 1832 c·ªông ƒë·ªìng\n",
      "‚úì Modularity: 0.6234\n",
      "   ‚Üí Modularity > 0.3: C·∫•u tr√∫c c·ªông ƒë·ªìng R√ï R√ÄNG\n",
      "\n",
      "üìä TH·ªêNG K√ä K√çCH TH∆Ø·ªöC C·ªòNG ƒê·ªíNG:\n",
      "   - Nh·ªè nh·∫•t: 1 nodes\n",
      "   - L·ªõn nh·∫•t: 393 nodes\n",
      "   - Trung b√¨nh: 2.5 nodes\n"
     ]
    }
   ],
   "source": [
    "def analyze_communities(G: 'nx.Graph', top_k_communities: int = 10) -> Tuple[Dict[str, Any], List]:\n",
    "    \"\"\"\n",
    "    Ph√°t hi·ªán c·ªông ƒë·ªìng trong m·∫°ng s·ª≠ d·ª•ng thu·∫≠t to√°n Louvain\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"3. PH√ÅT HI·ªÜN C·ªòNG ƒê·ªíNG (COMMUNITY DETECTION)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Ki·ªÉm tra c√≥ th∆∞ vi·ªán community detection kh√¥ng\n",
    "    try:\n",
    "        from networkx.algorithms import community as nx_community\n",
    "        HAS_LOUVAIN = hasattr(nx_community, 'louvain_communities')\n",
    "    except ImportError:\n",
    "        HAS_LOUVAIN = False\n",
    "    \n",
    "    if HAS_LOUVAIN:\n",
    "        print(\"\\nüîç S·ª≠ d·ª•ng thu·∫≠t to√°n Louvain...\")\n",
    "        communities = nx_community.louvain_communities(G, seed=42)\n",
    "        method = \"Louvain\"\n",
    "    else:\n",
    "        print(\"\\nüîç S·ª≠ d·ª•ng thu·∫≠t to√°n Greedy Modularity...\")\n",
    "        communities = list(nx_community.greedy_modularity_communities(G))\n",
    "        method = \"Greedy Modularity\"\n",
    "    \n",
    "    # Chuy·ªÉn th√†nh list ƒë·ªÉ s·∫Øp x·∫øp\n",
    "    communities = [set(c) for c in communities]\n",
    "    communities.sort(key=len, reverse=True)\n",
    "    \n",
    "    results[\"method\"] = method\n",
    "    results[\"total_communities\"] = len(communities)\n",
    "    \n",
    "    print(f\"\\n‚úì Ph√°t hi·ªán ƒë∆∞·ª£c {len(communities)} c·ªông ƒë·ªìng\")\n",
    "    \n",
    "    # T√≠nh modularity\n",
    "    try:\n",
    "        modularity = nx_community.modularity(G, communities)\n",
    "        results[\"modularity\"] = modularity\n",
    "        print(f\"‚úì Modularity: {modularity:.4f}\")\n",
    "        \n",
    "        if modularity > 0.3:\n",
    "            print(\"   ‚Üí Modularity > 0.3: C·∫•u tr√∫c c·ªông ƒë·ªìng R√ï R√ÄNG\")\n",
    "        elif modularity > 0.1:\n",
    "            print(\"   ‚Üí Modularity > 0.1: C·∫•u tr√∫c c·ªông ƒë·ªìng TRUNG B√åNH\")\n",
    "        else:\n",
    "            print(\"   ‚Üí Modularity ‚â§ 0.1: C·∫•u tr√∫c c·ªông ƒë·ªìng Y·∫æU\")\n",
    "    except:\n",
    "        results[\"modularity\"] = None\n",
    "    \n",
    "    # Th·ªëng k√™ k√≠ch th∆∞·ªõc c·ªông ƒë·ªìng\n",
    "    community_sizes = [len(c) for c in communities]\n",
    "    results[\"community_sizes\"] = {\n",
    "        \"min\": min(community_sizes),\n",
    "        \"max\": max(community_sizes),\n",
    "        \"mean\": sum(community_sizes) / len(community_sizes),\n",
    "        \"median\": sorted(community_sizes)[len(community_sizes)//2]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìä TH·ªêNG K√ä K√çCH TH∆Ø·ªöC C·ªòNG ƒê·ªíNG:\")\n",
    "    print(f\"   - Nh·ªè nh·∫•t: {min(community_sizes)} nodes\")\n",
    "    print(f\"   - L·ªõn nh·∫•t: {max(community_sizes)} nodes\")\n",
    "    print(f\"   - Trung b√¨nh: {sum(community_sizes)/len(community_sizes):.1f} nodes\")\n",
    "    \n",
    "    return results, communities\n",
    "\n",
    "# Ch·∫°y ph√¢n t√≠ch Community Detection\n",
    "community_results, communities = analyze_communities(G, top_k_communities=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä TOP 10 C·ªòNG ƒê·ªíNG L·ªöN NH·∫§T:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üîπ C·ªông ƒë·ªìng 1: 393 nodes\n",
      "   Label ch·ªß ƒë·∫°o: Artist (225 nodes, 57.3%)\n",
      "   Ph√¢n b·ªë: {'Artist': 225, 'Occupation': 37, 'Genre': 23, 'Company': 46, 'Album': 13, 'Instrument': 20, 'Song': 21, 'Group': 8}\n",
      "   Nodes m·∫´u: Lina (ca sƒ© H√†n Qu·ªëc), Wendy (ca sƒ©), Occupation_Dancer, Genre_C-pop, Elkie Chong\n",
      "\n",
      "üîπ C·ªông ƒë·ªìng 2: 217 nodes\n",
      "   Label ch·ªß ƒë·∫°o: Artist (106 nodes, 48.8%)\n",
      "   Ph√¢n b·ªë: {'Song': 24, 'Company': 24, 'Artist': 106, 'Group': 25, 'Genre': 16, 'Album': 18, 'Instrument': 3, 'Occupation': 1}\n",
      "   Nodes m·∫´u: D.I.S.C.O, Company_Konnect, Ham Eun-jeong, Wanna One, Ha Sung-woon\n",
      "\n",
      "üîπ C·ªông ƒë·ªìng 3: 168 nodes\n",
      "   Label ch·ªß ƒë·∫°o: Artist (85 nodes, 50.6%)\n",
      "   Ph√¢n b·ªë: {'Artist': 85, 'Occupation': 4, 'Album': 10, 'Song': 20, 'Company': 26, 'Group': 19, 'Instrument': 1, 'Genre': 3}\n",
      "   Nodes m·∫´u: Lee Daehwi, Kang Hye-won, AKB48, Hwarang, Occupation_Idol\n",
      "\n",
      "üîπ C·ªông ƒë·ªìng 4: 152 nodes\n",
      "   Label ch·ªß ƒë·∫°o: Song (69 nodes, 45.4%)\n",
      "   Ph√¢n b·ªë: {'Album': 36, 'Song': 69, 'Group': 8, 'Artist': 31, 'Genre': 1, 'Company': 7}\n",
      "   Nodes m·∫´u: The Boys (album c·ªßa Girls' Generation), You Think, 2PM, Oh! (b√†i h√°t c·ªßa Girls' Generation), Dancing Queen (b√†i h√°t c·ªßa Girls' Generation)\n",
      "\n",
      "üîπ C·ªông ƒë·ªìng 5: 144 nodes\n",
      "   Label ch·ªß ƒë·∫°o: Song (60 nodes, 41.7%)\n",
      "   Ph√¢n b·ªë: {'Song': 60, 'Album': 24, 'Occupation': 3, 'Artist': 29, 'Company': 6, 'Group': 13, 'Genre': 7, 'Instrument': 2}\n",
      "   Nodes m·∫´u: Sorry, Sorry (b√†i h√°t), Perfection, Occupation_Gi·∫£ng Vi√™n Thanh Nh·∫°c, Whiplash, Jonghyun\n",
      "\n",
      "üîπ C·ªông ƒë·ªìng 6: 132 nodes\n",
      "   Label ch·ªß ƒë·∫°o: Artist (53 nodes, 40.2%)\n",
      "   Ph√¢n b·ªë: {'Album': 12, 'Artist': 53, 'Song': 50, 'Group': 12, 'Company': 4, 'Genre': 1}\n",
      "   Nodes m·∫´u: Fancy You (EP), The Story Begins, Olivia Hye, Go Won, Dance the Night Away (b√†i h√°t c·ªßa Twice)\n",
      "\n",
      "üîπ C·ªông ƒë·ªìng 7: 129 nodes\n",
      "   Label ch·ªß ƒë·∫°o: Song (49 nodes, 38.0%)\n",
      "   Ph√¢n b·ªë: {'Company': 3, 'Artist': 47, 'Song': 49, 'Genre': 3, 'Album': 16, 'Group': 9, 'Instrument': 1, 'Occupation': 1}\n",
      "   Nodes m·∫´u: Company_131 Label, Jackson, Shut Down, JUMP, Company_Polydor\n",
      "\n",
      "üîπ C·ªông ƒë·ªìng 8: 128 nodes\n",
      "   Label ch·ªß ƒë·∫°o: Song (69 nodes, 53.9%)\n",
      "   Ph√¢n b·ªë: {'Song': 69, 'Album': 18, 'Company': 5, 'Artist': 24, 'Group': 5, 'Occupation': 1, 'Genre': 6}\n",
      "   Nodes m·∫´u: Without a Heart, Boy with Luv, Good Bye, Airplane Pt. 2, Be (album c·ªßa BTS)\n",
      "\n",
      "üîπ C·ªông ƒë·ªìng 9: 127 nodes\n",
      "   Label ch·ªß ƒë·∫°o: Artist (52 nodes, 40.9%)\n",
      "   Ph√¢n b·ªë: {'Genre': 3, 'Group': 13, 'Artist': 52, 'Company': 7, 'Song': 38, 'Album': 11, 'Instrument': 1, 'Occupation': 2}\n",
      "   Nodes m·∫´u: Genre_*dance, Isak N Jiyeon, Trinity, Company_Mbk, Genre_Electro House\n",
      "\n",
      "üîπ C·ªông ƒë·ªìng 10: 116 nodes\n",
      "   Label ch·ªß ƒë·∫°o: Artist (72 nodes, 62.1%)\n",
      "   Ph√¢n b·ªë: {'Artist': 72, 'Company': 8, 'Song': 21, 'Group': 11, 'Album': 1, 'Occupation': 1, 'Genre': 2}\n",
      "   Nodes m·∫´u: Bona (ca sƒ©), Company_Studio Blu, Where Should I Go, 5urprise, Starlight\n",
      "\n",
      "üìä PH√ÇN T√çCH C·ªòNG ƒê·ªíNG:\n",
      "----------------------------------------------------------------------\n",
      "   - C·ªông ƒë·ªìng ch·ªß y·∫øu Artist: 195\n",
      "   - C·ªông ƒë·ªìng ch·ªß y·∫øu Group: 26\n",
      "   - C·ªông ƒë·ªìng h·ªón h·ª£p: 1611\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "üìã K·∫æT LU·∫¨N V·ªÄ C·∫§U TR√öC C·ªòNG ƒê·ªíNG:\n",
      "----------------------------------------------------------------------\n",
      "   1. M·∫°ng K-pop c√≥ 1832 c·ªông ƒë·ªìng r√µ r√†ng\n",
      "   2. Modularity cao (0.623) cho th·∫•y c·∫•u tr√∫c c·ªông ƒë·ªìng m·∫°nh\n",
      "   3. C·ªông ƒë·ªìng l·ªõn nh·∫•t c√≥ 393 nodes (8.5% m·∫°ng)\n",
      "\n",
      "   üí° DI·ªÑN GI·∫¢I:\n",
      "   - C√°c c·ªông ƒë·ªìng c√≥ th·ªÉ ƒë·∫°i di·ªán cho:\n",
      "     + Ngh·ªá sƒ© c√πng c√¥ng ty (SM, YG, JYP, HYBE...)\n",
      "     + Th·∫ø h·ªá idol (1st, 2nd, 3rd, 4th generation)\n",
      "     + Th·ªÉ lo·∫°i √¢m nh·∫°c (Hip-hop, Ballad, Dance...)\n",
      "     + C√°c m·ªëi quan h·ªá h·ª£p t√°c, collab\n"
     ]
    }
   ],
   "source": [
    "# Chi ti·∫øt top communities\n",
    "print(f\"\\nüìä TOP 10 C·ªòNG ƒê·ªíNG L·ªöN NH·∫§T:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "community_results[\"top_communities\"] = []\n",
    "\n",
    "for i, comm in enumerate(communities[:10], 1):\n",
    "    # ƒê·∫øm labels trong community\n",
    "    label_counts = defaultdict(int)\n",
    "    for node in comm:\n",
    "        label = G.nodes[node].get('label', 'Unknown')\n",
    "        label_counts[label] += 1\n",
    "    \n",
    "    # T√¨m label ch·ªß ƒë·∫°o\n",
    "    dominant_label = max(label_counts.items(), key=lambda x: x[1])\n",
    "    \n",
    "    # L·∫•y m·ªôt s·ªë node m·∫´u\n",
    "    sample_nodes = list(comm)[:5]\n",
    "    \n",
    "    print(f\"\\nüîπ C·ªông ƒë·ªìng {i}: {len(comm)} nodes\")\n",
    "    print(f\"   Label ch·ªß ƒë·∫°o: {dominant_label[0]} ({dominant_label[1]} nodes, {100*dominant_label[1]/len(comm):.1f}%)\")\n",
    "    print(f\"   Ph√¢n b·ªë: {dict(label_counts)}\")\n",
    "    print(f\"   Nodes m·∫´u: {', '.join(sample_nodes)}\")\n",
    "    \n",
    "    community_results[\"top_communities\"].append({\n",
    "        \"id\": i,\n",
    "        \"size\": len(comm),\n",
    "        \"dominant_label\": dominant_label[0],\n",
    "        \"dominant_label_count\": dominant_label[1],\n",
    "        \"dominant_label_percentage\": 100 * dominant_label[1] / len(comm),\n",
    "        \"label_distribution\": dict(label_counts),\n",
    "        \"sample_nodes\": sample_nodes\n",
    "    })\n",
    "\n",
    "# Ph√¢n t√≠ch c√°c c·ªông ƒë·ªìng ƒë·∫∑c bi·ªát\n",
    "print(\"\\nüìä PH√ÇN T√çCH C·ªòNG ƒê·ªíNG:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# T√¨m c√°c c·ªông ƒë·ªìng c√≥ t√≠nh ch·∫•t ƒë·∫∑c bi·ªát\n",
    "artist_communities = []\n",
    "group_communities = []\n",
    "mixed_communities = []\n",
    "\n",
    "for i, comm in enumerate(communities):\n",
    "    label_counts = defaultdict(int)\n",
    "    for node in comm:\n",
    "        label = G.nodes[node].get('label', 'Unknown')\n",
    "        label_counts[label] += 1\n",
    "    \n",
    "    total = len(comm)\n",
    "    if label_counts.get('Artist', 0) / total > 0.7:\n",
    "        artist_communities.append((i, len(comm)))\n",
    "    elif label_counts.get('Group', 0) / total > 0.5:\n",
    "        group_communities.append((i, len(comm)))\n",
    "    else:\n",
    "        mixed_communities.append((i, len(comm)))\n",
    "\n",
    "print(f\"   - C·ªông ƒë·ªìng ch·ªß y·∫øu Artist: {len(artist_communities)}\")\n",
    "print(f\"   - C·ªông ƒë·ªìng ch·ªß y·∫øu Group: {len(group_communities)}\")\n",
    "print(f\"   - C·ªông ƒë·ªìng h·ªón h·ª£p: {len(mixed_communities)}\")\n",
    "\n",
    "community_results[\"community_types\"] = {\n",
    "    \"artist_dominated\": len(artist_communities),\n",
    "    \"group_dominated\": len(group_communities),\n",
    "    \"mixed\": len(mixed_communities)\n",
    "}\n",
    "\n",
    "# K·∫øt lu·∫≠n\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"üìã K·∫æT LU·∫¨N V·ªÄ C·∫§U TR√öC C·ªòNG ƒê·ªíNG:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "community_sizes = [len(c) for c in communities]\n",
    "print(f\"   1. M·∫°ng K-pop c√≥ {len(communities)} c·ªông ƒë·ªìng r√µ r√†ng\")\n",
    "\n",
    "if community_results.get(\"modularity\", 0) > 0.3:\n",
    "    print(f\"   2. Modularity cao ({community_results.get('modularity', 0):.3f}) cho th·∫•y c·∫•u tr√∫c c·ªông ƒë·ªìng m·∫°nh\")\n",
    "\n",
    "print(f\"   3. C·ªông ƒë·ªìng l·ªõn nh·∫•t c√≥ {max(community_sizes)} nodes ({100*max(community_sizes)/G.number_of_nodes():.1f}% m·∫°ng)\")\n",
    "\n",
    "# Di·ªÖn gi·∫£i c·ªông ƒë·ªìng\n",
    "print(\"\\n   üí° DI·ªÑN GI·∫¢I:\")\n",
    "print(\"   - C√°c c·ªông ƒë·ªìng c√≥ th·ªÉ ƒë·∫°i di·ªán cho:\")\n",
    "print(\"     + Ngh·ªá sƒ© c√πng c√¥ng ty (SM, YG, JYP, HYBE...)\")\n",
    "print(\"     + Th·∫ø h·ªá idol (1st, 2nd, 3rd, 4th generation)\")\n",
    "print(\"     + Th·ªÉ lo·∫°i √¢m nh·∫°c (Hip-hop, Ballad, Dance...)\")\n",
    "print(\"     + C√°c m·ªëi quan h·ªá h·ª£p t√°c, collab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì v√†o community_analysis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15472\\2260242745.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>size</th>\n",
       "      <th>dominant_label</th>\n",
       "      <th>dominant_label_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>393</td>\n",
       "      <td>Artist</td>\n",
       "      <td>57.251908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>217</td>\n",
       "      <td>Artist</td>\n",
       "      <td>48.847926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>Artist</td>\n",
       "      <td>50.595238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>152</td>\n",
       "      <td>Song</td>\n",
       "      <td>45.394737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>144</td>\n",
       "      <td>Song</td>\n",
       "      <td>41.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>132</td>\n",
       "      <td>Artist</td>\n",
       "      <td>40.151515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "      <td>Song</td>\n",
       "      <td>37.984496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>Song</td>\n",
       "      <td>53.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>127</td>\n",
       "      <td>Artist</td>\n",
       "      <td>40.944882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>116</td>\n",
       "      <td>Artist</td>\n",
       "      <td>62.068966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  size dominant_label  dominant_label_percentage\n",
       "0   1   393         Artist                  57.251908\n",
       "1   2   217         Artist                  48.847926\n",
       "2   3   168         Artist                  50.595238\n",
       "3   4   152           Song                  45.394737\n",
       "4   5   144           Song                  41.666667\n",
       "5   6   132         Artist                  40.151515\n",
       "6   7   129           Song                  37.984496\n",
       "7   8   128           Song                  53.906250\n",
       "8   9   127         Artist                  40.944882\n",
       "9  10   116         Artist                  62.068966"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# V·∫Ω bi·ªÉu ƒë·ªì Community\n",
    "if MATPLOTLIB_AVAILABLE:\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        \n",
    "        # T·∫°o DataFrame cho top communities\n",
    "        comm_df = pd.DataFrame(community_results[\"top_communities\"])\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax.barh(range(len(comm_df)), comm_df['size'], color='coral')\n",
    "        ax.set_yticks(range(len(comm_df)))\n",
    "        ax.set_yticklabels([f\"C·ªông ƒë·ªìng {row['id']}: {row['dominant_label']}\" for _, row in comm_df.iterrows()], fontsize=9)\n",
    "        ax.set_xlabel('S·ªë l∆∞·ª£ng nodes')\n",
    "        ax.set_title('TOP 10 C·ªòNG ƒê·ªíNG L·ªöN NH·∫§T')\n",
    "        ax.invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('community_analysis.png', dpi=150, bbox_inches='tight')\n",
    "        print(\"‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì v√†o community_analysis.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Hi·ªÉn th·ªã b·∫£ng\n",
    "        display(comm_df[['id', 'size', 'dominant_label', 'dominant_label_percentage']].head(10))\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è  Pandas ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t, b·ªè qua visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. T·ªïng k·∫øt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä T·ªîNG K·∫æT PH√ÇN T√çCH M·∫†NG X√É H·ªòI K-POP\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£  TH·∫æ GI·ªöI NH·ªé (SMALL WORLD):\n",
      "    - Average Path Length: 4.47\n",
      "    - Clustering Coefficient: 0.0557\n",
      "    - L√† Small World: ‚úì C√ì\n",
      "\n",
      "2Ô∏è‚É£  PAGERANK - TOP 5 NODES QUAN TR·ªåNG NH·∫§T:\n",
      "    1. Occupation_Di·ªÖn vi√™n (Occupation) - PageRank: 0.012774\n",
      "    2. Genre_R&B (Genre) - PageRank: 0.011163\n",
      "    3. Genre_Dance-pop (Genre) - PageRank: 0.007087\n",
      "    4. Genre_Hip hop (Genre) - PageRank: 0.006748\n",
      "    5. BTS (Album) - PageRank: 0.005784\n",
      "\n",
      "3Ô∏è‚É£  C·ªòNG ƒê·ªíNG:\n",
      "    - S·ªë c·ªông ƒë·ªìng: 1832\n",
      "    - Modularity: 0.6234\n",
      "\n",
      "======================================================================\n",
      "‚úì HO√ÄN T·∫§T PH√ÇN T√çCH\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä T·ªîNG K·∫æT PH√ÇN T√çCH M·∫†NG X√É H·ªòI K-POP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£  TH·∫æ GI·ªöI NH·ªé (SMALL WORLD):\")\n",
    "if \"is_small_world\" in small_world_results:\n",
    "    sw = small_world_results\n",
    "    print(f\"    - Average Path Length: {sw.get('average_path_length', 'N/A'):.2f}\")\n",
    "    print(f\"    - Clustering Coefficient: {sw.get('clustering_coefficient', 'N/A'):.4f}\")\n",
    "    print(f\"    - L√† Small World: {'‚úì C√ì' if sw.get('is_small_world') else '‚úó KH√îNG'}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£  PAGERANK - TOP 5 NODES QUAN TR·ªåNG NH·∫§T:\")\n",
    "if \"top_nodes\" in pagerank_results:\n",
    "    for node_info in pagerank_results.get(\"top_nodes\", [])[:5]:\n",
    "        print(f\"    {node_info['rank']}. {node_info['node']} ({node_info['label']}) - PageRank: {node_info['pagerank']:.6f}\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£  C·ªòNG ƒê·ªíNG:\")\n",
    "if \"total_communities\" in community_results:\n",
    "    comm = community_results\n",
    "    print(f\"    - S·ªë c·ªông ƒë·ªìng: {comm.get('total_communities', 'N/A')}\")\n",
    "    if comm.get('modularity'):\n",
    "        print(f\"    - Modularity: {comm.get('modularity', 'N/A'):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úì HO√ÄN T·∫§T PH√ÇN T√çCH\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì v√†o outputs/community_analysis.png\n",
      "\n",
      "üìä PH√ÇN B·ªê K√çCH TH∆Ø·ªöC C·ªòNG ƒê·ªíNG:\n",
      "--------------------------------------------------\n",
      "  1-2             nodes: 1797 c·ªông ƒë·ªìng ( 98.1%)\n",
      "  3-5             nodes:    3 c·ªông ƒë·ªìng (  0.2%)\n",
      "  6-10            nodes:    3 c·ªông ƒë·ªìng (  0.2%)\n",
      "  11-20           nodes:    5 c·ªông ƒë·ªìng (  0.3%)\n",
      "  21-50           nodes:    6 c·ªông ƒë·ªìng (  0.3%)\n",
      "  51-100          nodes:    7 c·ªông ƒë·ªìng (  0.4%)\n",
      "  101-200         nodes:    9 c·ªông ƒë·ªìng (  0.5%)\n",
      "  201-300         nodes:    1 c·ªông ƒë·ªìng (  0.1%)\n",
      "  301+            nodes:    1 c·ªông ƒë·ªìng (  0.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15472\\1087283540.py:55: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# V·∫Ω bi·ªÉu ƒë·ªì Community (ch·ªâ bar chart top 10, kh√¥ng v·∫Ω histogram v√¨ ph√¢n b·ªë qu√° l·ªách)\n",
    "if MATPLOTLIB_AVAILABLE:\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        # L·∫•y k√≠ch th∆∞·ªõc c·ªßa t·∫•t c·∫£ c·ªông ƒë·ªìng ƒë·ªÉ t√≠nh th·ªëng k√™\n",
    "        community_sizes = [len(c) for c in communities]\n",
    "        max_size = max(community_sizes)\n",
    "        \n",
    "        # T·∫°o figure v·ªõi 1 subplot (ch·ªâ bar chart)\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        # Bar chart top 10 c·ªông ƒë·ªìng l·ªõn nh·∫•t\n",
    "        comm_df = pd.DataFrame(community_results[\"top_communities\"])\n",
    "        ax.barh(range(len(comm_df)), comm_df['size'], color='coral')\n",
    "        ax.set_yticks(range(len(comm_df)))\n",
    "        ax.set_yticklabels([f\"C·ªông ƒë·ªìng {row['id']}: {row['dominant_label']}\" for _, row in comm_df.iterrows()], fontsize=9)\n",
    "        ax.set_xlabel('S·ªë l∆∞·ª£ng nodes', fontsize=11)\n",
    "        ax.set_title('TOP 10 C·ªòNG ƒê·ªíNG L·ªöN NH·∫§T', fontsize=12, fontweight='bold')\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('outputs/community_analysis.png', dpi=150, bbox_inches='tight')\n",
    "        print(\"‚úì ƒê√£ l∆∞u bi·ªÉu ƒë·ªì v√†o outputs/community_analysis.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        # T√≠nh v√† in th·ªëng k√™ ph√¢n b·ªë (ch·ªâ text, kh√¥ng v·∫Ω histogram)\n",
    "        bins = [1, 3, 6, 11, 21, 51, 101, 201, 301, max_size + 1]\n",
    "        counts, bin_edges = np.histogram(community_sizes, bins=bins)\n",
    "        \n",
    "        # T·∫°o nh√£n cho bins\n",
    "        bin_labels = []\n",
    "        for i in range(len(bins) - 1):\n",
    "            if bins[i+1] == max_size + 1:\n",
    "                bin_labels.append(f'{bins[i]}+')\n",
    "            else:\n",
    "                bin_labels.append(f'{bins[i]}-{bins[i+1]-1}')\n",
    "        \n",
    "        # In th·ªëng k√™ ph√¢n b·ªë\n",
    "        print(f\"\\nüìä PH√ÇN B·ªê K√çCH TH∆Ø·ªöC C·ªòNG ƒê·ªíNG:\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, (label, count) in enumerate(zip(bin_labels, counts)):\n",
    "            if count > 0:\n",
    "                percentage = 100 * count / len(communities)\n",
    "                print(f\"  {label:15} nodes: {count:4} c·ªông ƒë·ªìng ({percentage:5.1f}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
