# üìã Ch·ª©ng minh: Small LLM (‚â§1B Parameters)

T√†i li·ªáu n√†y ch·ªâ ra c√°c ƒëo·∫°n code th·ªÉ hi·ªán vi·ªác s·ª≠ d·ª•ng m√¥ h√¨nh ng√¥n ng·ªØ nh·ªè v·ªõi s·ªë l∆∞·ª£ng tham s·ªë ‚â§ 1 t·ª∑.

---

## 1. ƒê·ªãnh nghƒ©a Model (File: `src/chatbot/small_llm.py`)

### 1.1. Model ƒë∆∞·ª£c ch·ªçn: Qwen2-0.5B-Instruct

```49:49:src/chatbot/small_llm.py
    model_name: str = "Qwen/Qwen2-0.5B-Instruct"
```

**Gi·∫£i th√≠ch:** Model m·∫∑c ƒë·ªãnh l√† `Qwen2-0.5B-Instruct` v·ªõi **0.5 t·ª∑ tham s·ªë** (500M parameters).

### 1.2. C·∫•u h√¨nh Model

```63:67:src/chatbot/small_llm.py
    "qwen2-0.5b": LLMConfig(
        model_name="Qwen/Qwen2-0.5B-Instruct",
        max_new_tokens=512,
        temperature=0.7
    ),
```

**Gi·∫£i th√≠ch:** Model key `"qwen2-0.5b"` ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a v·ªõi model `Qwen2-0.5B-Instruct` (0.5B = 500M parameters).

### 1.3. Class Documentation

```101:107:src/chatbot/small_llm.py
class SmallLLM:
    """
    Small Language Model wrapper for K-pop chatbot.
    
    Uses quantized models (‚â§1B parameters) for efficient inference
    while maintaining good response quality for Vietnamese K-pop Q&A.
    """
```

**Gi·∫£i th√≠ch:** Class `SmallLLM` ƒë∆∞·ª£c document r√µ r√†ng l√† s·ª≠ d·ª•ng models **‚â§1B parameters**.

---

## 2. T√≠nh to√°n v√† Hi·ªÉn th·ªã S·ªë Tham S·ªë (File: `src/chatbot/small_llm.py`)

### 2.1. Method t√≠nh s·ªë tham s·ªë

```230:241:src/chatbot/small_llm.py
    def _get_model_size(self) -> str:
        """Get model size in human-readable format."""
        if self.model is None:
            return "Unknown"
            
        param_count = sum(p.numel() for p in self.model.parameters())
        if param_count >= 1e9:
            return f"{param_count / 1e9:.2f}B parameters"
        elif param_count >= 1e6:
            return f"{param_count / 1e6:.2f}M parameters"
        else:
            return f"{param_count} parameters"
```

**Gi·∫£i th√≠ch:** 
- `sum(p.numel() for p in self.model.parameters())` - T√≠nh t·ªïng s·ªë tham s·ªë
- Hi·ªÉn th·ªã d·∫°ng "B" (t·ª∑) n·∫øu ‚â• 1e9, "M" (tri·ªáu) n·∫øu ‚â• 1e6

### 2.2. Hi·ªÉn th·ªã khi load model

```223:224:src/chatbot/small_llm.py
            print(f"‚úÖ Model loaded successfully!")
            print(f"   Model size: {self._get_model_size()}")
```

**Gi·∫£i th√≠ch:** Khi load model, s·∫Ω in ra s·ªë tham s·ªë c·ªßa model.

---

## 3. Verification trong Demo (File: `src/demo_chatbot.py`)

### 3.1. Demo ki·ªÉm tra s·ªë tham s·ªë

```30:47:src/demo_chatbot.py
def demo_1_small_llm():
    """Demo 1: Small LLM (‚â§1B params) - 1 ƒëi·ªÉm"""
    print_section("1. DEMO: Small LLM (‚â§1B Parameters)")
    
    from chatbot.small_llm import SmallLLM, get_llm
    
    print("üîÑ ƒêang kh·ªüi t·∫°o Small LLM...")
    try:
        llm = get_llm("qwen2-0.5b")
        
        # Get model size
        param_count = sum(p.numel() for p in llm.model.parameters())
        param_count_b = param_count / 1e9
        
        print(f"\n‚úÖ Model: Qwen2-0.5B-Instruct")
        print(f"‚úÖ S·ªë tham s·ªë: {param_count_b:.3f} t·ª∑ ({param_count/1e6:.1f}M)")
        print(f"‚úÖ Y√™u c·∫ßu: ‚â§ 1 t·ª∑ tham s·ªë")
        print(f"‚úÖ K·∫øt qu·∫£: {'‚úÖ ƒê·∫†T' if param_count_b <= 1.0 else '‚ùå KH√îNG ƒê·∫†T'}")
```

**Gi·∫£i th√≠ch:**
- Load model `qwen2-0.5b`
- T√≠nh s·ªë tham s·ªë: `param_count = sum(p.numel() for p in llm.model.parameters())`
- Chuy·ªÉn ƒë·ªïi sang t·ª∑: `param_count_b = param_count / 1e9`
- **Verify:** `param_count_b <= 1.0` ‚Üí ƒê·∫†T y√™u c·∫ßu

---

## 4. Verification trong Test (File: `src/test_chatbot.py`)

### 4.1. Test ki·ªÉm tra s·ªë tham s·ªë

```248:255:src/test_chatbot.py
    # 1. Small LLM (‚â§1B params)
    print("1. ‚úÖ Small LLM (‚â§1B params):")
    if chatbot.llm:
        param_count = sum(p.numel() for p in chatbot.llm.model.parameters())
        param_count_b = param_count / 1e9
        print(f"   - Model: Qwen2-0.5B-Instruct")
        print(f"   - S·ªë tham s·ªë: {param_count_b:.3f} t·ª∑")
        print(f"   - Y√™u c·∫ßu: ‚â§ 1 t·ª∑ ‚Üí {'‚úÖ ƒê·∫†T' if param_count_b <= 1.0 else '‚ùå KH√îNG ƒê·∫†T'}")
```

**Gi·∫£i th√≠ch:** T∆∞∆°ng t·ª± demo, test script c≈©ng verify s·ªë tham s·ªë ‚â§ 1 t·ª∑.

---

## 5. S·ª≠ d·ª•ng trong Chatbot (File: `src/chatbot/chatbot.py`)

### 5.1. Kh·ªüi t·∫°o v·ªõi model m·∫∑c ƒë·ªãnh

```67:73:src/chatbot/chatbot.py
    def __init__(
        self,
        data_path: str = "data/merged_kpop_data.json",
        llm_model: str = "qwen2-0.5b",
        use_embeddings: bool = True,
        verbose: bool = True
    ):
```

**Gi·∫£i th√≠ch:** Chatbot m·∫∑c ƒë·ªãnh s·ª≠ d·ª•ng `llm_model="qwen2-0.5b"` (0.5B parameters).

### 5.2. Load LLM

```108:119:src/chatbot/chatbot.py
        # 4. Small LLM (optional)
        self.llm = None
        if llm_model:
            if verbose:
                print(f"  ü§ñ Loading LLM: {llm_model}...")
            try:
                self.llm = get_llm(llm_model)
            except Exception as e:
                if verbose:
                    print(f"  ‚ö†Ô∏è LLM loading failed: {e}")
                    print("  üí° Using fallback mode (context-based responses)")
                self.llm = None
```

**Gi·∫£i th√≠ch:** Load LLM th√¥ng qua `get_llm(llm_model)` v·ªõi model key `"qwen2-0.5b"`.

---

## 6. C√°ch Ch·∫°y v√† Verify

### 6.1. Ch·∫°y Demo

```bash
python src/demo_chatbot.py
```

**Output m·∫´u:**
```
‚úÖ Model: Qwen2-0.5B-Instruct
‚úÖ S·ªë tham s·ªë: 0.500 t·ª∑ (500.0M)
‚úÖ Y√™u c·∫ßu: ‚â§ 1 t·ª∑ tham s·ªë
‚úÖ K·∫øt qu·∫£: ‚úÖ ƒê·∫†T
```

### 6.2. Ch·∫°y Test

```bash
python src/test_chatbot.py
# Ch·ªçn option 4: Ki·ªÉm tra y√™u c·∫ßu b√†i t·∫≠p
```

**Output m·∫´u:**
```
1. ‚úÖ Small LLM (‚â§1B params):
   - Model: Qwen2-0.5B-Instruct
   - S·ªë tham s·ªë: 0.500 t·ª∑
   - Y√™u c·∫ßu: ‚â§ 1 t·ª∑ ‚Üí ‚úÖ ƒê·∫†T
```

### 6.3. Verify tr·ª±c ti·∫øp trong code

```python
from chatbot.small_llm import get_llm

llm = get_llm("qwen2-0.5b")
param_count = sum(p.numel() for p in llm.model.parameters())
param_count_b = param_count / 1e9

print(f"S·ªë tham s·ªë: {param_count_b:.3f} t·ª∑")
print(f"Y√™u c·∫ßu: ‚â§ 1 t·ª∑ ‚Üí {'‚úÖ ƒê·∫†T' if param_count_b <= 1.0 else '‚ùå KH√îNG ƒê·∫†T'}")
```

---

## 7. T√≥m t·∫Øt

| Y·∫øu t·ªë | Gi√° tr·ªã | V·ªã tr√≠ trong code |
|--------|---------|-------------------|
| **Model ƒë∆∞·ª£c ch·ªçn** | Qwen2-0.5B-Instruct | `small_llm.py:49, 64` |
| **S·ªë tham s·ªë** | 0.5 t·ª∑ (500M) | Model specification |
| **T√≠nh to√°n s·ªë tham s·ªë** | `sum(p.numel() for p in model.parameters())` | `small_llm.py:235` |
| **Verification** | `param_count_b <= 1.0` | `demo_chatbot.py:47`, `test_chatbot.py:255` |
| **S·ª≠ d·ª•ng trong chatbot** | `llm_model="qwen2-0.5b"` | `chatbot.py:70` |

---

## 8. K·∫øt lu·∫≠n

‚úÖ **ƒê·∫†T Y√äU C·∫¶U:** 
- Model: Qwen2-0.5B-Instruct
- S·ªë tham s·ªë: **0.5 t·ª∑ (500M)** < **1 t·ª∑**
- Code c√≥ verification r√µ r√†ng: `param_count_b <= 1.0`
- C√≥ demo v√† test ƒë·ªÉ ch·ª©ng minh

---

## 9. C√°c file li√™n quan

1. **`src/chatbot/small_llm.py`** - ƒê·ªãnh nghƒ©a v√† load model
2. **`src/demo_chatbot.py`** - Demo verification
3. **`src/test_chatbot.py`** - Test verification
4. **`src/chatbot/chatbot.py`** - S·ª≠ d·ª•ng model trong chatbot




